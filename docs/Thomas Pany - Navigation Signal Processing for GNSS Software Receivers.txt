

Library of Congress Cataloging-in-Publication Data
A catalog record for this book is available from the U.S. Library of Congress.
British Library Cataloguing in Publication Data
A catalog record for this book is available from the British Library.
ISBN-13: 978-1-60807-027-5
Cover design by Greg Lamb
Accompanying MATLAB and assembler programs are available at www.artechhouse.com. 
© 2010 ARTECH HOUSE
685 Canton Street
Norwood, MA 02062
All rights reserved. Printed and bound in the United States of America. No part of this book 
may be reproduced or utilized in any form or by any means, electronic or mechanical, includ­
ing photocopying, recording, or by any information storage and retrieval system, without 
permission in writing from the publisher.
All terms mentioned in this book that are known to be trademarks or service marks have 
been appropriately capitalized. Artech House cannot attest to the accuracy of this informa­
tion. Use of a term in this book should not be regarded as affecting the validity of any trade­
mark or service mark.
10 9 8 7 6 5 4 3 2 1

v
Contents
Preface 
xiii
Acknowledgments 
xvii
 Chapter 1 
Radio Navigation Signals 
1
1.1  Signal Generation	
1
1.2  Signal Propagation	
2
1.3  Signal Conditioning	
3
1.4  Motivation for a Generic Signal Model	
4
1.5  Sampling	
5
1.6  Deterministic Received Signal Model	
6
1.7  Stochastic Noise Model	
6
1.8  Short-Period Signal Model	
7
1.8.1  Zeroth-Order Moment of Signal Power	
8
1.8.2  First-Order Moment of Signal Power	
8
1.8.3  Second-Order Moment of Signal Power	
9
1.8.4  First-Order Moment of Signal Power Variations	
9
1.8.5  Separation of Code and Carrier Correlation	
10
1.9  Exemplary Signals	
11
1.9.1  A Model for the GPS C/A-Code Signal	
11
1.9.2  A Model for the Galileo E1 Open-Service Signal	
13
1.9.3  Pulsed GNSS Signals	
14
1.9.4  Gaussian Double Pulse	
15
References	
16
 Chapter 2 
Software-Defined Radio 
17
2.1  Definitions	
17
2.2  Communication Radios	
19
2.2.1  GNU Radio	
19
2.2.2  Joint Tactical Radio System	
19
2.3  GNSS Software Receivers	
22
2.3.1  Front Ends	
22
2.3.2  Illustrative Applications	
25
2.3.3  High-End GNSS Software Receivers	
28
2.4  Technology Evaluation and Discussion	
30
References	
30


Contents 
vii
4.3.1  Model for One or More Propagation Paths	
73
4.3.2  Single Propagation Path	
76
4.3.3  Correlation Point	
91
4.3.4  Linearization	
97
4.3.5  Multiple Propagation Paths	
98
4.3.6  Two Propagation Paths: Code-Phase CRLB	
100
4.3.7  Two Propagation Paths: Doppler CRLB	
104
4.3.8  Two Propagation Paths: Remark on Other Bounds	
104
4.4  Data Reduction	
106
4.4.1  Sufficient Statistics	
106
4.4.2  Multicorrelator Approach	
107
4.4.3  First-Derivative Approach	
107
4.4.4  Colored Noise	
108
4.5  Bayesian Approach	
108
4.5.1  Minimum Mean-Squared Error Estimation	
109
4.5.2  Kalman–Bucy Filter	
110
4.5.3  Other Filters	
112
4.5.4  Use of Kalman Filters in GNSS Signal Processing	
113
4.6  Squaring Loss Revisited	
114
4.7  Numerical Simulation	
117
4.7.1  Evaluation of Bounds	
118
4.7.2  Cost Function	
119
4.7.3  LSQ Solution	
120
4.8  Discussion	
124
References	
125
 Chapter 5 
Signal Detection 
129
5.1  Detection Principles	
129
5.1.1  Simple Hypothesis Testing	
130
5.1.2  Composite Hypothesis Testing	
131
5.2  Detection Domains	
133
5.2.1  Pseudorange Domain Detection	
133
5.2.2  Position Domain Detection	
133
5.3  Preprocessing	
133
5.4  Clairvoyant Detector for Uniformly Distributed Phase	
134
5.5  Energy Detector	
137
5.6  Bayesian Detector	
138
5.7  Generalized Likelihood-Ratio Detector	
140
5.7.1  Single Coherent Integration	
141
5.7.2  Multiple Coherent Integrations	
142
5.7.3  Considering Navigation Signal Interference	
147
5.7.4  Data and Pilot	
149
5.8  System-Detection Performance	
154
5.8.1  Idealized Assumptions	
155
5.8.2  Mean Acquisition Time	
155

  5.8.3  System Probabilities	
156
  5.8.4  Independent Bin Approximation	
156
  5.8.5  Code-Phase and Doppler Losses	
157
  5.9  Long Integration Times and Differential Detectors	
158
5.10  Discussion	
159
  References	
161
 Chapter 6 
Sample Preprocessing 
163
6.1  ADC Quantization	
163
6.1.1  Quantization Rule	
163
6.1.2  Matched Filter	
165
6.1.3  Evaluation of Expected Values	
167
6.1.4  Infinite Number of Bits	
169
6.1.5  Numerical Evaluation	
170
6.2  Noise-Floor Determination	
174
6.3  ADC Requirements for Pulse Blanking	
174
6.3.1  Front-End Gain and Recovery Time	
175
6.3.2  Pulse Blanking	
175
6.3.3  ADC Resolution	
176
6.4  Handling Colored Noise	
178
6.4.1  Spectral Whitening	
178
6.4.2  Modified Reference Signals	
179
6.4.3  Overcompensation of the Incoming Signal	
180
6.4.4  Implementation Issues	
180
6.5  Sub-Nyquist Sampling	
180
References	
182
 Chapter 7 
Correlators 
185
7.1  Correlator and Waveform-Based Tracking	
185
7.2  Generic Correlator	
187
7.2.1  Expected Value	
188
7.2.2  Covariance	
189
7.2.3  Variance	
191
7.3  Correlator Types with Illustration	
191
7.3.1  P-Correlator	
192
7.3.2  F-Correlator	
193
7.3.3  D-Correlator	
194
7.3.4  W-Correlator	
194
7.4  Difference Correlators	
197
7.4.1  Single-Difference P-Correlators	
197
7.4.2  Double-Difference P-Correlators	
199
7.5  Noisy Reference Signal for Codeless Tracking	
200
7.5.1  Expected Value	
202
7.5.2  Covariance	
202
viii 
Contents

Contents 
ix
7.5.3  Variance	
204
7.5.4  L2 P(Y)-Code Carrier-Phase Discriminator Noise	
204
7.6  Incorporating Colored Noise	
206
7.6.1  White-Noise Transformation	
206
7.6.2  Early–Late Code Discriminator with Infinite Sample Rate	
208
7.7  Comparison of Finite and Infinite Sample Rates	
212
References	
214
 Chapter 8 
Discriminators 
217
8.1  Noncoherent Discriminators	
217
8.1.1  Code Discriminator	
217
8.1.2  Doppler Discriminator	
221
8.1.3  Phase Discriminator	
223
8.1.4  Clipping	
225
8.2  S-Curve Shaping	
225
8.2.1  Code-Discriminator Performance Characteristics	
226
8.2.2  Optimum S-Curve	
227
8.2.3  Frequency-Domain S-Curve Shaping	
228
8.2.4  Discussion	
231
8.3  Multipath Estimating Techniques	
231
8.3.1  The LSQ Equations	
232
8.3.2  Calibration	
235
8.3.3  General Procedure	
235
8.3.4  Correlator Placement	
236
8.3.5  Initial Values	
236
8.3.6  Number of Required Iterations	
237
8.3.7  Multipath Detection	
237
8.3.8  Discussion	
238
8.4  From Discriminator Noise to Position Accuracy	
238
References	
239
 Chapter 9 
Receiver Core Operations 
241
9.1  Test-System Configuration	
241
9.2  Signal-Sample Bit Conversion	
242
9.2.1  Algorithm	
243
9.2.2  Numerical Performance	
244
9.2.3  Discussion and Other Algorithms	
245
9.3  Resampling	
245
9.3.1  Algorithm	
245
9.3.2  Numerical Performance	
245
9.3.3  NCO Resolution	
246
9.3.4  Discussion and Other Algorithms	
248
9.4  Correlators	
248
9.4.1  SDR Implementation	
249

9.4.2  Discussion and Other Algorithms	
250
9.5  Fast Fourier Transform	
251
9.5.1   Algorithm	
251
9.5.2   Convolution Theorem	
252
9.5.3   Time-Domain Correlation and Data Preparation	
253
9.5.4   Spectral Shifting	
256
9.5.5   Limited-Size Inverse FFT	
257
9.5.6   Circular Correlation with Doppler Preprocessing	
260
9.5.7   Handling Secondary Codes	
263
9.5.8   Asymptotic Computational Performance	
267
9.5.9   Reported FFT Performance Values	
267
9.5.10  Discussion and Number of Correlators	
269
9.6  Reality Check for Signal Tracking	
271
9.7  Power Consumption	
272
9.8  Discussion	
274
References	
275
 Chapter 10 
GNSS SDR RTK System Concept 
277
10.1  Technology Enablers	
277
  10.1.1  Ultra-Mobile PCs	
277
  10.1.2  Cost-Effective High-Rate Data Links	
278
10.2  System Overview	
279
  10.2.1  Setup	
279
  10.2.2  Sample Applications	
280
  10.2.3  Test Installation and Used Signals	
280
10.3  Key Algorithms and Components	
281
10.4  High-Sensitivity Acquisition Engine	
281
  10.4.1  Doppler Search Space	
282
  10.4.2  Correlation Method	
284
  10.4.3  Clock Stability	
284
  10.4.4  Line-of-Sight Dynamics	
287
  10.4.5  Flow Diagram and FFT Algorithms	
287
  10.4.6  Acquisition Time	
288
10.5  Assisted Tracking	
289
  10.5.1  Vector-Hold Tracking	
290
  10.5.2  Double-Difference Correlator	
291
10.6  Low-Cost Pseudolites	
297
  10.6.1  Continuous-Time Signals	
299
  10.6.2  Pulsed Signals	
299
10.7  RTK Engine	
304
References	
305
 Chapter 11 
Exemplary Source Code 
307
11.1  Intended Use	
307
 
Contents

Contents 
xi
11.2  Setup	
307
  11.2.1  Required Software	
307
  11.2.2  Preparing the Simulation	
308
  11.2.3  Signal Selection and Simulation Parameters	
308
11.3  Routines	
308
  11.3.1  True Cramér-Rao Lower Bound	
308
  11.3.2  Discriminator Noise Analysis	
308
  11.3.3  FFT Acquisition	
308
  11.3.4  Simplified Vector Tracking with Multipath Mitigation  
and Spectral Whitening	
309
  Appendix  
A.1  Complex Least-Squares Adjustment	
311
A.1.1  Definitions	
311
A.1.2  Probability Density Function	
312
A.1.3  The Adjustment	
312
A.1.4  Real- and Complex-Valued Estimated Parameters	
314
A.1.5  A Posteriori Variance of Unit Weight	
315
A.1.6  Example	
318
A.1.7  Discussion	
320
A.2  Representing Digital GNSS Signals	
320
A.2.1  Complex-Valued Input Signal	
320
A.2.2  Real-Valued Input Signal	
321
A.2.3  Comparing Real- and Complex-Valued Signals	
322
A.3  Correlation Function Invariance	
326
A.4  Useful Formulas	
329
A.4.1  Fourier Transform	
329
A.4.2  Correlation Function	
331
A.4.3  Correlation with an Auxiliary Function	
332
A.4.4  Correlation with Doppler	
333
A.4.5  Correlation in Continuous Time	
334
A.4.6  Probability Density Functions	
336
References	
338
Abbreviations 
339
List of Symbols 
343
About the Author 
345
Index 
347

xiii
Preface
The continuous developments of software-defined radio technology resulted in the 
appearance of the first real-time GPS software radios at the beginning of this cen-
tury. For the first time, it was possible to realize a complete GNSS receiver without 
going into the depths of cumbersome hardware development that requires develop-
ment or programming of low-level digital circuitry. The hardware development ef-
forts were indeed so high that only a very limited number of companies or research 
institutes could afford them. Furthermore, the implementation constraints were so 
severe, especially for the first generation of GPS receivers, that often crude signal-
processing approximations were necessary to allow a real implementation. Cur-
rently, software-defined radio technology not only allows receiver implementations 
by a larger research community, but also drastically increases the signal-processing 
capabilities. It also has the potential to become, in certain navigation areas, a com-
mercial success.
Software radio technology provides an opportunity to design a new class of 
GNSS receivers, being more flexible and easier to develop than their FPGA- or 
ASIC-based counterparts. Therefore, this text reviews navigation signal detection 
and estimation algorithms and their implementation in a software radio. A focus 
is put on high-precision applications for GNSS signals and an innovative RTK re-
ceiver concept based on difference correlators is proposed. 
This text makes extensive use of the least-squares principle. The least-squares 
principle is the typical basis for the calculation of a navigation solution. An adjust-
ment or a Kalman filter calculates positions from pseudorange observations in vir-
tually any GNSS receiver. Within this text, the least-squares principle is consistently 
extended to also allow signal samples as observations. In contrast to the pseudorange- 
observation equation, the signal sample model is highly non-linear, causing a num-
ber of difficulties that are discussed. Furthermore, signal sample observations can 
be complex-valued.
In the author’s opinion, the development of a navigation receiver does not nec-
essarily require an in-depth theoretical knowledge of signal-estimation and signal-
detection theory. The basic algorithms like correlation and tracking can also be 
understood on an intuitive basis. Indeed many textbooks skip the highly theoretical 
signal-estimation and signal-detection framework and focus on engineering aspects. 
The question arises: What can we learn from the theoretical treatment that is pre-
sented here? First, the theory allows a performance assessment without building a 
receiver. By providing benchmarks like the Cramér-Rao lower bound or the clair-
voyant detector, the theory serves also as a reference with which to compare a real 
implementation. This text attempts to generalize the existing theory for arbitrary 
navigation signal waveforms, going beyond existing GNSS signals. The theoretical 

treatment also gives hints for optimal algorithms; useful examples that are discussed 
are spectral whitening and the least-squares-based multipath-estimating discrimina-
tor. Efficient algorithms are found in the frequency domain for signal acquisition, 
which itself would justify the effort of going into theoretical details. Furthermore, 
the theoretical analysis points out that new developments could be expected in the 
field of direct-position estimation (in a single-step procedure, instead of estimating 
a position via pseudoranges), which should give advantages in terms of interference 
robustness and sensitivity. Sensitivity might be further increased by using Bayesian 
techniques (like a particle filter) that do not rely on a linearized signal model.
Unfortunately, the existing navigation signal-processing theory has limits and 
does not always provide an optimal algorithm for detection or estimation. Ex­
amples are the nonexistence of a uniform most powerful detector for acquisition and 
the nonexistence of a minimum variance unbiased code-phase or Doppler estimator 
for finitely received signal power. In addition, the practical usability of Bayesian 
techniques within signal processing (apart from the Kalman filter) is not completely 
assessed. Overall, it seems that a theoretically optimal navigation receiver is out-of-
reach today, even if only signal processing is considered. However, software radio 
technology closes the gap between existing theory and real implementation.
Overview
Within this text, the navigation signal processing theory is described for generic navi-
gation signals to allow a broad range of applications, beyond that of GNSS. Require-
ments for navigation signals are introduced in Chapter 1 and are illustrated with one 
GPS, one Galileo, and two pulsed signals. Software-defined radio technology will be 
introduced in Chapter 2, together with the architecture and the data flow of a per-
manent GNSS reference station in Chapter 3. Chapters 4 and 5 focus on theoretical 
signal-processing aspects and Chapters 6 through 9 shift the focus to implementation. 
An innovative high-precision software radio concept is presented in Chapter 10 using 
double­-difference correlators, in addition to double-difference pseudorange and carrier-
phase observations to increase carrier-phase tracking stability for real-time kinematic 
applications. Finally, on the Artech House Web site, www.artechhouse.com, this book 
has some MATLAB and assembler programs that illustrate the core signal-processing 
concepts of a navigation receiver. Chapter 11 describes this software.
Summary of Presented Signal-Processing Theory
In Chapter 1, requirements are formulated that a generic navigation signal has to 
fulfill to allow for the simultaneous estimation of the code phase, the Doppler and 
the carrier phase. Based on those requirements, Chapter 4 reviews the estimation 
theory for navigation signals using a consistent mathematical notation and derives 
the theory from first principles. The presented mathematical derivations are very 
detailed and with the finite sample rate approach, a reader should be able to adapt 
the theory for his or her purposes easily. The finite sample rate description is also 
chosen to enable a software receiver developer to establish a one-to-one correspon-
dence of theory and implementation at every stage of signal processing. 
xiv 
Preface


com/static/reslib/pany/pany1.html. The source code includes the FFT acquisition 
methods and multipath-estimating tracking. Furthermore, MATLAB scripts for 
the true Cramér-Rao lower bound as well as for the thermal-noise analysis of the 
noncoherent discriminators are included. The scripts run with the four exemplary 
navigation signals of Chapter 1 and are outlined in Chapter 11.
Book’s Usage for Practical Receiver Implementation
This book should help in building advanced navigation software receivers. It is 
not a beginner’s book and the reader should be familiar with the architecture 
of a GNSS software receiver, which is, for example, excellently described by 
Borre’s book mentioned in Chapter 2. Borre’s book also comes with a complete 
MATLAB receiver and our text may help you to extend this receiver for high-sensitivity 
applications using efficient FFT techniques or for high-precision applications ap-
plying multipath-mitigation schemes or stable double-difference carrier-phase 
tracking.
To build a navigation software receiver, you need there things: navigation sig-
nal samples, a software framework that handles the data flow, and efficient core 
algorithms.
Signal samples can be obtained by one of the GNSS front ends described in 
Chapter 2 or you can use the single-channel signal generator of Chapter 11. Some-
times, the front-end manufacturers can provide you with exemplary signal-sample 
streams, too. 
Writing a software receiver framework from scratch can be a quite tedious 
work. The framework handles the enormous amount of signal samples, synchro-
nizes the different receiver channels, computes the position, and provides some 
standard output formats. You can short-cut this by adapting the MATLAB source 
code mentioned above. Another possibility to avoid this cumbersome work is to 
use a commercial software receiver having an application programming interface, 
which you can plug into your own source code. Chapter 11 provides you with a 
single-channel framework that demonstrates how to convert the sample stream into 
pseudorange measurements. 
Finally, the core algorithms can actually be found within this text. They are 
derived in a way that they can be adapted easily for a specific framework and the 
assembler code should help to realize them efficiently.
xvi 
Preface

xvii
Acknowledgments 
This work would not have been possible without the support from numerous co-
workers and colleagues. I am especially grateful to the researchers of the University 
of Federal Armed Forces in Munich, to the researchers at the IFEN GmbH, and to 
many colleagues from research institutes from all over the world.
I am grateful to Professor Günter W. Hein for continually encouraging me to 
enter this field, for his uninterrupted belief in technology, and for showing me ways 
of going beyond limits. Professor Bernd Eissfeller established the basis for GNSS 
receiver technology research at the Institute of Geodesy and Navigation. His con-
tribution to this work cannot be overvalued. I would also like to thank Professor 
Jörn Thielecke for fruitful discussions. With his knowledge on communication and 
navigation signal processing, he showed me several important links between both 
fields.  


2	
Radio Navigation Signals
output, or to the digitized signal obtained after (optional) downconversion and 
filtering of the received signal. 
The broadcast navigation signal structure is known to the receiver and will be 
characterized in the following paragraphs. A good way to do this is to merge the 
frontend filter into the output filter (i.e., into a combined filter) and to describe the 
signal after the output filter. This simplification is useful for signal processing pur-
poses and is valid, because both antennas, the propagation path, and the frontend 
filter act as linear systems to the signal. Nonlinear effects of the amplifiers or mixer 
are not considered.
Without the combined filter (or output filter), the transmitted signal rS is writ-
ten as
	
( )
( )
( )cos(2
)
S
S
RF
r t
a d t c
t
f
t
π
¥
=
	
(1.1)
Here, fRF is the carrier frequency in hertz, c (t) is the infinite bandwidth signal 
representation at baseband, and d(t) represents a broadcast navigation message. 
The transmitted signal is described in the signal-in-space (SIS) interface control doc-
ument (ICD) [1, 2]. The symbol aS denotes the signal amplitude in arbitrary units.
Other signals might be transmitted on the same carrier frequency by the same 
satellite. For example, the Global Positioning System (GPS) C/A signal is broadcast 
in phase quadrature with the P(Y) signal on the L1 (1,575.42 MHz) carrier fre-
quency. The access to the different signals is controlled via c (t). Different wave-
forms of c∞(t) can be used to realize code division multiple access (CDMA), time 
division multiple access (TDMA), or—by including a carrier into c (t)—frequency 
division multiple access (FDMA) schemes. 
With the combined filter, the signal is mathematically written as
	
= -
+
( )
( )
( )sin(2
)
( ) ( )cos(2
)
S
S
Q
RF
S
I
RF
r t
a d t c
t
f
t
a d t c t
f
t
π
π
	
(1.2)
with 
	
( )
( )
( )
I
Q
c t
c t
ic
t
=
+
	
(1.3)
representing the filtered baseband representation of the signal obtained by applying 
(1.10). The signal cQ(t) is an artifact generated by the filter. The filter does not affect 
d(t), as long as the data rate (e.g., 50 bit/s) is much smaller than the filter bandwidth 
(e.g., 2 MHz). If the radio frequency (RF) is much higher than the filter bandwidth, 
cQ(t) is small and can be ignored.
Using a complex notation, the signal after the combined filter is given as
	
( )
Re{ ( ) ( )exp(2
)}
S
S
RF
r t
a
d t c t
if
t
π
=
	
(1.4)
1.2  Signal Propagation
According to Fermat’s principle, the line-of-sight component of the signal rS(t) 
travels along the shortest propagation path from the transmitter to the receiver. 
Eventually, one or more reflected signals [i.e., copies of rS(t)] are superimposed with 
the line-of-sight signal. Each copy has a different amplitude, Doppler, carrier phase 

1.3  Signal Conditioning	

delay, or code phase delay. Furthermore, the line-of-sight component is delayed by 
the atmosphere. Accurate modeling of the propagation effects is one of the key ele-
ments to obtain a precise position and this topic is covered in many satellite navi-
gation text books [3, 4]. We will not go into the modeling details, but will instead 
focus on a model for the received signal that can be used as a basis for delay and 
Doppler estimation. 
Delays affect the carrier and the data-modulating signals c(t), d(t) differently. 
Frequency-independent (nondispersive) delays are caused by the geometric distance 
and by the electrically neutral part of the atmosphere (troposphere). Frequency-
dependent (dispersive) delays are caused by the ionosphere and by the receiver and 
transmitter hardware. Dispersive and nondispersive delays add up and result in the 
group delay τG, delaying c(t) and d(t). The carrier is delayed by the phase delay τP. 
The delays τG and τP are not equal because the ionospheric delay contributes to 
each of them with a different sign. The difference is typically less than 100m and 
varies with a frequency not more than 0.05 Hz if no scintillations are present. Also, 
hardware group and phase delay are generally different.
The group delay, τG, affects c(t) via
	
,0
( )
(
( ))
(
)
G
D
G
c t
c t
t
c
t
τ
α
τ
®
-
»
-
	
(1.5)
and similarly for d(t). The phase delay, τP, affects the carrier via
	
,0
exp(2
)
exp(2
(
( )))
exp(2
(
))
RF
RF
P
RF
D
P
if
t
if
t
t
if
t
π
π
τ
π
α
τ
®
-
»
-
	
(1.6)
with
	
/ ,0
/
0
0
( )
(1
)
G P
G P
D
t
t
τ
τ
α
=
-
-
	
(1.7)
The coefficient αD
	
1
D
v
c
α
=
-
	
(1.8)
is the Doppler effect, caused by the change in the group/phase delay, expressed as 
velocity v in meters per second. The linearization is carried out around the epoch t0. 
If the signal duration Tcoh under consideration is short, the Doppler effect on c(t), 
d(t) can be ignored, as in 
	
,0
0
(
)
(
( ))
coh
D
G
c
T
c
t
c t
t
vB
α
τ
τ
>>
Þ
-
»
-
	
(1.9)
and similarly for d(t), where B denotes the signal (or data message) bandwidth in 
hertz.
1.3  Signal Conditioning
After signal reception by the antenna, the signal is amplified, filtered, and eventually 
downconverted. Amplification changes the amplitude of the signal (from aS to a), 
but leaves the signal structure invariant. 

4	
Radio Navigation Signals
The frontend filter limits the bandwidth of the received navigation signals and 
of the received noise. It also rejects out-of-band signals. The frontend filter is typi-
cally of lower bandwidth than the output filter and neglecting the output filter is a 
reasonable approximation. The resulting filter is a band pass filter and is described 
by its baseband equivalent H via
	
¥
=
( )
(
( ))
c t
H c
t 	
(1.10)
For signal estimation and detection, it is largely irrelevant at which center fre-
quency the filter operates; it can be placed at the RF, at the IF, or at baseband. Nor-
mally, filters with discrete components or SAW filters operating at the IF are used, 
but discrete polyphase filters at baseband have also been utilized. Global navigation 
satellite system (GNSS) receivers normally do not integrate the filter into a chip 
solution.
Downconversion changes the signal carrier model by
	
,0
,0
exp(2
(
))
exp(2
(
)
2
)
RF
D
P
RF
D
P
LO
if
t
if
t
if
t
π
α
τ
π
α
τ
π
-
®
-
-
	
(1.11)
where fLO is the local oscillator frequency in hertz.
For each transmitter and propagation path, a signal of the form 
	
0
,0
( )
(
( ))exp(2
(
)
2
)
rec
RF
D
P
LO
r
t
ac t
t
if
t
if
t
τ
π
α
τ
π
=
-
-
-
	
(1.12)
arrives at the front end’s ADC(s). The ADC(s) either quantize(s) the real and the 
imaginary part of the signal or quantizes only one of them (see Appendix A.2).
1.4  Motivation for a Generic Signal Model
By specifying core signal elements, it is possible to reduce the amount of information 
that is necessary to analyze a navigation system. The baseband representation of 
the navigation signal c(t), the time over which d(t) remains constant, and the carrier 
frequency represent core elements that determine to a large extent how precisely a 
receiver can estimate code and carrier delay, the Doppler shift, and, consequently, 
its position. They are summarized in Table 1.1. 
The assumptions imposed on the received signals are kept as general as pos-
sible to allow the application of the developed theory to a wide range of signals. It 
focuses mostly on conventional GNSS continuous-time CDMA signals using binary 
phase shift keying (BPSK), binary offset carrier (BOC), multiplexed BOC (MBOC), 
alternative BOC (AltBOC), or any other spread-spectrum technique. Furthermore, 
Table 1.1  Influence of Navigation Signal Elements on 
Signal Processing Parameters
Signal Element
Affected Signal Processing Parameter
c(t)
Code correlation function Rc,c,  
Doppler correlation function
d(t)
Coherent integration time Tcoh,  
Doppler correlation function

1.5  Sampling	

pulsed signals are included because they are being used by pseudolites, by LORAN-C, 
or RADAR-like ranging systems. In principle, the theory can also be adapted for 
sonar ranging systems and, with some limitations, for optical ranging systems. Only 
one frequency band is considered (e.g., GPS L1); a generalization from a sampling 
of one frequency band to multiple frequency bands is obvious, but one should be 
take care that all bands are sampled synchronously.
No assumption on the relation of the signal bandwidth to the sampling rate is 
made and, in particular, sub-Nyquist sampling rates can be used. No assumption on 
the modulation scheme is made as long as the received signal waveform at baseband 
c(t) is known a priori to the receiver. Eventually, filters influence the theory via the 
waveform c(t). The more narrow the filter bandwidth, the smoother the waveform 
will be. 
The filter bandwidth and characteristics define how much noise power is be-
ing received: the wider the bandwidth, the higher the noise power. For simplicity, a 
unity noise power is assumed in (1.16) and it is important to keep in mind that only 
ratios between power levels have meaningful values, as described in Section 1.8.1. 
In that sense, (1.16) defines the power scale.
The Nyquist criterion does not fully apply because the waveform c(t) is known 
to the receiver beforehand. Consequently, there is no need to reconstruct the signal 
waveform from the received samples [5]. As shown in Section 6.5, a good choice 
for the sample rate is exactly equal to the Nyquist rate (e.g., being equal to the noise 
bandwidth). Lower sample rates yield less-independent signal samples, thereby gen-
erally decreasing the accuracy of the obtained estimates. The accuracy decrease can 
be modeled as an effective signal power loss. This observation is also true when 
multiple reflections of the same signal are received.
In the rest of this chapter, we will formulate generic conditions for navigations 
signals. Later, we illustrate the conditions with two GNSS signals and two pulsed 
terrestrial navigation signals. In addition to those parameters, the number of re-
ceived signals, the amplitude, and the geometric placement of the transmitters affect 
the positioning result (see Sections 4.1.3 and 8.4).
1.5  Sampling
In the following, a number of L signal samples are considered, indexed by m. The 
index m assumes, in general, the values
	
{
}
1,
,L
µ Î
…
	
(1.13)
The sampling epoch tm in seconds for the sample m is given by 
	
s
t
f
µ
µ
=
	
(1.14)
and fs defines the ADC sample rate in samples per second. Optionally, the sampling 
epochs can be offset by a fixed amount of time, which will not explicitly be men-
tioned here.
For each sampling epoch tm, a complex-valued (i.e., I plus Q) signal sample is 
generated. We chose a complex signal representation to work with more compact 

6	
Radio Navigation Signals
expressions compared to working with real-valued signal representations using, 
for example, only the I-component. In Appendix A.2, it is shown that both signal 
representations are equivalent. Additionally, it is possible to derive an equation us-
ing the complex-valued signal representation and then to adapt the final result for 
the real-valued signal representation. This can be done by taking the real compo-
nent of the obtained results or by similar methods. This approach is used in Chap-
ters 7 and 8. The GNSS SDR implementation of Chapter 2 works internally with a 
real-valued signal representation. 
1.6  Deterministic Received Signal Model 
A digitized received signal sample is modeled as a complex random variable Sm be-
ing composed of a deterministic part rm and a purely stochastic part Nm,
	
;
m
m
S
r
N
r
N
µ
µ
µ
µ
µ
=
+
=
+
å
	
(1.15)
The deterministic part is the sum of all received signals rm;m broadcast from one 
or more transmitters propagating along one or more paths; for example, the index 
m distinguishes not only the different emitters, but also the different propagation 
paths. Furthermore, m may distinguish different signal components (e.g., data and 
pilot signals) broadcast by the same transmitter.
1.7  Stochastic Noise Model
The baseline assumption for the stochastic component of the received signal is to 
model it as complex-valued uncorrelated white noise having unity variance in each 
component
	
,
0,
0,
2
N N
N N
N N
µ
υ
µ
υ
µ
υ
µ υ
δ
=
=
=
N
N
N
	
(1.16)
and zero mean
	
0
Nµ
=
N
	
(1.17)
The white noise originates from the received and internally generated noise.
In general, it is assumed that the amplitudes of the individual noise random 
variables Nm are Gaussian distributed. However, important results described in the 
following chapters also hold for arbitrary amplitude distributions of Nm, provided 
that (1.16) and (1.17) hold. A common example of a non-Gaussian noise distribu-
tion is the ADC quantization noise, which will be discussed in Section 6.1.
It is important to recognize that the comparably simple white-noise spectral 
characteristic is sufficient to model many navigation receiver frontends, as long as 
the sample rate is properly chosen (see Section 6.5). In fact, if (1.16) is not fulfilled, 
which occurs when oversampling is employed and results in nonwhite noise, then 
the operation of spectral whitening can be applied as described in Section 6.4. The 
operation of spectral whitening yields uncorrelated noise samples that allow the 
operation to work with the simple noise model (1.16) and simultaneously reduces 

1.8  Short-Period Signal Model	
7
the estimated parameters’ variances. If spectral whitening cannot be employed, 
methods discussed in Section 7.6 show how to adapt the results obtained under the 
assumption of white noise for the case of colored noise. 
1.8  Short-Period Signal Model
The deterministic component of the received signal model is the superposition of a 
number of signals. Each signal may be different but they are required to share the same 
structure, which will be defined later. The index m is abandoned in the following.
This structure is valid for short periods of time, typically being related to the 
coherent integration time and being on the order of a few tens of milliseconds at 
maximum in a standard GNSS receiver implementation.
We assume that the deterministic part of the received signal samples is modeled 
during a sufficiently short interval as
	
1
(
)exp
2 s
L
r
ac t
i
t
f
µ
µ
µ
τ
ω
ϕ
ì
ü
æ
ö
æ
ö
+
ï
ï
=
-
-
-
í
ý
ç
÷
ç
÷
è
ø
è
ø
ï
ï
î
þ	
(1.18)
Here, a denotes the signal amplitude in arbitrary units, τ is the delay (or code 
phase) of the signal in seconds, j is the carrier phase of the signal in radians, and ω 
is the angular frequency plus Doppler in radians per second. All values are instan-
taneous values and refer to a particular interval. The relation of the values between 
the different intervals will not be specified here.
The signal amplitude a is a measure for the received signal power and the delay 
τ relates to the geometric distance between transmitter and receiver. The carrier 
phase j contains information of the geometric distance, but is also used to ac-
commodate a possible broadcast navigation message. The angular frequency ω is 
given by the nominal frequency (being either zero, an intermediate frequency, or 
the nominal carrier frequency) plus a Doppler offset caused by the relative velocity 
between transmitter and receiver. 
The signal c(t) is the baseband representation of the broadcast navigation signal 
waveform (eventually complex-valued). In the example of a GPS C/A-code transmit-
ter, it is a 1-ms pseudorandom noise signal using a BPSK modulation scheme. The 
signal c(t) is affected by filters located on either the transmitter or the receiver side. 
It is important to recognize that the signal c(t) can be quite arbitrary and could 
assume a CDMA spreading code or a pulsed waveform. The important requirement, 
however, is that the waveform c(t) must be known to the receiver before receiving 
it. Additionally, five more requirements are formulated next. Three of these require-
ments, provided in Sections 1.8.1 through 1.8.3, are mostly of a formal nature (i.e., 
they relate to the definitions of constants and interval boundaries) and pose only few 
constraints on the waveform itself. The other two requirements, given in Sections 
1.8.4 and 1.8.5, are more strict and need to be fulfilled if the signal will allow sepa-
ration of Doppler estimates from delay estimates. The two conditions given in Sec-
tions 1.8.1 and 1.8.4 are extended to be compatible with the used estimation scheme 
(complex least-squares adjustment). The extensions are trivially fulfilled if the sig-
nal c(t) is real-valued and the extensions ensure that the code phase, the Doppler, 

	
Radio Navigation Signals
and the complex amplitude estimates are uncorrelated in the event that only a line-
of-sight signal is present.
It should be noted that the requirements formulated next need to be fulfilled 
sufficiently, but not necessarily exactly. Overall, they ensure that the Fisher informa-
tion matrix (4.60) can be sufficiently approximated by a diagonal matrix. 
1.8.1  Zeroth-Order Moment of Signal Power
The signal waveform at baseband is required to have an average unity power during 
the interval of interest, for example,
	
2
1
1
(
)
1
L
c t
L
µ
µ
τ
=
-
»
å
	
(1.19)
This is required so that only the signal amplitude a contains information of the 
received signal power and the waveform c(t) is assumed to be independent from the ac-
tual received power. This equation is approximately valid for all τ values of interest.
The numerical value of a itself is meaningless as it is expressed in arbitrary 
units. However, it can be related to the ratio between signal power and noise power 
spectral density C/N0, which is described in detail in Appendix A.2. Because of 
(1.19), the following equation holds:
	
2
0
/
2
sf a
C N =
	
(1.20)
The value of C/N0 is expressed in hertz.
Equation (1.19) implies that
	
-
-
»
í
ý
1
1
Re
(
)
(
)
0
L
c t
c t
L
µ
µ
µ
τ
τ
=
ì
ü
ï
ï
¢
ï
ï
î
þ
å
	
(1.21)
according to Appendix A.4.2. Note, c  denotes the first derivative of the waveform 
c. To avoid correlations between the imaginary part of the code phase estimate with 
the complex signal amplitude, it is required that the imaginary part of the above 
expression vanishes; overall, we require
	
-
-
»
1
1
(
)
(
)
0
L
c t
c t
L
µ
µ
µ
τ
τ
=
¢
å
	
(1.22)
Equation (1.22) is trivially fulfilled, if the waveform c(t) is real valued.
1.8.2  First-Order Moment of Signal Power 
The first-order moment in time of the signal power, with respect to the midpoint of 
the interval of interest, is required to vanish; for example, 
	
ç
÷
è
ø
2
1
1
(
)
0
2
L
s
L
t
c t
f
µ
µ
µ
τ
=
æ
ö
+
-
-
»
å
	
(1.23)

1.8  Short-Period Signal Model	
9
This requirement ensures that estimates for the angular frequency and the car-
rier phase are uncorrelated with each other, which will be shown in Section 4.3.2. 
This equation is approximately valid for all τ values of interest. The requirement 
is fulfilled if the signal power is located symmetrically in time with respect to the 
midpoint of the interval.
1.8.3  Second-Order Moment of Signal Power 
The second-order moment in time of the signal power with respect to the midpoint 
of the interval of interest evaluates to 
	
µ
µ
µ
2
2
3
2
2
2
1
1
1
2
1
(
)
(
)
2
2
12
L
L
freq
s
s
s
L
L
L
L
t
c t
c t
f
f
f
µ
µ
τ
τ
χ
=
=
æ
ö
æ
ö
+
-
-
-
-
-
=
-
»
ç
÷
ç
÷
è
ø
è
ø
å
å
µ
	
(1.24)
The constant χfreq measures the nonuniformity of the signal power distribution 
in time. If the signal power is constant during time (i.e., |c(t)|2 = 1), then χfreq = 1. 
This constant will be much smaller than 1, causing a reduced frequency estimation 
accuracy, especially for single pulses. This equation is approximately valid for all τ 
values of interest.
1.8.4  First-Order Moment of Signal Power Variations
Motivated by the requirement of Section 1.8.2, the first-order moment in time of 
the first derivative of the signal power, with respect to the midpoint of the interval 
of interest, is required to vanish; for example, 
	
2
1
1
(
)
0
2
L
s
L
t
c t
f
µ
µ
µ
τ
τ
=
æ
ö
+
¶
-
-
»
ç
÷ ¶
è
ø
æ
ö
ç
÷
è
ø
å
	
(1.25)
This implies that
	
1
1 Re
(
)
(
)
0
2
L
s
L
t
c t
c t
f
µ
µ
µ
µ
τ
τ
τ
=
æ
ö
+
¶
ì
ü
-
-
-
»
í
ý
ç
÷
¶
è
ø
î
þ
å
	
(1.26)
and, additionally, it is required that the imaginary part vanishes; overall, it is re-
quired that
	
1
1
(
)
(
)
0
2
L
s
L
t
c t
c t
f
µ
µ
µ
µ
τ
τ
=
æ
ö
+
-
-
-
»
¢
ç
÷
è
ø
å
	
(1.27)
This requirement ensures that Doppler estimates and code phase estimates are 
uncorrelated, which will be shown in Section 4.3.2. This equation is approximately 
valid for all τ values of interest. This requirement is nontrivial and might not hold 
for certain waveforms c(t). An example for which it does not hold occurs if c(t) as-
sumes a single Gaussian bell-shaped curve. In that case, complex-valued delay and 
complex-valued Doppler estimates are totally correlated.

10	
Radio Navigation Signals
1.8.5  Separation of Code and Carrier Correlation
When we consider two waveforms, c1(t) and c2(t), and their cross-correlation in-
cluding Doppler (see also Appendix A.4.4), then we require that the code correla-
tion be sufficiently well separated from the Doppler contribution. More specifically, 
it is required that 
	
1
2
1
2
,
1
1
(
)
(
)exp
( )
( )
2
L
c c
s
L
c t
c t
i
t
L
R
f
µ
µ
µ
µ
τ
ω
κ ω
τ
=
ì
ü
æ
ö
+
ï
ï
-
-
»
í
ý
ç
÷
è
ø
ï
ï
î
þ
å
	
(1.28)
is approximately fulfilled for a properly chosen function κ(ω), with κ(0) = 1. Equa-
tion (1.28) is fulfilled for all signals occurring in a certain navigation problem. The 
function κ(ω) is universal and applies to transmitted, received, or internally gener-
ated signal pairs (e.g., baseband signal plus P-, D-, F-, or W-correlator reference 
signals of Chapter 7) and to any combination of them.
In the case of a timely uniform distributed signal power |c1(t)| = |c2(t)| = const., 
the function κ(ω) is given as
	
2
2
2sin
2
( )
sinc
2
coh
coh
coh
i T
i T
coh
coh
coh
T
i e
e
T
T
T
ω
ω
ω
ω
κ ω
ω
ω
-
æ
ö
ç
÷
-
è
ø
æ
ö
»
=
=
ç
÷
è
ø
æ
è
ö
ø
	
(1.29)
Here, Tcoh = L/fs denotes the integration time in seconds.
Assuming a signal c(t) that fulfills (1.19), then κ(0)  1 and the conditions (1.23) 
and (1.28) require that κ(ω) fulfills
	
2
0
1
2
1
1
(
) exp
2
1
(
)
(0)
0
2
(0)
0
L
s
L
s
L
i
c t
i
t
f
L
c t
t
iL
f
µ
µ
ω
µ
µ
µ
µ
τ
ω
ω
τ
κ
κ
=
=
=
æ
ö
ì
ü
æ
ö
¶
+
ï
ï
æ
ö
-
-
-
ç
÷
í
ý
ç
÷
ç
÷
è
ø
¶
è
ø
ï
ï
è
ø
î
þ
æ
ö
+
=
-
-
» -
»
¢
ç
÷
è
ø
Þ
»
¢
å
å
	
(1.30)
Furthermore, the conditions (1.24) and (1.28) imply for κ(ω)
	
2
2
0
1
2
3
2
2
1
2
2
1
(
) exp
2
1
(
)
(0)
2
12
1
(0)
12
L
s
L
freq
s
s
freq
s
L
i
c t
i
t
f
L
L
L
c t
t
L
f
f
L
f
µ
µ
ω
µ
µ
µ
µ
τ
ω
ω
τ
κ
χ
κ
χ
=
=
=
æ
ö
ì
ü
æ
ö
¶
+
ï
ï
æ
ö
-
-
-
ç
÷
í
ý
ç
÷
ç
÷
è
ø
¶
è
ø
ï
ï
è
ø
î
þ
æ
ö
+
-
=
-
-
» -
»
¢¢
ç
÷
è
ø
-
Þ
» -
¢¢
å
å
	
(1.31)

1.9  Exemplary Signals	
11
For large L and Tcoh  L/fs, the conditions are summarized as
	
2
(0)
1
(0)
0
1
(0)
12
freq coh
T
κ
κ
κ
χ
»
»
¢
» -
¢¢
	
(1.32)
1.9  Exemplary Signals
This section illustrates the generic signal model with four types of navigation sig-
nals. Table 1.2 summarizes signal parameters of the four exemplary navigation 
signals. For each signal, we chose a typical coherent integration time. The pulsed 
open-service (OS) pilot signal is introduced in detail in Section 1.9.3 and Chapter 
10 and uses TR = 100 ms and TP = 4 ms. 
1.91  A Model for the GPS C/A-Code Signal
The American GPS is the most popular navigation system worldwide. Its first de-
velopment satellites were launched in 1978. Currently, 32 GPS satellites orbit the 
Earth and transmit navigation signals on three different frequencies: L1, L2, and 
L5. Of all the signals, the C/A-code signal on L1 is best known. All mass-market 
GNSS receivers make use of it and it is also the workhorse for professional and 
scientific applications. Originally, the C/A-code signal was forseen for acquisition 
of the P(Y) code. 
The C/A-code signal utilizes the CDMA scheme and the pseudorandom noise 
(PRN) code sequences are Gold sequences 1 ms in length at a chipping rate of fc = 
1.023 Mchip/s employing the BPSK modulation scheme. Details of the signal can 
be found in [1].
A baseband model of the signal is given by a convolution of the PRN code se-
quence cn with the single-chip waveform p∞(t) 
	
( )
(
)
n
c
n
c
t
c p
tf
n
¥
¥
¥
=-¥
=
-
å
	
(1.33)
The elements of the spreading code sequence cn assume values of –1 and +1 and 
the sequence is periodic with a period of NPRN = 1,023,
Table 1.2  Important Parameters of Exemplary Navigation Signals
Typical  
Tcoh (ms)
R¢¢–c,c(0)  (ms)–2
κ(ω)
GPS C/A
20
–21.37
(1.29) with Tcoh = 20 ms
Galileo OS Data
4
–76.59
(1.29) with Tcoh = 4 ms
Galileo OS Pilot
100
–87.58
(1.29) with Tcoh = 100 ms
Pulsed OS Pilot
100
–87.58
(1.29) with Tcoh = 4 ms
Gaussian Double Pulse
1
–0.005
(A.124)

12	
Radio Navigation Signals
	
PRN
n
n mN
c
c
m
+
=
ÎZ	
(1.34)
The navigation message amplitude d(t) assumes values of –1 and +1 and re-
mains constant over the 20-ms bit duration. Spreading code sequences and bits are 
synchronized. 
The signal chip waveform is given by
	
1
0
1
( )
0
otherwise
n
p
n
¥
£
<
ì
= í
î
	
(1.35)
As with any PRN code sequence, the C/A-code sequence can be modeled by 
a sequence of uniform distributed, binary (–1 and +1), and independent random 
variables with
	
,
n
m
n m
C C
δ
=
C
	
(1.36)
This model is only an approximation to the signal. Especially for short codes 
like the C/A code, significant deviations (nonvanishing cross-correlation and side 
autocorrelation peaks) may occur. However, (1.36) is useful because it allows a 
uniform treatment of the entire GPS C/A-code signal family, independent from the 
PRN code number. 
A filter affects the single-chip waveform and leaves the spreading code sequence 
untouched,
	
(
( ))
(
(
))
(
)
n
c
n
c
n
n
H c
t
c H p
tf
n
c p tf
n
¥
¥
¥
¥
=-¥
=-¥
=
-
=
-
å
å
	
(1.37)
The filtered single-chip waveform p(t) must be normalized to fulfill the require-
ment of Section 1.8.1. Using (1.36), the correlation function of the signal can be 
simplified as
	
,
1
1
,
1
,
,
1
,
1
1
0
1
1
( )
(
) (
)
(
)
(
)
1
(
)
(
)
1
(
) (
)
1
(
) (
)
1
(
L c
L
L
c c
m
c
n
c
m n
L
m
c
n
c
m n
L
n m
c
c
m n
L
c
c
n
t f
n
R
c t
c t
c p t f
m
c p t f
n
L
L
C p t f
m
C p t f
n
L
p t f
m
p t f
n
L
p t f
n
p t f
n
L
p t
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
δ
τ
τ
¥
=
=
=-¥
¥
=
=-¥
¥
=
=-¥
¥
=-¥
=
-
=
=
-
=
-
-
-
»
»
-
-
-
=
-
-
-
=
-
-
-
»
å
å å
å å
å å
å å
å
C
1
,
,
1
0
) (
)
( )
( )
L c
t f
L
c
c
p p
L c
p p
n
f
n
p t f
n
R
t f R
µ
µ
τ
τ
τ
-
=
=
-
-
-
»
=
å
å
	
(1.38)
and tL fc is the number of chips contained in the sampling interval.





17
17
C H A P T E R  2
Software-Defined Radio
This chapter revises the software-defined radio concept by providing definitions of 
terms; it shows the connections between GNSS software radios and developments 
in the communications area. GNSS software radio applications are presented and it 
is argued that software radios are suitable for high-end GNSS receivers. 
2.1  Definitions
A (true) software radio is a radio consisting of an antenna, an ADC/DAC, and 
a programmable unit (processor) that runs a piece of software. In contrast, a 
software-defined radio (SDR), generally, is a design principle to realize one or more 
components of a radio in a configurable manner. In the extreme case, the term SDR 
can be applied to radios that support different standards by sharing the same hard-
ware unit (or software modules) but running them with different parameter sets 
[such as parameter-controlled SDR (PaC-SDR)].
Both radio design methods emphasize the inherent flexibility of software com-
pared to hardware to reduce development efforts and maintain a certain level of 
flexibility and compatibility in the radio or to realize complex operations efficiently 
[e.g., a handover between different protocols such as the global system for mo-
bile communication (GSM) and the universal mobile telecommunications system 
(UMTS)]. As a drawback, SDRs often place higher requirements on the underlying 
hardware in terms of power consumption and processing performance compared 
to the radio as an application-specific integrated circuit (ASIC). 
J. Mitola presented the software-radio idea to a broad community in 1995. 
Mitola had previously worked on increasing flexibility and interoperability of radios 
[1]. A comprehensive summary of SDR, including origins, drivers, and perspectives, 
was published by Tuttlebee in [2]. Recent aspects of network and user administration 
that explain flexible mobile communication networks are covered in [3]. These in-
clude adaptive protocol layers, organization of different services, security aspects, in-
telligent (cognitive) radios, spectrum pooling, and automatic modulation detection.
A key characteristic of SDR techniques is the mixture of classical radio technol-
ogy (e.g., modulation, demodulation, and channel estimation) and modern, mostly 
object-oriented, software techniques. The hardware of a SDR is required to have 
increased flexibility for it to be compatible to the SDR software, which follows 
standards and procedures that mimic the functionally of classical radios. 
SDRs can be created using different hardware technologies. The lowest levels 
of a SDR, which include an antenna and an amplifier, do not differ from conven-
tional hardware radios. At the next level, a SDR might directly digitize the received 
RF broadband signal, or it may first downconvert and filter it before carrying out 

18	
Software-Defined Radio
digital sampling. It is known that for direct sampling of a broad frequency band 
(e.g., 0.8–2.2 GHz, which contains all digital civilian mobile phone communica-
tion standards) not only is a high sampling rate (e.g., 4.4 GHz) required, a high bit 
resolution to control signal dynamics of all signals in the frequency range is also 
required. Assuming a constant sampling rate, the ADC-bit resolution increases by 
1.5 bits every 8 years [4]. It is therefore expected that in future SDRs, only limited 
parts of the RF spectrum will be sampled [3]. Furthermore, power consumption of 
the ADC and of the subsequent signal-processing units would increase dramatically 
if they had to operate for a very broad frequency band.
After the signal has been converted to its digital form, it is processed by the 
radio. Digital signal-processing elements in a SDR exist in configurable ASICs, field-
programmable gate arrays (FPGAs), digital signal processors (DSPs), and general 
purpose processors (GPPs). Note that this work focuses on the receive function of a 
radio, but that the discussion also applies to the transmission path if the data flow 
is reversed.
Reconfigurable ASICs are related to the technique called PaC-SDR. For PaC-
SDR, several communication standards are investigated with respect to their 
similarities and differences. Common algorithms are designed, which can then be 
configured using different parameter sets to work for the investigated communi-
cation standards. These algorithms might then be realized as ASICs or software 
modules. PaC-SDR implies that the standards under consideration do not differ 
completely. PaC-SDR can be considered as the least flexible form of a SDR as in-
field software updates are not possible. In contrast, modular SDR (Mod-SDR) is 
a technique to run the required algorithms as software modules on exchangeable 
hardware (i.e., on a processor or on FPGAs). This not only allows reconfiguration 
of the algorithms with different parameters, but also allows complete reorganiza-
tion or updating of the algorithm. The main problem with Mod-SDR is that the 
software and the underlying hardware need to be compatible. Wiesler discusses 
three methods to run Mod-SDR software [5]: 
There exists a standardized hardware platform including compilers and li-
braries. The compiler directly generates binary code for this platform stan-
dard. The software is developed specifically for this platform and can be easily 
downloaded. The disadvantage is that hardware manufacturers have to follow 
this standard strictly and cannot incorporate their own code or hardware.
The compiler generates generic code (similar to the case for JAVA compil-
ers) and the hardware manufacturers provide a translator from the generic 
code to the binary code of the platform. This allows more freedom for the 
hardware manufacturers in their hardware development. On the other hand, 
standardization is still required at the level of the generic language. It is also 
known that directly generated binary code often runs faster than translated 
code, which is important for real-time radio applications.
Every hardware manufacturer develops its own software specifically for its 
own hardware radio. There exists no SDR standard, which maintains com-
petitiveness among different manufacturers and protects their intellectual 
property. Software updates are performed primarily when upgrading to new 
standards or when errors have to be corrected. 
1.
2.
3.

2.2  Communication Radios	
19
In the context of GNSS SDR, the third solution dominates although some ef-
forts have been undertaken to realize a GNSS radio under the JTRS SCA [6] or 
as a GNU radio [7]. It is also known that GNSS SDRs often serve as prototype 
platforms for later ASIC designs or the investigation of different signal-processing 
algorithms. The use of prototype SDRs is common in research and development 
but is usually not relevant for deployed radios. Overall, the term SDR covers an 
enormous number of techniques.
2.2  Communication Radios
A vast number of communication software radio implementations exist because the 
often small bandwidth of a communication channel allows for an efficient compu-
tational implementation on a DSP. The examples in Sections 2.2.1 and 2.2.2 pro-
vide insight into the underlying architecture of high-complexity software radios:
2.2.1  GNU Radio
GNU Radio is an open-source project consisting of a library of signal-processing 
blocks written in C++ and Python scripts used to connect the signal-processing 
blocks [8]. The GNU radio software runs on the PC platform under various operat-
ing systems. The Universal Software Radio Peripheral (USRP) is a dedicated front-
end hardware, and allows receiving and transmitting radio signals in the frequency 
range from direct current (DC) to 2.9 GHz [9]. The USRP can be connected to the 
GNU radio running on the PC via a USB 2.0 connector. The GNU radio project 
started in 1998 as a toolkit for learning about, building, and deploying SDRs. It is 
currently an official GNU project. 
The C++ building blocks process an infinite stream of data flowing from their 
input ports to their output ports. A building block can, for example, implement an 
FIR filter or perform FM demodulation. Some building blocks connect to hardware 
like the PC speaker, microphone, or screen on the user side, or to the USRP on the 
RF side. The Python script defines the sample rate of the radio, selects the C++ 
building blocks, and defines the connections between the building blocks. 
Because the GNU Radio project provides full source-code access, new applica-
tions can be developed with relative ease. However, the software does not follow 
any industry standards and seems to focus on the research sector. GNU Radio ap-
plications are numerous and include an HDTV receiver. The USRP includes a small 
FPGA, which performs minor tasks (e.g., digital upconversions and downconver-
sions) on the FPGA instead of on the PC.
Initial attempts have been undertaken to process GPS signals with the GNU Ra-
dio [7]. A GLONASS receiver has been developed that uses the USRP as a front end 
but uses its own software framework [10].
2.2.2  Joint Tactical Radio System
The largest field of application for SDRs is currently in the military domain. Apart 
from reduced development costs and increased flexibility, a military SDR approach 

20	
Software-Defined Radio
offers the possibility of reprogramming radios in the field, allowing changes in cryp-
tographic methods to be performed easily. Of importance is the potential to form 
ad-hoc networks in the field that allow the exchange of various data (e.g., speech, 
text, maps) between soldiers and the command center.
Several programs exist in different nations to replace legacy radios with SDRs. 
Due to the size of those programs, great efforts have been undertaken to standard-
ize and coordinate the development efforts. The US Department of Defense (DoD) 
program Joint Tactical Radio System (JTRS), briefly introduced in Section 2.3, is 
based on the work of the Joint Program Executive Office for the JTRS [2, 11]. It is 
important to note that other programs exist as well [12].
The JTRS program was initiated in early 1997 to replace existing legacy radios 
in the DoD inventory. It evolved from separate radio replacement programs to an 
integrated effort to network multiple weapon system platforms focusing especially 
on the last tactical mile. JTRS is intended to link the global information grid (GIG) 
to the military personnel. This goal would be achieved by developing a family of 
interoperable SDRs that operate as nodes in a network to ensure secure wireless 
communication and networking services for mobile and fixed forces.
Within the context of JTRS, waveform is a technical term of importance. A 
waveform is the entire set of radio and communication functions that occur from 
the user’s input to the radio frequency output and vice versa. A JTRS-waveform 
implementation consists of a waveform application code, radio set devices, and 
radio system applications. Originally, there were 32 JTRS waveforms; that num-
ber has been reduced to nine: Wideband Networking Waveform (WNW), Soldier 
Radio Waveform (SRW), Joint Airborne Networking–Tactical Edge (JAN-TE), 
Mobile User Objective System (MUOS), Single Channel Ground and Airborne Ra-
dio System (SINCGARS), Link-16, Enhanced Position Location Reporting System 
(EPLRS), HF, and UHF SATCOM [13]. The JTRS also considered different form 
factors that are defined as the linear dimensions and configuration of a device.
The JTRS program tries to exploit key SDR elements to achieve the develop-
ment of the system within the allocated budget. The key element—government-
purpose rights—ensures software reusability among different product lines. This is 
achieved partly by the JTRS information repository, which is available to industry 
vendors. Currently, it consists of 3.5 million lines of code, including 15 waveforms 
and two operating environments. 
The next key element—the open-systems architecture approach—focuses on an 
overarching systems-engineering model. This model directs performance, design specifi-
cations, and standards for the operation of the system. It is based on the freely available 
software communication architecture (SCA) [13]. The SCA is based on a standardized 
operating environment implementing portable operating system interface (POSIX) and 
middleware (software that ties together other software blocks) implementing the Com-
mon Object Requesting Broker Architecture (CORBA) standard. 
The key feature, as shown in Figure 2.1, is that the receiver is a multiprocessor 
system. The software communications architecture (SCA) requires the underlying 
operation of the system to realize POSIX application programming interfaces (APIs) 
between the operating system and the applications. The communication of different 
parts of the software (objects) running on different processors (GPPs, DSPs, and 
FPGAs) is of the utmost importance. This is facilitated by the CORBA middleware. 


22	
Software-Defined Radio
SCA. However, investigations to implement the GPS waveform under the SCA are 
underway [6].
2.3  GNSS Software Receivers
The idea of a GNSS SDR gained broad attention with the Ph.D. thesis of D. Akos 
[15]. In that work, the core concepts were implemented and 30 seconds of GPS data 
was processed until a SPS position fix was achieved. To demonstrate the flexibility, 
GLONASS signals were successfully acquired and tracked. 
The work by Akos performed all the signal processing in the postprocessing 
mode, but soon thereafter a real-time implementation was achieved on a DSP and 
on a general-purpose PC [16].
There are many pieces of software from different research groups which do 
one part (e.g., fast Fourier transform (FFT) acquisition of CDMA signals) or all 
of the GNSS processing in postprocessing and do not claim to be a SDR [17]. 
Because of the inherent flexibility of SDR, it is difficult to give a precise definition 
for a GNSS software radio. For example, a GNSS receiver always has a proces-
sor that is responsible for the user interface and the position, velocity, and time 
(PVT) calculation. Often this processor is used for tracking-loop control. In con-
trast, simple communication receivers (e.g., an FM radio) can be built without any 
programmable elements. In a strict sense, even very old GPS receivers were SDRs 
because at least one programmable element was involved. Additional confusion 
arose because GNSS receiver prototyping is commonly done using an FPGA for sig-
nal correlation. Whereas this approach clearly uses a SDR, within the GNSS com-
munity there is a tendency to call only an operational DSP/GPP receiver a software 
receiver. 
Within this work, we define a GNSS software receiver as a real-time (capable) 
GNSS receiver that does all the signal processing after downconversion and sam-
pling on a general-purpose processor. This processor can either be part of an em-
bedded platform or part of a standalone computer. Eventually, some small part of 
the signal conditioning (e.g., IF filtering or sample rate reduction) can be done by 
a programmable logic device (PLD) or FPGA. In contrast if the major part of the 
signal correlation is done in an FPGA, then it shall be called an FPGA receiver. If 
the signal correlation is done on an ASIC, the receiver will be called a hardware 
receiver. Furthermore, we use the terms receiver and radio synonymously. 
2.3.1  Front Ends
From the very beginning of GNSS software receivers, the software development was 
accompanied by dedicated front-end development. As pointed in an earlier article, 
three types of software receiver front ends emerged, which are distinguished by 
their hardware interfaces [18]:
­USB 2.0 front ends, mostly for the PC sector, see Figure 2.3;
­Front ends with proprietary (e.g., serial SPI, SSP) interfaces at the digital- 
signal level for the embedded sector;

2.3  GNSS Software Receivers	
23
­Front ends using COTS ADC converters using their own interface or industry 
standards such as PCI or PCI64.
The number of frequencies, the bandwidth of the sampled frequency bands, the 
sample rate, and the number of ADC bits influence, to a large extent, the architec-
ture of the software receiver. This is mainly because, with an increasing amount of 
incoming data, the processing power requirements and IF sample interface specifi-
cations change. On the other hand, several front-end architectures such as (super) 
heterodyne, direct baseband, low-IF, and direct-RF sampling have been used in 
conjunction with GNSS software receivers, but the influence of the front-end archi-
tecture on the software is rather low. It is essentially sufficient to adapt the IF within 
the software and eventually work with complex (I/Q) or real (I) input samples.
A good front-end design is crucial to achieving high receiver performance be-
cause analog design mistakes can often not be compensated by the processing soft-
ware. Good front ends are, of course, also required for hardware receivers. The 
only difference between a hardware receiver and a software receiver front end is 
that the software receiver tries to keep the sample rate as low as possible to reduce 
the computational load. Typically, the sample rate is chosen slightly above or even 
below the Nyquist rate, as will be discussed in Section 6.5. In contrast, the hard-
ware receiver might use a higher sample rate to achieve, for instance, a small corre-
lator spacing. For example, a sample rate of 16 MHz for a GPS C/A-code hardware 
receiver allows a correlator spacing down to 0.064 chip, whereas a sample rate of 
4 MHz limits the spacing to 0.25 chip (assuming that different correlators are ob-
tained by shifting the generated PRN code signal by one sample).
To illustrate typical front-end designs for software receivers, consider the four 
types of front ends whose key parameters are listed in Table 2.1. The first is used 
for an embedded system focusing on mass-market applications. The second is a 
research and development USB-based front end for L1 signals. The third has been 
partly specified at the University FAF Munich and is designed for a GNSS refer-
ence station receiver. The fourth is a flexible signal analysis system (created as a 
laboratory setup at the University FAF Munich) that is able to receive two L-band 
frequency bands with arbitrary center frequencies.
The information gathered for the embedded system is based on commercial 
information, and it should be noted that no specification of the IF filter could be 
found [22]. In fact, the data sheet states that the IF filter order should be tailored 
Figure 2.3  Different software receiver front ends, all with USB connectors, from left: embedded 
[19] (copyright Maxim Integrated Products), R&D L1 [20] (copyright IFEN GmbH), and reference 
station GNSS receiver [21]. (Copyright Fraunhofer IIS; all images reprinted with permission.)

24	
Software-Defined Radio
to the specific application and that, for example, a standalone GPS receiver will not 
require stop-band attenuation as strong as that required by a GPS receiver for an in-
tegrated wireless handset [19]. Furthermore, the spectral purity [i.e., the maximum 
height of spikes within the IF power spectral density (PSD)] has not been verified 
experimentally.
The embedded system uses two downconversion stages to bring the GPS L1 
signal down to 3.78 MHz. Eventually, this allows for the use of a wider range of ref-
erence oscillator frequencies compared to a single downconversion stage. It includes 
a SPI serial interface. The SPI is a de facto standard; many processors for embedded 
systems include SPI controllers. 
The R&D L1 front end converts the RF to the IF of 96 MHz in a single step 
and then uses bandpass sampling to further downconvert it to 4.348 MHz [20]. The 
sampled IF signal is buffered before transfer over the USB port. 
The reference station front end uses a heterodyne architecture. Each RF fre-
quency band is (separately) downconverted to 53.8 MHz. A discrete bandpass filter 
limits the bandwidth before sampling and a real-valued IF signal is digitized. The 
front end uses a 2- or 4-bit ADC. It has been demonstrated that the 4-bit ADC pro-
vides a significant performance gain if interference is present by being less sensitive 
to saturation effects.
The highest flexibility can be achieved with a laboratory setup consisting of a 
commercial ADC card (an ICS-572B is used here) with commercial off-the-shelf 
(COTS) mixers and local oscillators. The components are connected through 
SMA connectors. COTS mixers and low-noise amplifiers (LNAs) are available up 
to frequencies of several GHz. The RF is downconverted to a selectable IF with 
a single mixer. The ADC Nyquist bandwidth is 52.5 MHz. COTS lowpass fil-
ters are used to discard higher-frequency components. The design requires that 
the antenna LNA already includes an RF filter to suppress the image frequency 
Table 2.1  Front-End Parameters and Performance Figures
Name
Embedded
R&D L1
Reference Station
Signal Analysis  
System
Architecture
Superheterodyne
Heterodyne
Low IF
Heterodyne
Final IF
3.78 MHz
4.348 MHz
53.8 MHz
1–25 MHz
Number of bands
1
1
3
2
Carrier frequency
L1
L1
L1, L2, L5
1–4.2 GHz
Bandwidth
< 3 MHz
10 MHz
13 or 18 MHz
See text
Sample rate
6.5 MHz
23.104 MHz
40.96 MHz
105 MHz
Internal buffer
—
32 MB
None
64 MB
Number of bits
1.5–2.5
1.5
2 or 4
14
Filter characteristic
Discrete L/C  
or SAW, ceramic
Active discrete
Discrete  
(Bessel type)
—
Spectral purity
—
< 2.5 dB
< 1 dB
Generally worse
Gain
32–83 dB
36–106 dB
40–90 dB
24 dB
Noise figure
4.7 dB
> 1.6 dB
1.3 dB
2.5 dB
Analog stability
—
High
High
Low
Oscillator
TCXO/crystal
TCXO
TCXO/external
External
IF sample interface
Serial (SPI, SSP)
USB 2.0
2 × USB 2.0
PCI64

2.3  GNSS Software Receivers	
25
at RF-2xIF. Furthermore, the experimental setup does not give a completely clean 
digital IF signal and several spikes appear. The high number of bits results in a 
high dynamic range of over 80 dB, making the system well suited for interference/ 
jamming applications.
When comparing the four front ends, one clearly sees the increase in the num-
ber of frequency bands, bandwidth, bits, and sample rate from the embedded solu-
tion to the signal analysis system. The noise figure is best for the reference station 
front end, but it should be emphasized that the total receiver noise figure is mostly 
determined by the low-noise amplifier (LNA) that is either integrated into the an-
tenna or located directly behind the antenna. The noise figure of the front end is less 
important. All four front ends sample a real signal. This avoids the use of a second 
ADC and simplifies the data transfer.
2.3.2  Illustrative Applications
Sections 2.3.2.1 through 2.3.2.4 will present applications where GNSS SDRs have 
already been established. Software receivers are excellent teaching tools; two books 
have already been published on this topic [23, 24].
2.3.2.1  ASIC Replacement
The most obvious application of a GNSS SDR receiver is to replace existing hard-
ware chip solutions. For laptops/mobile phones/PNDs (or in general, for embedded 
systems), there already exists laboratory software as well as commercial solutions. 
Software-GPS-enabled laptops have been on the market since 2008 [25].
On an embedded system or, more specifically, on a mobile phone or personal 
navigation device (PND), a general-purpose processor is available. Therefore, the 
possibility exists to run a GNSS SDR on this processor. The advantages are that a 
GNSS baseband chip can be avoided and that the GNSS receiver interacts more 
flexibly with other software on the same system. Provision of GNSS-aiding data via 
the mobile phone data link, for example, is more easily achieved. Also, integration 
with other sensors (e.g., WLAN) or any other user software provides potential ad-
vantages in obtaining an integrated position solution. The GNSS software can later 
be upgraded for upcoming systems and services. An RF front end and an antenna 
are still required and have to fulfill the same requirements as a hardware receiver. 
The disadvantages of a software solution compared to a hardware solution include 
increased processing load and power consumption.
Some design ideas exist for creating a complete GNSS SDR as an embedded 
system, where a dedicated processor not running the application software is used 
for the GNSS functions; that is, the GNSS SDR has the same form factor as a hard-
ware receiver. The processor basically replaces the baseband chip. The module itself 
provides the same interfaces as a hardware receiver, but retains SDR flexibility.
The most critical issues for a SDR embedded receiver are the limited resources 
in terms of processing power, memory size, and memory bandwidth. Commercial 
solutions such as SiRFSoft are explicitly optimized for market-leading platforms 
like the Intel XScale [26]. Those platforms provide dedicated instructions to speed 
up signal-processing algorithms, like multiply-and-add commands. There are also 


2.3  GNSS Software Receivers	
27
side GPS receiver has a very short TTFF and is capable of tracking the high signal 
dynamics.
An asset (e.g., container or car) tracking system could periodically record small 
portions of IF samples that are temporarily stored in a nonvolatile memory. At some 
point, the data is transferred to a PC that runs the server-side radio. By utilizing 
ephemeris data and navigation data bits, the server-side radio can do a data wipe-
off to increase the acquisition sensitivity. Depending on the duration of the sample 
snapshot, even high positioning accuracy can be obtained. A related mass-market 
application could be to localize images shot by a digital camera. The IF samples 
would then be stored with the image [32].
It should also be noted that all receiver performance parameters, such as sen-
sitivity, accuracy, and availability can be perfectly optimized if a GNSS signal is 
recorded and processed in a postprocessing manner. For example, in postprocessing 
mode, an unlimited number of correlators can be used.
2.3.2.3  GNSS Reflectometry
One of the applications where GNSS SDRs have gained much merit is in the area 
of bistatic remote sensing. In this case, the GNSS signal is reflected by the earth’s 
surface and is received by a receiver mounted on various platforms, ranging from a 
tower over an airplane to space-borne receivers. The usefulness of these signals was 
realized over a decade ago when scientists proposed a new method of ocean altim-
etry [33]. Meanwhile, the method has been adapted to measure sea roughness, wind 
speed and direction, ice coverage, and soil moisture and has additional potential 
applications in other remote-sensing areas.
In the case of a space-borne receiver, the bistatically scattered signal is diffusely 
radiated from a large area of the earth’s surface, often covering tens of kilometers 
and thousands of Hertz in Doppler as the observation geometry changes over the 
scattering surface or glistening zone [34]. The receiver tracking the reflected sig-
nal has to correlate over a wide code phase and Doppler range involving a mul-
titude of correlators. Furthermore, the reflected signals are attenuated and show 
strong amplitude fluctuations, such that high-end signal processing is generally 
required.
Table 2.2  Server-Side GNSS Radio Applications
Name
Performance  
Measure
Aiding Data  
Utilization
SDR Advantage
Missile tracking
TTFF
Ephemeris, coarse PVT
High dynamics
Snapshot for E911
TTFF, accuracy
Ephemeris, coarse PVT
Reduced mobile unit  
complexity
Asset tracking, image 
tagging
Sensitivity
Ephemeris, navigation  
data bits
Increased sensitivity,  
reliability, low power 
consumption
GNSS science
—
All
Realization of new  
algorithms
Signal post processing
Sensitivity, accuracy, 
availability
All
Highest possible  
performance

28	
Software-Defined Radio
The United Kingdom’s Disaster Monitoring Constellation satellites are exam-
ples of a SDR implementation for remote sensing [35]. These satellites normally use 
two GPS antennas for rapid positioning. For remote sensing, a third antenna (an L1 
high-gain, down-looking, left-handed polarized antenna) was added. The IF signal 
of the down-looking antenna was sampled with a rate of 5.71 MHz and with 2 bits. 
The data was stored on an onboard, solid-state data recorder. About 20 seconds of 
data was sampled and later transmitted to the ground station for offline processing. 
The reflected signals have been detected and Doppler delay maps have been pro-
duced. The data is available for other researchers to ensure that the valuable signal 
is optimally analyzed [34].
2.3.2.4  GNSS Constellation Signal Generators and Spoofers
SDR technology can also be applied to generate GNSS signals in a flexible manner. 
To the author’s knowledge, all available GNSS signal generators that are able to 
simulate received GNSS signals of a whole satellite constellation use either FPGAs 
or GPPs to generate the signals. A GNSS software signal generator based on a 
GPP with RF output capability has been described by Pósfay [36]. The work [37] 
describes a GNSS signal recorder and playback system used to collect real signals 
(with traffic information) in the field and to play them back in the laboratory. 
Humphreys describes a GPS spoofer that simultaneously receives GPS C/A-code 
signals and transmits an adaptive spoofing signal. Both functions are created with 
SDR technology on a DSP basis [38].
2.3.3  High-End GNSS Software Receivers
This work endorses the use of GNSS SDRs as high-end receivers. This is an area 
where software receivers may gain increased importance in the future. New and 
optimized signal-processing algorithms may be more easily developed on these plat-
forms and current and future processor technology will provide an abundance of 
processing power. Software receiver developments are also discussed by the Inter-
national GNSS Service (IGS), an organization that generates precise ephemeris and 
terrestrial reference frames based on a network of permanent GNSS receivers [39].
Signal processing (acquisition and tracking) in GNSS chips commonly boils 
down to the evaluation of the cross-correlation function of the received signal with 
locally generated replica signals. Signal processing in a chip is limited by the follow-
ing factors (among others):
­A low number of bits are used to represent the received and the locally gener-
ated signal.
­The received signal is processed as a stream (e.g., older signal samples are not 
available for a reiteration).
­Development efforts are generally high.
­Inclusion of high-rate aiding data such as data wipe-off, (semi-)codeless 
techniques, or deep GPS/ INS integration requires explicit synchronization 
lines.

2.3  GNSS Software Receivers	
29
The GNSS signal and system design took into account these limitations. For 
example, the GPS signals at baseband can be represented by one bit. The cross- 
correlation among different signals is minimized so that a tracking channel can 
generally ignore the influence of PRN codes broadcast from satellites other than the 
one whose signal is being tracked.
However, these restrictions still limit the signal-processing capabilities of a 
GNSS receiver and those limitations become relevant if the receiver performance 
needs to be optimized. Currently, the receiver core technologies listed in Table 2.3 
have been identified as areas where improvements can still be expected. 
The presented limitations are not intrinsically hardware-receiver specific, but 
could be solved more easily with a software solution. A high-end GNSS SDR will 
run on a high-performance computer that generally consumes increased electrical 
power. If it is assumed that sufficient electrical power is available (e.g., via a power 
line), then a high-performance computer can provide nearly unlimited processing 
power for the radio, simply by using multiple processors or cores. Because these 
computers are equipped with large storage devices (RAM or hard discs) they over-
come nearly all deficiencies mentioned in Table 2.3. This work proposes algorithms 
that exploit this increased processing power and demonstrates how the resulting 
GNSS SDR outperforms an ASIC-based solution.
Table 2.3  Current High-End Hardware GNSS Receiver Deficiencies
Technology
Measure
Hardware Receiver Deficiency
Acquisition
Sensitivity
Still a low number of correlators are used, lack of 
proper interference handling, no data wipe-off, short 
(  20 ms) coherent integration times
Tracking
Multipath error
Generally suboptimal multipath-mitigation techniques 
are used and multipath reflections are not tracked
Thermal noise error
No data wipe-off, independent channel tracking used  
(no vector tracking), locally generated signal not  
band-limited
Transient errors
No reiteration of signal correlation to follow high  
dynamic signals
Interference
Only crude interference mitigation (e.g., pulse blanking) 
used, no adaptive filtering, no cancellation
GPS C/A-cycle slips
Short (  20 ms) coherent integration times, no data  
wipe-off, thus Costas discriminators are used
GPS/INS integration
Ultratight coupling seldom used due to high  
implementation and synchronization efforts, loose or 
close coupling schemes predominate; coherent  
integration is based on a constant line-of-sight velocity, 
ignoring user accelerations
Positioning
TTFF
TTFF is long if no aiding data is used
Accuracy
Propagation channel characteristics (e.g., multipath 
parameters) not used in positioning solution
Carrier phase
Double differences are formed with carrier phase  
pseudoranges; less cycle slips are expected if double  
differences are formed with correlator values
Signal Level
Interference
Interference is normally neither detected nor mitigated
Flexibility
Inclusion of new navigation signals is generally difficult
Reliability
Signal-processing problems (e.g., cycle slips, loss of 
lock) cannot be traced back because the input signal is 
discarded after processing

30	
Software-Defined Radio
Recent developments in ultramobile PCs will allow high-end GNSS signal- 
processing algorithms to run on a platform with reduced power consumption. Ul-
tramobile PC components form the basis for the innovative real-time kinematic 
(RTK) receiver concept discussed in Chapter 10.
2.4  Technology Evaluation and Discussion
Previously, it was demonstrated that no clear separation between a hardware re-
ceiver and software receiver could be drawn. Important parts of the signal process-
ing (e.g., tracking-loop closure) are often part of the receiver software (firmware) in 
a typical GPS-chip solution. The chips may even utilize small processors to calculate 
an FFT to acquire signals. On the other hand, software-GNSS radios utilize dedi-
cated hardware units to accelerate the signal processing. This may range from vec-
tor multiply-and-add units of high-performance processors to FPGAs. These units 
often have a strict structure and the software utilizing them has to be optimized 
specifically for them. Consequently, the GNSS SDR gives up some of its flexibility.
The distinction between a software and hardware receiver seems not to be very 
helpful. However, the amount of work a receiver manufacturer puts into develop-
ing the receiver hardware platform is important. This may range from a developer 
choosing a good laptop, to building his own CPU board, to finally designing an 
ASIC. The hardware platform determines important real-time performance pa-
rameters like size, power consumption, and number of correlators. If only COTS 
components are used (e.g., a low-end PC), these parameters are normally far from 
optimal. On the other hand, wisely chosen processors integrated into an optimized 
board may outperform classical ASIC correlator chip solutions for certain applica-
tions. However, developing a multiprocessor system may require similar efforts to 
that of an ASIC design.
At the moment of writing, it is expected that SDR solutions based on COTS 
components will continue to have some disadvantages in terms of size and power 
consumption; these criteria are relevant for many positioning applications. COTS 
software receivers will enter the market at the high-performance sector as reference 
stations and in niche markets, like specialized RTK receivers. Because the receiver 
life cycle is typically several years in the field of navigation, the GNSS SDR technol-
ogy will be mature when Galileo reaches its final operational capability. We also 
expect that DSP or embedded processor-based solutions will be found in mass- 
marketed products in the coming years.
References
  [1]  Mitola, J., “The Software Radio Architecture,” IEEE Commun. Mag., Vol. 33, No. 5, 
1995, pp. 26–38.
  [2]  Tuttlebee, W., Software Defined Radio: Origins, Drivers and International Perspectives, 
New York: Wiley, 2002.
  [3]  Rhiemeier, A.-R., Modulares Software Defined Radio, University Karlsruhe (TH), Kaiser-
straße 12, D-76131 Karlsruhe, http://digbib.ubka.uni-karlsruhe.de/volltexte/1000001174, 
2004.

2.4  Technology Evaluation and Discussion	
31
  [4]  Walden, R. H., “Analog-to-Digital Converter Survey,” Areas Commun., Vol. 17, No. 4, 
1999, pp. 539–550.
  [5]  Wiesler, A., Parametergesteuertes Software Radio für Mobilfunksysteme, University Karl-
sruhe (TH), Kaiserstraße 12, D-76131 Karlsruhe, http://digbib.ubka.uni-karlsruhe.de/ 
volltexte/3222001, 2001. 
  [6]  Brown, A., and D. Babich, “Implementing a GPS Waveform Under the Software Com-
munications Architecture,” Proc. 19th Int. Technical Meeting of the Satellite Division of 
the Institute of Navigation (ION-GNSS) 2006, Fort Worth, TX, September 26–29, 2006, 
pp. 2334–2345.
  [7]  Danielsen, T., “Creating a GNSS Receiver From Free Software Components,” Proc. 20th 
Int. Technical Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 
2007, Fort Worth, TX, September 25–28, 2007, pp. 2731–2741.
  [8]  Blossom, E., “Exploring GNU Radio,” Free Software Foundation, http://www.gnu.org/
software/gnuradio/doc/exploring-gnuradio.html, 2004.
  [9]  Ettus Research, “Homepage of Ettus Research,” Ettus Research LLP, http://www.ettus.
com, 2007.
[10]  Peng, S., and B. M. Ledvina, “A Real-Time Software Receiver for the GLONASS L1 Sig-
nal,” Proc. 21st Int. Technical Meeting of the Satellite Division of the Institute of Naviga-
tion (ION-GNSS) 2008, Savannah, GA, September 16–19, 2008, pp. 2268–2279.
[11]  Joint Program Executive Office for the Joint Tactical Radio System, “Joint Tactical Radio 
System,” U.S. Department of the Navy, http://jpeojtrs.mil/, 2007.
[12]  Finish Defense Forces, “Finish Software Radio Project,” Finnish Defense Forces Telecom-
munication Laboratory and Centre for Wireless Communications, http://www.mil.fi/laitok-
set/pvtt/fsrpbook.pdf, 2007.
[13]  Anderson, S., and S. A. Davis, “The Joint Tactical Radio System—Reloaded,” CHIPS - 
the Department of the Navy Information Technology Magazine, Vol. July–September, No. 
2006, pp. 6–9.
[14]  Bard, J. D., “Joint Tactical Radio System,” Space Coast Communication Systems, Inc., 
http://www.spacecoastcomm.com/docs/JTRS.pdf, 2003.
[15]  Akos, D., A Software Radio Approach to Global Navigation Satellite System Receiver 
Design, Athens, OH: Ohio University, 1997.
[16]  Akos, D. M., et al., “Real-Time GPS Software Radio Receiver,” Proc.  Institute of Navi-
gation National Technical Meeting (ION-NTM) 2001, Long Beach, CA, January 22–24, 
2001, pp. 809–816.
[17]  Cheng, U., W. J. Hurd, and J. I. Statman, “Spread-Spectrum Code Acquisition in the Pres-
ence of Doppler Shift and Data Modulation,” IEEE Trans. Commun., Vol. 38, No. 2, 
1990, pp. 241–250.
[18]  Pany, T., J.-H. Won, and G. Hein, “GNSS Software Radio, Real Receivers or Just a Tool 
for Experts?” InsideGNSS, Vol. 1, No. 5, 2006, pp. 48–56.
[19]  Maxim Integrated Products, “MAX2741, Maxim Integrated L1-Band GPS Receiver 
(19-3559; Rev 0),” Maxim Integrated Products, Inc., http://www.maxim-ic.com/products/
wireless/gps/max2741.cfm?CMP=490, 2005.
[20]  IFEN GmbH, “NavX®-NSR - GPS/Galileo Navigation Software Receiver, Brochure,” 
IFEN GmbH, http://www.ifen.com/content/flyer/NavX-NSR-Flyer.pdf, 2007.
[21]  Fraunhofer Institut für Integrierte Schaltungen, “Triband Frontend L1, L2 and L5 with 
USB,” Fraunhofer Institut für Integrierte Schaltungen, http://www.iis.fraunhofer.de, 2008.
[22]  NXP Software, “swGPSTM Personal, Software GPS solution for PNDs, PMPs and smart-
phones,” NXP Software, http://www.software.nxp.com/assets/Downloadablefile/swGPS-
personal_vs3-13467.pdf, 2007.
[23]  Tsui, J. B. Y., Fundamentals of Global Positioning System Receivers: A Software Approach, 
2nd ed., New York: Wiley, 2005.

32	
Software-Defined Radio
[24]  Borre, K., et al., A Software-Defined GPS and Galileo Receiver: A Single Frequency Ap-
proach, Boston, MA: Birkhäuser, 2007.
[25]  PR Newswire, “ASUS Selects NXP Software’s swGPS™ for World’s First Mainstream 
GPS-Enabled Notebook PC,” http://www.prnewswire.com/cgi-bin/stories.pl?ACCT= 
109&STORY=/www/story/09-13-2007/0004662288&EDATE=, 2008.
[26]  SiRF Technology, “Company homepage,” SiRF Technology, Inc., http://www.sirf.com, 
2008.
[27]  Fastrax, “White paper on Fastrax Software GPS receiver: Smart Positioning with Fastrax 
Software GPS Receiver,” Fastrax, Ltd., http://www.fastraxgps.com, 2008.
[28]  CSR plc, “LC7830FM: CSR’s combined solution for GPS and FM,” CSR plc, http://www.
csr.com, 2008.
[29]  Trimble Navigation, Ltd., “Trimble News Release: Trimble and u-Nav Offer High Per-
formance, Low Power GPS Chipset Solutions, TrimCore NEu,” Trimble Navigation, Ltd., 
http://www.trimble.com/news/release.aspx?id=030806a, 2006.
[30]  Brown, A., P. Brown, and J. Griesbach, “GeoZigBee: A Wireless GPS Wristwatch Tracking 
Solution,” Proc. 19th Int. Technical Meeting of the Satellite Division of the Institute of Navi-
gation (ION-GNSS) 2006, Fort Worth, TX, September 26–29, 2006, pp. 2883–2888.
[31]  Won, J. H., S. J. Ko, and J. S. Lee, “Implementation of External Aiding and Novel Pseudo-
range Generation Algorithms for Fast TTFF of GPS Translator System,” Proc. 12th GNSS 
Workshop, Jeju Island, Korea, December 1–2, 2005.
[32]  NXP Software, “NXP SnapSpot GPS Technology and JOBO photoGPS capture a location 
in an instant,” NXP Software, http://www.software.nxp.com/?pageid=139, 2007.
[33]  Martin-Neira, M., “A Passive Reflectometry and Interferometry System (PARIS)—Applica-
tion to Ocean Altimetry,” ESA Journal, Vol. 17, No. 4, 1993, pp. 331–355.
[34]  Gleason, S., “An Open Source Software Receiver for Bistatic Remote Sensing,” Proc. 20th 
Int. Technical Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 
2007, Fort Worth, TX, September 25–28, 2007, pp. 2742–2748.
[35]  Gleason, S., et al., “Detection and Processing of Bistatically Reflected GPS Signals from 
Low Earth Orbit for the Purpose of Ocean Remote Sensing,” IEEE Trans. on Geoscience 
and Remote Sensing, Vol. 43, No. 6, 2005, pp. 1229–1241.
[36]  Pósfay, A., T. Pany, and B. Eissfeller, “First Results of a GNSS Signal Generator Using a 
PC and a Digital-to-Analog Converter,” Proc. 18th Int. Technical Meeting of the Satellite 
Division of the Institute of Navigation (ION-GNSS) 2005, Long Beach, CA, September 
13–16, 2005, pp. 1861–1870.
[37]  Averna, The Test Engineering Company, “URT, Universal Receiver Tester,” Averna, Inc., 
http://www.averna.com, 2008.
[38]  Humphreys, T. E., et al., “Assessing the Spoofing Threat: Development of a Portable 
GPS Civilian Spoofer,” Proc. 21st Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation (ION-GNSS) 2008, Savannah, GA, September 16–19, 2008, 
pp. 2314–2325.
[39]  Humphreys, T. E., L. E. Young, and T. Pany, “Considerations for Future IGS Receivers,” 
Proc. American Geophysical Union Fall Meeting, San Francisco, CA, December 15–19, 
2008.

33
33
C H A P T E R  3
GNSS Receiver Structure and Dataflow
The architecture of a GNSS software receiver determines, to a large extent, the 
potential receiver applications; it is shaped by the underlying hardware capabilities. 
The envisaged processing modes (real-time and postprocessing) are important to 
the architecture as well as to the targeted-use cases, such as a standalone reference-
receiver operation, snapshot mode, or receiver development environment.
In this chapter, the receiver architecture of the ipexSR is outlined. It targets 
a real-time-capable, multifrequency GNSS receiver running under a nonreal-time 
operating system like Microsoft Windows. It exploits the capabilities of multicore 
CPUs by separating the tasks into several threads; it is prepared to accommodate 
external sensor data in addition to the GNSS signals. A screenshot of this software 
GNSS receiver is shown in Figure 3.1. Its real-time behavior will be described in 
Section 3.3.1 and performance results are included in Section 3.4.
The architecture of the receiver is governed by the receiver block diagram that 
describes the constituting receiver modules and the exchanged data. The execution 
diagram shows the timeline and the synchronization of the different operations 
performed by the receiver. The real-time requirement dictates, to a large extent, 
the data flow within the receiver. An optimal implementation of the receiver core 
operations, correlation, and FFT (described in Chapter 9) is achieved by grouping 
the GNSS samples in fixed-length units instead of processing them on a sample-
by-sample basis (as would be done using a hardware receiver). Because this GNSS 
sample arrangement influences the block diagram as well as the execution flow, it 
shall be described first.
3.1  GNSS Sample Handling
In the following section, the GNSS sample handling shall be described. The focus 
will be on the real-time mode. In addition, several possibilities for postprocessing 
shall be described. 
It should be mentioned that by counting the GNSS signal samples, the receiver’s 
internal time base is realized, which shall also be described below. 
For GNSS receivers, there exist several methods of how IF signal samples can 
be accessed by the signal processing unit. An overview is shown in Figure 3.2. In 
the simplest case, an incoming IF sample is processed immediately after its output 
by the ADC. 
This method is used in most hardware-based receivers that do not buffer the IF 
samples and have the possibility of processing the samples instantaneously within 
multiple channels (this implies, for example, that all code generators and correlat­
ors run at the ADC rate or faster). If the hardware receiver uses a massive parallel 


3.1  GNSS Sample Handling	
35
digitized samples are transferred to the processing platform running the software 
receiver. The platform sees the received signal as a continuous stream of samples. 
There may exist multiple synchronous streams of samples if multiple frequency 
bands are received (e.g., GPS L1 and L2). 
3.1.1.1  Timing
The streams are required to be synchronously derived from the ADC output; no 
sample must be lost when the data is transferred from the ADC to the processing 
platform. The ADC itself is required to be synchronized to the front-end oscillator, 
which also controls signal down conversion. As a consequence, the internal time base 
can be realized by counting the number of received GNSS signal samples. The inter-
nal receiver time is determined by a startup epoch value plus the number of received 
samples divided by the sample rate. The value of the startup epoch can, for example, 
be read from the PC clock, but can also be set to zero. If multiple streams are pres-
ent, then every stream can be used for time-based calculations because all streams are 
required to be synchronous. After reading the startup epoch, external clocks (like the 
PC clock) are no longer used and the internal time base is completely based on count-
ing the received samples. After a PVT solution is available, the receiver clock error 
is obtained; it estimates the difference between the GNSS time scale and the internal 
receiver time scale. It is composed of a constant part related to the startup epoch read-
ing and a time variable part related to the front-end oscillator stability. 
It should be noted that reading and adjusting the PC clock and establishing 
a relationship to the IF sample stream can be quite imprecise (e.g., on the order 
of several tenths of milliseconds under the Windows operating system due to the 
10-ms granularity of the Windows task scheduler). There exist special items of hard-
ware, such as an IEEE1588-enabled PCI network interface card, that allow sample 
synchronization down to 100-ns accuracy, provided that a hardware connection 
between the front end and the interface card is established [1]. If the IEEE1588 
time server is properly configured, the samples can be directly synchronized to a 
GNSS time scale without the necessity to compute a PVT solution. This could be 
important for indoor positioning, where precise synchronization with approximate 
coordinates can shrink the acquisition search space drastically. 
3.1.1.2  Batch-Processing
The GNSS sample streams are based on a relatively high sample rate being, at 
minimum, several megahertz. Because of overhead operations (loop control, data 
movement) direct processing of each single sample on a sample per sample basis is com-
putationally too demanding for real-time operations in a GNSS SDR (in contrast to 
hardware receivers based either on ASICs of FPGAs). Instead, the samples are grouped 
into units called batches. Certain processing parameters (e.g., NCO rates) are kept 
constant for all the samples in one batch. This approach is commonly called batch- 
processing. There exist several possibilities of what to call those batches; in the 
following, the terms packets and frames will be used. These terms do not have any 
specific meaning by themselves, but they distinguish several ways of how to group 
GNSS signal samples. They will be explained later.



38	
GNSS Receiver Structure and Dataflow
caused by the processing and the latency introduced when changing the output 
state (e.g., changing the pulse-per-second signal state from high to low). The 
error introduced by the extrapolation can be exactly evaluated (and consequently 
be minimized) because the receiver itself relies on assumptions on the signal dynam-
ics (e.g., tracking loop filter bandwidths or positioning Kalman filter settings). Also, 
hardware receivers have latencies of at least 1–20 ms caused by the tracking loop 
update only being performed after the coherent integration has finished [2].
The ipexSR is soft real-time capable. There is no hardware synchronization be-
tween the receiver output (e.g., the computers serial ports) and the GNSS front end, 
and it would not make much sense in changing the software to be hard real-time 
capable, a task that would require porting the source code onto a real-time OS.
3.1.2  Postprocessing Mode
In a postprocessing mode (or postmission mode) the GNSS signals are first recorded 
and stored on a hard disk and are later processed in a second step. Generally, post­
processing allows the implementation of more sophisticated algorithms because there 
is no time limit for the algorithm execution time. However, recorded GNSS signals can 
also be processed as if they were captured in real-time (like a replay mode), which is the 
mode implemented in the ipexSR. The postprocessing modes shall be described later.
3.1.2.1  Real-Time Like Processing
When the ipexSR processes record GNSS signals in a postprocessing mode, it sim-
ply reads the signals from the hard disk and subdivides them in the same way into 
packets and frames, as described in Section 3.1.1. A difference in the real-time op-
eration is given only by the possibility to configure processing modules in a way that 
other modules wait until a certain operation is completed. For example, the master 
receiver can be configured to pause its signal tracking until a signal acquisition fin-
ishes. No IF sample buffer (see Figure 3.4) is consequently required and obviously 
much more external data (like precise ephemeris data available several days after 
the actual measurement) can be used to aid the receiver.
3.1.2.2  Random Access
Postprocessing of GNSS signals has the potential to allow the implementation of 
completely different signal processing algorithms because, in principle for a given 
measurement period, all signal samples are available at once. This idea is nicely 
introduced by van Grass and is compared to sequential processing methods [3]. 
However, more sophisticated algorithms, as described by van Grass, are possible. 
In an extreme case, a direct solution of the MLE equations as described in Section 
4.2.3 or the method shown by Closas is imaginable [4]. Another example is snap-
shot positioning as described by Brown, where the position is estimated from a very 
short duration (< 1 second) piece of IF samples [5]. 
From the data-handling point of view, the distinguishing feature is that those 
algorithms have random access to the recorded signal samples and there is no need 
to group them into packets or frames. The time to access those samples is, however, 

3.2  Module Diagram	
39
orders of magnitude slower because that data has to be read from the hard disk if 
the signal duration under consideration is longer than a few seconds.
3.2  Module Diagram
The ipexSR architecture is described as a module diagram shown in Figure 3.4. The 
single modules have self-explaining names and are described in detail in the follow-
ing sections. A module is actually realized as a number of C++ classes. The ipexSR 
is a multithread program. Modules that are executed within the same thread have 
the same style in Figure 3.4. 
The data exchanged by the modules is described in Table 3.1. As the soft-
ware receiver is configurable, the number of modules and the number of threads is 
configuration-dependent. Specifically, the number of receiver modules in Figure 3.4 
depends on the configuration, and only for Receiver 1 in Figure 3.4 is the master 
channel/channel structure shown. All other receivers share the same structure, with 
the exception of the last receiver, which acts as a spectrum analyzer. 
The main data flow in the software receiver is as follows. The USB front-end 
driver collects the IF samples from the GNSS front end, groups them into packets 
and stores them in the IF sample buffer. The packets also contain data from external 
sensors captured within the same time span covered by the respective packet. The 
master receiver retrieves a packet from the IF sample buffer and passes it to the 
acquisition manager and the receivers. The acquisition manager, with the Level 1 
and 2 acquisition units, acquires the GNSS signals and the receivers track the GNSS 
signals. A dedicated receiver acts as an IF spectrum analyzer. Each receiver utilizes 
several master channels to track different satellites. Each master channel needs one 
Table 3.1  Data Types Occurring in Figure 3.4
Code
Description
1
USB microframes containing GNSS IF samples
2
Data from other sensors (PC clock reading, IMU measurements, 
barometric measurements)
3
Time-stamped packets of IF samples plus external sensor data; one 
packet contains data for time span of about 10–400 ms
4
Frame of preprocessed IF samples; one frame contains data for a 
time span less than the primary coherent integration interval (e.g., 
less than 1 ms for the GPS C/A-code)
5
Code phase or pseudorange, Doppler and visibility indicator of 
GNSS signals
6
Correlator values
7
Raw data (code and phase pseudorange, Doppler, C /N0, cycle slip 
flag, signal quality indicators, measurement accuracy)
8
Same as (7) plus time synchronized sensor data
9
Same as (8) plus position estimate
A
Decoded GNSS navigation messages, ephemeris data, clock  
corrections, atmospheric models, AGNSS data
B
GNSS correction data (differential corrections, data from a GNSS 
reference station or reference station network)
C
Position estimate from external source

40	
GNSS Receiver Structure and Dataflow
or two channels that do the correlation for the data and for the pilot signal com-
ponent. The master receiver retrieves from each receiver the pseudorange measure-
ments and passes them to the navigation processor. A PVT solution is calculated, 
verified, visualized, and output to other user applications. The most recent PVT is 
kept in memory (called receiver status) and is used to aid signal acquisition (e.g., 
Doppler prediction) and tracking (e.g., vector tracking).
In the following subsections, a brief functional description of each module shall 
be given.
3.2.1  USB Front-End Driver
The USB front-end driver establishes a connection to the GNSS front end and retrieves 
the GNSS samples. The ipexSR allows the use of the isochronous USB 2.0 high-speed 
mode, where IF sample bits are transferred over the USB link grouped in USB micro-
frames of a size of 1,024 bytes. The ipexSR also allows for the use of other USB transfer 
modes that will not be described here. After a USB microframe has been received, its 
samples are bit-converted, as described in Section 9.2. The samples are converted from 
a 2- or 4-bit format to a 16-bit format. The converted samples are used to fill up a 
packet of IF samples. A special protocol using time stamps (patent pending) is used to 
ensure time synchronicity within and in-between IF sample streams. After a packet is 
filled up with samples, it is put on the IF sample buffer.
The USB front-end driver represents the most time-critical task in the software 
receiver because it runs before the IF sample buffer. After a USB microframe has 
been received, the front-end driver has to react immediately. Otherwise, the fol-
lowing USB microframe will be lost, which potentially can cause serious problems 
in the signal processing. The ipexSR uses two different threads to realize the USB 
front-end driver. One thread retrieves the USB microframes. The other one does the 
bit conversion, puts the packet on the IF sample buffer, and optionally writes the 
sample data into a file on the computer’s hard disk.
3.2.2  IF Sample Buffer
The IF sample buffer is part of the USB front-end driver and represents a relatively 
large amount of main memory used to buffer IF samples. The buffer itself acts as 
a FIFO buffer. If a buffer overflow occurs (if the software receiver is too slow), the 
buffer is completely flushed. This is communicated to the master receiver, which 
initiates a series of actions (similar to reacquisition) to continue tracking after the 
buffer flush. Although a buffer flush should not occur during standard operation, 
buffer flushes cannot be completely avoided. In the case of a GNSS reference sta-
tion, a buffer flush may occur once per day and the buffer flush strategy ensures that 
pseudoranges are continuously tracked with a reduced accuracy, but the buffer flush 
causes carrier phase cycle slips.
3.2.3  Sensor Interface
If external sensor data is provided to the software receiver, like IMU data for GNSS/
INS integration, the sensor interface retrieves this data and passes it to the USB 

3.2  Module Diagram	
41
front-end driver, which includes the sensor data in the IF sample packets. Currently, 
different IMUs, a magnetometer, a barometer, Wi-Fi power readings, and external 
NMEA strings are supported.
A particularly simple external sensor is the PC clock, which can be (optionally) 
read on a continuous basis. For each IF sample packet, the corresponding PC clock 
reading is stored. Reading the PC clock allows the software receiver to also deter-
mine the PC clock error with respect to a GNSS time scale. Assuming that the PC 
clock error varies smoothly, it allows other applications running on the same PC to 
have access to the GNSS time scale. If the PC is equipped with a special clock, as 
described by researchers of the Institute of Embedded Systems, then the time trans-
fer could potentially be with submicrosecond accuracy [1]. The internal PC clock 
allows only an accuracy of several 10 ms. 
3.2.4  Postprocessing Mode
If the software receiver runs in postprocessing mode, the USB front-end interface, 
the IF sample buffer, and the sensor interface are deactivated and are replaced by a 
data input module that reads the same data from the hard disk. 
3.2.5  Master Receiver
The master receiver coordinates the signal processing but does no processing itself. 
It retrieves one packet of IF samples and passes it to the receivers. It checks whether 
GNSS signals shall be acquired and, if yes, it collects the necessary number of IF 
sample packets to be passed to the acquisition manager. The master receiver checks 
if a pseudorange measurement shall be performed and determines the exact mea-
surement epoch. The measurement epoch is aligned to, for example, full seconds of 
GPS time. If a pseudorange measurement is to be performed within a given packet, 
it informs the receiver modules (which make use of the master channels for this 
task) to read the code and carrier pseudorange (plus auxiliary data) for a given ref-
erence sample. The master receiver retrieves the measurements from the receivers, 
merges them to a single record, and passes them to the navigation processor.
After the master receiver has completed its tasks, it waits until all Receiver 
modules finish processing the current packet of IF samples. In this way, processing 
of different GNSS services is synchronized. In the postprocessing mode, the master 
receiver waits for the acquisition manager to finish, whereas in real-time mode, 
the master receiver does not wait for the acquisition manager. Results from the 
acquisition manager are passed to the receiver modules. Finally, the master receiver 
retrieves the next packet of IF samples. 
3.2.6  Receiver
For each tracked GNSS service (e.g., the GPS C/A-code, or the Galileo E5a Open 
Service) there exists one receiver module that controls a configurable number of 
master channels to track satellite signals for this service. 
The receiver module does service-specific preprocessing (e.g., pulse blanking for 
E5/ L5/ E6 services) and then subdivides the sample packet into smaller frames, as 

42	
GNSS Receiver Structure and Dataflow
described in Section 3.1.1.2. Within a loop, all frames are processed by one master 
channel by calling the respective master channel functions. After the loop ends, the 
receiver advances to the next master channel. This has been found to be more ef-
fective than passing one frame of data to all master channels and then advancing 
to the next frame. All the channel configuration data including PRN codes are kept 
in the CPU’s memory caches. The receiver module also controls the multicorrelator 
behavior of the master channels, which are later used for signal quality monitoring. 
If the receiver is configured to work in the multiplexing multicorrelator mode, it 
sequentially activates and stops the multicorrelator mode of the respective master 
channels.
Normally there exists a special receiver module—called the spectrum analyzer— 
that computes and monitors the power spectral density of the received IF sample 
streams. This receiver module neither uses master channels nor subdivides packets 
into frames.
3.2.7  Master Channel
The master channels run within the same thread as their controlling receiver mod-
ule. One master channel maintains the NCO values and can determine the code 
and phase pseudorange data based on the NCO values. It monitors several status 
variables like the loss-of-lock or the cycle slip flag. A master channel controls one or 
two channels, depending upon whether the service contains only a data component 
or a data plus pilot component. 
The Master channel receives one frame of IF samples from the receiver that is 
passed directly to the channel(s) with the current NCO values. The master channel 
retrieves the correlation values from the channel(s) and computes the tracking 
errors. It then updates the NCO variables based on the selected tracking loop 
scheme.
3.2.8  Channel
The channel run within the same thread as their controlling receiver module. One 
channel retrieves IF sample frames from the controlling master channel with NCO 
values. The channel does the reference signal generation, the correlation, the bit 
synchronization, navigation data bit extraction and navigation data message decod-
ing. The channel returns, at maximum, one set of correlation values to the master 
channel per frame. Decoded navigation data messages are stored in the navigation 
record data structure. 
3.2.9  Acquisition Manger
The acquisition manager coordinates GNSS signal acquisition in the software re-
ceiver. Signal acquisition is by far the computationally most demanding operation 
in the software receiver; careful control of this algorithm is required to leave enough 
processing resources for, for example, tracking. The signal acquisition algorithms 
run within their own thread. Signal acquisition is triggered by the master receiver, 
in regular, user-configurable intervals. 

3.2  Module Diagram	
43
After an acquisition has been initiated, the acquisition manager first determines 
which signals can be expected by the receiver to be above a certain elevation cutoff 
angle and which are already tracked. If a PVT solution is available and if ephemeris 
or almanac data is available, the code phase and Doppler search range are deter-
mined. If both values can be determined very precisely (e.g., less than one chip and 
a few hertz accuracy) then this signal is considered to be acquired. This is called 
vector acquisition because, similar to a VDLL, the code phase and the Doppler 
are derived from the navigation solution. If vector acquisition is not possible, the 
parameters are put into a list. This is repeated for all signals and finally the list is 
passed to the level-1 (cold-start) acquisition module. This module tries to acquire 
the signals contained in that list by FFT methods. Signals that cannot be acquired by 
the level-1 module are then passed to the level-2 (warm-start) acquisition module. 
Finally, the results from all three acquisition methods (vector, level 1, and level 2) 
are combined and returned to the master receiver.
3.2.10  Level-1 and Level-2 Acquisitions
Within the ipexSR, the actual signal acquisition is fully flexible and different acqui-
sition algorithms can be used. Normally, the correlation is done in the frequency 
domain and squaring or differential detectors can be used for further noncoherent 
integration. The algorithms can be configured and two different configuration sets 
are possible. They are named level-1 (cold-start) and level-2 (warm-start) acquisi-
tions. The level-1 parameters are applied to all satellite signals, whereas the level-2 
parameters are applied only to acquire those signals where it is possible to reduce 
the Doppler search space based on an (approximate) PVT solution and satellite 
ephemeris/almanac data. Obviously the level-2 parameters can be chosen to use 
longer coherent integration times and/or more noncoherent steps.
3.2.11  Navigation Processor
The navigation processor is like the master receiver or the acquisition manager. It is 
a controlling module that does no processing itself. It receives the code and phase 
pseudorange measurements and passes them to encapsulated modules described in 
the following three sections. The navigation processor, with its modules, runs in its 
own thread.
3.2.12  Positioning with RAIM
Within a GNSS receiver, positioning has a central role. In fact, there may be dif-
ferent positioning algorithms running and operating on the same data, with each 
positioning algorithm being optimized for certain aspects (e.g., integrity, accuracy, 
RTK). Within the ipexSR there is one positioning algorithm that has an outstanding 
role because it is used to determine the receiver internal PVT estimate. This estimate 
is used to determine satellite visibility or to do vector acquisition. Therefore, the po-
sitioning algorithm is optimized for utmost robustness. It operates on an epoch-per-
epoch basis instead of relying on a previous position estimate. This avoids linked 
errors caused by occasional gross positioning errors. Furthermore, the positioning 

44	
GNSS Receiver Structure and Dataflow
includes RAIM; it also informs the master receiver to stop tracking satellite signals 
that are identified to have gross errors. If no position at all can be determined for a 
certain number of epochs, the master receiver is totally reset to acquire all signals 
from scratch. All signals that can be successfully verified that their code pseudo­
range and Doppler match the PVT estimates are flagged to be acceptable.
3.2.13  Navigation Modules
The ipexSR includes a large number of navigation modules that all operate on the 
same pseudorange data on an epoch-per-epoch basis. This includes positioning with 
EGNOS, positioning with RTCM corrections, ionospheric monitoring, and signal 
quality monitoring using multicorrelator values [6, 7].
3.2.14  Input and Output Modules
Input and output modules are special navigation modules because they interact 
with other applications and /or user equipment. The following output modules can 
be used: RTCM output, RINEX observation file output, commercial GNSS receiver 
emulation, NMEA output, and tracking-status output. Currently, there is one input 
module used to read RTCM correction data.
3.2.15  Receiver Status
The receiver status is a special data structure containing the most recently validated 
PVT estimate with the corresponding measurements. All software receiver modules 
have access to this data structure. Additionally, it can be set by the user based on 
an external PVT solution. 
3.2.16  Navigation Records
The software receiver contains a database, which contains all navigation messages. 
The database is called “Navigation Records.” Records can be provided via the 
GNSS signals, they can be read from the hard disk, and they can be obtained via 
an EGNOS-SISNET connection or from an AGNSS server. The Navigation Record 
type and content are usually directly derived from the different GNSS message 
structures, but special records also exist for, for example, tropospheric model-
ing, or to define fixed pseudolite positions. The management of this database can 
be quite complex, especially if a permanent operation of the software receiver is 
considered. 
3.2.17  AGNSS and SISNET Connection
The navigation records database can be configured to connect to ESA’s SISNET or 
to establish a connection to an AGNSS server. Both connections use a TCP/ IP con-
nection. The SISNET connection provides EGNOS records. The assisted connec-
tion uses proprietary formats to exchange navigation records between an AGNSS 
server and AGNSS receiver. Both are software receivers, but one is configured to act 

3.3  Execution Flow	
45
as the server and the other to act as the client. Multiple clients can connect to one 
server.
3.3  Execution Flow
It is common practice to define an SDR as a multiprocessor system as described in 
Section 2.2.2. To exploit the capabilities of a multiprocessor system, the software 
itself needs to be parallel or, in other terms, the software execution path should be 
split up into several threads. Threads can be executed on different processors simul-
taneously and need to be synchronized to each other to maintain data coherency. 
If the software uses more threads than available processors (or cores), different 
threads are executed partly sequentially.
To get more insight into an execution flow of a GNSS SDR, the ipexSR shall 
be analyzed with a thread profiler [8]. This tool visualizes the activity of all threads 
and shows the synchronization between the threads. The thread activity is plotted 
as a function of time and the diagrams are called (thread) time lines (see Figures 3.9 
or 3.10). As shown in Figure 3.5, a thread can be active (actually doing a computa-
tion) or it can wait for a certain event (e.g., a receiver thread may wait for the next 
packets of IF samples to arrive). The thread profiler also indicates if a thread is in 
a spin loop and permanently polling an event that should be set by another thread 
(and is thereby wasting CPU resources). Thin (yellow) vertical or diagonal lines in 
the time line indicate thread synchronization (e.g., one thread tells another thread 
to resume its activity). The time line also shows the most time-consuming path or 
call sequence originating from the program start as a (red) bold, highlighted hori-
zontal line. Please see this book’s homepage (mentioned in Chapter 11) for color 
Figure 3.5  Thread time line diagram legend.

46	
GNSS Receiver Structure and Dataflow
versions of Figures 3.9, 3.10, and 3.11. A critical path can flow across different 
threads at different times during a program’s execution. A serial application has a 
single flow, which corresponds to the default critical path. A multithreaded applica-
tion has multiple flows. The critical path determines the total execution time of the 
software; code along the critical path should be optimized. Optimizing code outside 
the critical path does not reduce the software execution time.
It should be mentioned that thread profiling causes a computational overhead 
of several percentages. The software execution flow thus slightly differs from a 
program run without profiling. 
Two real-time configurations shall be investigated in the following section: the 
first runs a multifrequency configuration on a multicore computer; the second in-
vestigates a single-frequency configuration on a single-core computer.
3.3.1  Computer with Four CPU Cores
The software receiver was configured to track five GNSS services (GPS C/A, GPS 
L2C, GIOVE-A E1-OS, SBAS on L1, GIOVE-A E5a-OS). A sixth receiver was con-
figured to act as an IF spectrum analyzer. A triple-frequency front end (the reference 
station front end of Table 2.1) has been used and the time span covered by one 
packet of IF samples has been 0.41 second. The computer platform was equipped 
with two Xeon 5140 (2.33 GHz) processors, each having two CPU cores. The over-
all processing load of the GNSS SDR in this configuration was quite low and much 
less than 50%. The profiling results of this configuration are shown in Figures 3.6 
and 3.9 during signal tracking. Figures 3.7 and 3.10 contain profiling results for a 
period during which the SDR acquires signals.
3.3.1.1  Concurrency Level
Figures 3.6 and 3.7 show the concurrency level of the software. The concurrency 
level is an indicator of how many tasks the software programs could run simulta-
neously. If the concurrency level equals the number of cores (in this case, four) the 
Figure 3.6  Concurrency level distribution corresponding to Figure 3.9.

3.3  Execution Flow	
47
computer is perfectly loaded. If the concurrency level exceeds this number, the sys-
tem is overutilized, and if the number is less than the number of cores the system is 
underutilized. During pure tracking (Figure 3.6), most of the time only one thread 
is executed. Alternatively, the system may wait for IF samples, which is indicated as 
a concurrency level of zero.
If signal acquisition is performed, the average concurrency level increases by 
one, as shown in Figure 3.7. Both figures also demonstrate that the computer is 
required to run four or more tasks simultaneously only in rare cases. 
3.3.1.2  Sample Reception
The SDR runs two threads to retrieve IF samples from the USB front end. They are 
called “FhGUSBInterface” and “FhGUSBInterfaceDispatcher” in Figures 3.9 and 
3.10. The first thread retrieves the USB micropackets, using low-level operating sys-
tem calls, more or less directly from the USB host located in the computer. It receives 
this data with a rate faster than 19.2 ms. This thread is extremely time-critical because 
it must be almost instantaneously ready to receive the next batch of data. Therefore, 
it puts the raw USB data into memory and informs the FhGUSBInterfaceDispatcher. 
The FhGUSBInterfaceDispatcher thread brings the raw USB samples into timely cor-
rect order and performs a bit conversion from the front end 2/4-bit format to the 
internal 16-bit format (see Section 9.2). Figures 3.9 and 3.10 show that the dispatcher 
is active with a rate of slower than 100–200 ms. Every 410 ms (on average) a packet 
of IF samples is completed and the Master Receiver is informed.
3.3.1.3  Signal Processing
After being triggered, the master receiver starts with preprocessing of the next IF 
sample packet (actually copying the data within the computer’s main memory; see, 
e.g., the time span of 54.7–54.84 seconds in Figure 3.9). Then the different receivers 
are triggered to start processing this packet. The master receiver and the receivers 
can work in overlapping fashion; for example, the master receiver can fetch the next 
Figure 3.7  Concurrency level distribution corresponding to Figure 3.10.

48	
GNSS Receiver Structure and Dataflow
packet (if available) and start its preprocessing while the Receivers work on the old 
packet. This is, for example, visible during time spans of 55.00 to 55.01 seconds 
in Figure 3.9. Normally, however, there is no need for overlapping because the re-
ceivers finish before the next packet arrives. In Figures 3.9 and 3.10, one sees that 
different receivers need different execution times. The C/A-code receiver (receiver 0) 
needs the most time because it tracks the most signals. The spectrum analyzer (re-
ceiver 5) is activated only for every second packet. 
When an acquisition is running the computer spends fewer resources for track-
ing and signal processing; in some receivers tracking is slightly delayed (see time 
span 41.61– 41.74 seconds of Figure 3.10).
3.3.1.4  Navigation Processor
Both threading time lines in Figures 3.9 and 3.10 show nicely that indeed most of 
the time is spent for signal processing. The navigation processor is activated (in 
this particular configuration) only every second and needs a few milliseconds to 
complete. This also includes quite extensive data logging and RINEX output. Also 
the controller (the interface to the user or to the GUI) consumes only marginal 
computational resources.
3.3.2  Computer with a Single CPU Core
A second real-time threading analysis was done on the test system described in 
Table 9.1. This is a single-core computer and obviously only one thread can run 
at a time. The system is less powerful and a single-frequency (GPS C/A-code on 
Receiver 0) configuration with a spectrum analyzer (Receiver 1) was chosen. An L1 
front end (R&D L1 front end of Table 2.1) was used, which has a different software 
Figure 3.8  Concurrency distribution corresponding to Figure 3.11.

Figure 3.10  Threading time line for the multifrequency GNSS receiver configuration running on four CPU cores (acquisition running).
Figure 3.11  Threading time line for the single-frequency GNSS receiver configuration running on one CPU core.
Figure 3.9  Threading time line for the multifrequency GNSS receiver configuration running on four CPU cores (no acquisition).

50	
GNSS Receiver Structure and Dataflow
interface compared to Section 3.3.1.2. The time span covered by one packet of IF 
samples is 91 ms.
The concurrency level is shown in Figure 3.8 for the threading time line of 
Figure 3.11. Most of the time the software has a need to run two threads simulta­
neously, but only one can be executed. The system is overutilized. The threading 
time line in Figure 3.11 is also quite different from the ones of Section 3.3.1. It ap-
pears to be more chaotic because the computer switches between the threads. The 
computer itself has a processing load of nearly 100% when running the GNSS SDR 
with the thread profiler. 
The thread time line in Figure 3.11 shows no visible structure in the IF sample 
reception thread. The respective thread “threadFunc” is more or less continuously 
active while receiving data from the USB port. Interestingly, IF sample packets are 
usually processed in groups of two, as can be seen from the active time line of the 
Master Receiver or the Receiver 0. One packet contains data for 91 ms and the Mas-
ter Receiver is active around five times within a period of 1 second. Signal tracking 
almost completely pauses while an acquisition is running (time span 189.3–191.5 
seconds of Figure 3.11). Immediately after acquisition, the signal processing runs 
faster than in real time to recover the lost time.
3.4  GNSS Reference Station Configuration
The ipex software receiver can be configured to work as a GNSS reference station 
and the algorithms and parameters required for this operation mode shall be out-
lined in the following sections. 
A GNSS reference station is typically located at a fixed site and the antenna usu-
ally has a good field of view to track all GNSS satellites above the horizon. GNSS 
measurements (code and carrier pseudorange) are produced with a rate of 1 Hz and 
are used as correction data for roving GNSS receivers, to precisely determine the 
position of the reference station itself or for other professional and scientific ap-
plications. A reference station is required to track all signals in view and to provide 
measurements of highest accuracy and reliability.
3.4.1  Acquisition Parameters
The reference station configuration uses a single coherent integration (see Section 
5.7.1) to acquire signals in a cold-start mode. The cold-start mode is used when 
the receiver is unable to predict the Doppler frequency of a signal. This prediction 
step would require an available satellite almanac and a coarse receiver position 
and receiver time information. When this prediction can be done, a warm start is 
performed and the receiver uses multiple coherent integrations (with noncoherent 
summation) as described in Section 5.7.2.3. The used FFT algorithm will be outline 
in Section 9.5.4. The presence of data bits or a secondary code is simply ignored. 
Before applying the FFT acquisition, the signals are resampled to an acquisition 
sample rate defined by dividing the FFT length by the coherent integration time.
Acquisition parameters are summarized in Table 3.2. For each satellite system 
(GPS or Galileo) there is one acquisition signal that is acquired first. For example, 

3.4  GNSS Reference Station Configuration	
51
the C/A-code on L1 is the acquisition signal for GPS. After it is acquired, code phase 
and Doppler for L2 (or L5) can be calculated and a handover from L1 to the other 
frequencies is performed.
The single coherent integration method is less memory-consuming than using 
multiple coherent integrations and is usually sufficient to acquire rising GPS signals 
as soon as the satellite has an elevation higher than 2–3°. Usually, the signal is 
tracked continuously until the satellite disappears behind the horizon. 
We found it useful to have a backup solution for GIOVE-A E5a that is used 
when the handover from E1 is not working. The backup solution is realized as 
warm-start parameters for the Q-channel of E5a (see Table 3.2). During the early 
GIOVE-A tests, the code phase relationship between E1 and E5a was not totally 
clear from open literature. It is not possible to do a handover if an unknown code 
phase offset between E1 and E5a larger than 30m is present. The lack of ephemeris 
and almanac data for GIOVE-A (remember, this was a test satellite) does not allow 
for a warm start on E1. Only when E1 is already tracked can the Doppler search 
range for E5a be limited. 
3.4.2  Tracking Parameters
For signal tracking, the ipex software receiver generates references signals, as de-
scribed in Section 9.3, and correlates them with the method of Section 9.4. Code-
phase, carrier-phase, and Doppler discriminators are described in Section 8.1 and 
are based on one P-, D-, and F-correlator (see Chapter 7). To speed up the numerical 
performance, already-generated reference signals are reused for multiple correla-
tions, as pointed out in Section 4.3.2.10 and Section 9.6.
The P-correlator reference signal equals the infinite-bandwidth PRN code 
signal, including the modulation scheme. No carrier-phase multipath mitigation 
scheme is employed. This choice is the simplest one and the most easy to realize. The 
F-correlator is approximated by splitting the coherent integration into two parts of 
equal length, as described in Section 7.3.2. The D-correlator reference signals are 
partly optimized to mitigate code multipath. For the C/A-code, a double-delta-like 
reference signal is used that is given by (8.32) with d = 0.2. For L2 CM, an early-
minus-late reference signal with d = 0.1 is used, as defined via (7.116). A difficulty 
arose when precomputing a reference signal for the L2 CL code (which has a period 
of 1.5 seconds). It turns out, it needs too much memory if a narrow correlator spac-
ing is required. Consequently, there were three options: disregarding L2 CL, using 
L2 CL with d = 1, or porting the software receiver to a 64-bit operating system. We 
Table 3.2  GNSS Reference Station Acquisition Parameters
Signal
Tcoh (ms)
Noncoherent 
Integrations
FFT Length
Cold start
L1 C/A
4
1
8,192
E1 C
8
1
65,536
Warm start
L1 C/A
4
5
8,192
E5a Q
4
25
131,072

52	
GNSS Receiver Structure and Dataflow
chose the first option for simplicity. The BOC(1,1) signal on GIOVE-A E1 is tracked 
using an S-curve shaping correlator (see Section 8.2.4) and the E5a signal is tracked 
with an early-minus-late d = 0.66 correlator.
Tracking loop filters are summarized in Table 3.3, together with the coherent inte-
gration time. The GPS C/A carrier phase is tracked with an atan (one-quadrant) phase 
discriminator, and the full carrier phase is derived by decoding the sign of the GPS 
C/A NAV message preamble. For all other signals, an atan2 (four-quadrant) phase 
discriminator is used that works only on the pilot component. At this writing, the 
GPS L2 CM signal is broadcast as a pilot signal without any navigation message.
Sub-Nyquist sample rates are used to reduce the computational load (see Section 
6.5). The front-end samples the IF signals with a rate of 40.96 MHz. All frequency 
bands have a 3-dB bandwidth of around 13 MHz. For tracking, the sample rate is 
reduced to 20.48 MHz. For GPS C/A tracking, the sample rate is further reduced to 
10.24 MHz, if the C/N0 lies above 40 dBHz.
3.4.3  Performance Results
Two exemplary spectrums of the received GNSS frequency bands are shown in 
Figure 3.12. For Figure 3.12(b), an active antenna with a 50-dB integrated LNA 
was used; Figure 3.12(a) is based on a passive antenna with a 17-dB LNA directly 
attached to it. The spectra were obtained from analyzing 0.2 second of the received 
signal. The spectra are offset with respect to the nominal carrier frequencies and are 
shifted with respect to each other because the nominal IF is different for each fre-
quency band. For L1 and L2, one sees the main lobes of the GPS L1 C/A and the GPS 
L2 CM+CL signals centered directly at the nominal carrier frequency. Doppler shifts 
are too small to be visible in these figures. Furthermore, it should be pointed out that 
the signal power spectral density adds to the noise power spectral density. Therefore, 
we can actually see the GPS signal power spectral density in Figure 3.12 although the 
GPS signal amplitude is much smaller than the noise amplitude. 
Remarkably, interfering signals are present in Figure 3.12. On L2, several 
narrowband interferers show up. On L1 and L5, narrowband interferers are pres-
ent with one being of wider bandwidth (at around +5.2 MHz on L1 and –6.2 
MHz on L5). Whereas the interferers on L1 and L5 are well suppressed, when the 
GNSS signals are despreaded, the strong interfering signal on L2 in Figure 3.12(a) 
significantly distorts the signal reception and brings the 2-bit ADC into saturation. 
Generally, we have found interfering signals of low power in many places. How-
ever, the strong L2 interferer is a local phenomenon at the campus of the University 
FAF Munich. It can be well-suppressed by a digital notch filter within the software 
receiver, but due to ADC saturation effects, an effective signal power loss of around 
5 dB is the consequence.
Table 3.3  GNSS Reference Station Tracking Parameters
Signal
Phase Discriminator
Tcoh (ms)
BDLL (Hz)
BPLL (Hz)
L1 C/A
atan
20
0.01
18
L2 CM
atan2
20
0.01
18
E1 B+C
atan2
4
0.05
18
E5a I+Q
atan2
20
0.05
18


54	
GNSS Receiver Structure and Dataflow
The code and carrier tracking performance is shown in Figure 3.13 and Figure 
3.14 for one pass of GPS PRN7 and GIOVE-A. The code error is computed by first 
subtracting the code pseudorange from the carrier pseudorange (both expressed in 
meters). Then a fifth-order polynomial is fitted to the difference. The polynomial 
models the ionospheric delays. The ionospheric delay is removed from the differ-
ence and the result is plotted as “code error” in both figures. The carrier phase is 
totally cycle-slip free if data with an elevation larger than 7° is considered. The 
figures also show the estimated C/N0. 
Apart from L2, the Figure 3.13 and Figure 3.14 confirm the expected signal 
performance. GPS C /A code pseudoranges are of decimeter accuracy and E5a has 
the highest accuracy due to its large bandwidth. For low elevations, all signals show 
strong C /N0 fluctuations caused by multipath effects. The antenna was mounted 
on top a metal roof. For L2, code tracking errors of maximally 2m occur and the 
C /N0 value is reduced by the interference. The rather large code tracking errors 
result from the reference signals not being recomputed frequently enough. The cor-
relation point wanders outside the linearity region and this degrades the code phase 
estimation accuracy (see Section 4.3.2.10).
3.5  Discussion
Several possibilities for the data flow in a GNSS SDR have been discussed in this 
chapter. For real-time processing (and in practice for most postprocessing configu-
rations), the immense data volume processed by a GNSS SDR constrains the signal 
Figure 3.14  Code-minus-carrier and estimated C/N0 for GIOVE-A, January 1, 2009.

3.5  Discussion	
55
processing to work on only a limited portion of the IF sample data at a time (batch 
processing). The most striking difference between a hardware and a software re-
ceiver is the capability and necessity for a software receiver to buffer IF samples.
A specific receiver architecture has been presented that was used to develop 
the ipexSR as a multifrequency GNSS SDR. The architecture was carefully chosen 
and not only influences the resulting software itself, but also relates to the software 
development process. It is important that the architecture fits the development en-
vironment (here C++), the involved developing team members and their specific 
capabilities. To some extent, the team requirements may have an even larger impact 
on the architecture than the technical requirements. 
Different options exists to run a GNSS SDR in real time. The ipexSR is imple-
mented in a manner to allow its operation in real time (in a loose sense) under 
Windows (a non real-time operating system). The software itself utilizes multiple 
processors or cores and is separated into several threads. A threading analysis shows 
that the receiver behaves very much like a real-time GNSS SDR in a strict sense. It 
immediately reacts after receiving the IF samples if (and most likely only if) there is 
a sufficient number of cores available and if the processing load is clearly beyond 
100% (e.g., around 50–60% at a maximum). In that case, acquisition and tracking 
can run in parallel. If the software gets heavily loaded to more than 70–80%, there 
will be, for example, tracking pauses of several seconds or other phenomena that 
may occur that should not be present in a real-time GNSS SDR.
References
  [1]  Institute of Embedded Systems InES, “IEEE1588 Enabled PCI Network Interface Card,” 
http://ines.zhaw.ch/institut/products/ieee-1588-hardware/page.html, 2008.
  [2]  Trimble Navigation Ltd., “MS750, Dual Frequency RTK Receiver for Precise Dynamic 
Positioning,” http://trl.trimble.com/docushare/dsweb/Get/Document-12640/ms750pp.pdf, 
2007.
  [3]  van Grass, F., et al., “Comparison of Two Approaches for GNSS Receiver Algorithms: 
Batch Processing and Sequential Processing Considerations,” Proc. 18th Int. Technical 
Meeting of the Satellite Division of the Institute of Navigation (ION-GNNS) 2005, Long 
Beach, CA, September 13–16, 2005, pp. 200–211.
  [4]  Closas, P., et al., “Bayesian Direct Position Estimation,” Proc. 21st Int. Technical Meeting 
of the Satellite Division of the Institute of Navigation (ION-GNNS) 2008, Savannah, GA, 
September 16–19, 2008, pp. 183–190.
  [5]  Brown, A., P. Brown, and J. Griesbach, “GeoZigBee: A Wireless GPS Wristwatch Tracking 
Solution,” Proc. 19th Int. Technical Meeting of the Satellite Division of the Institute of Nav-
igation (ION-GNNS) 2006, Fort Worth, TX, September 26–29, 2006, pp. 2883–2888.
  [6]  Anghileri, M., et al., “Performance Evaluation of a Multi-Frequency GPS/Galileo/SBAS 
Software Receiver,” Proc. 20th Int. Technical Meeting of the Satellite Division of the In-
stitute of Navigation (ION-GNNS) 2007, Fort Worth, TX, September 25–28, 2007, pp. 
2749–2761.
  [7]  Stöber, C., et al., “Implementing Real-time Signal Monitoring within a GNSS Software Re-
ceiver,” Proc. European Navigation Conference (ION-GNNS) 2008, Toulouse, April 22–25, 
2008.
  [8]  Intel Corp., “Thread Profiler 3.1 Build:0.25466,” http://www.intel.com, 2007.

57
C h a p t e r  4
Signal Estimation
This chapter will introduce signal-estimation techniques that are used by a naviga-
tion receiver. The basic goal of the receiver is to obtain an estimate of its position; 
this will be optimized with respect to application-specific criteria. One option is to 
look for unbiased estimators having minimum variances. Another option could be 
to minimize the mean-squared error if a priori stochastic information on the dis-
tribution of the true position (e.g., a user-motion model) or of any related quantity 
is available. The first approach is called nonrandom parameter estimation because 
the position is regarded as an unknown but otherwise deterministic quantity. In a 
GNSS receiver, for example, pseudorange estimation (an intermediate step before 
position estimation) is usually treated as a nonrandom parameter-estimation prob-
lem. The second approach—Bayesian parameter estimation—treats the position as 
a random variable. Kalman filtering, being a Bayesian technique, is commonly used 
to estimate user positions in a navigation receiver. 
The chapter starts with nonrandom parameter-estimation techniques, which 
are regarded in this context to be more fundamental, simply because no stochastic 
models are needed. Furthermore, the nonrandom parameter-estimation approach 
allows the use of powerful analytical tools, like the Cramér–Rao lower bound 
(CRLB). The described estimators try to achieve this lower bound as much as pos-
sible. Nonrandom parameter estimation is especially useful if GNSS signal param-
eters such as code phase, Doppler, frequency, or amplitude are considered, because 
no (or only very crude) stochastic models are available for them. Bayesian estima-
tion (or more specifically, a Kalman filter) is a suitable approach if the estimated 
parameters are the user position or trajectory. In that case, better stochastic models 
are available. In other words, it is possible to provide useful stochastic information 
for the movement of a vehicle, but range-measurement errors from the vehicle to 
a satellite, including multipath, atmospheric delays or satellite orbit/clock errors, 
may require sophisticated modeling that is too complex for practical use within the 
signal-processing stage. 
Reviewing the algorithmic design of a navigation receiver is of special impor-
tance for a SDR receiver because the SDR concept potentially provides the possibil-
ity to redesign well-known navigation signal-processing techniques to implement 
more complex algorithms as compared to hardware receivers. 
4.1  Parameters of Interest
Before starting with the description of the different estimation techniques, it is use-
ful to look at the parameters to be estimated in a navigation receiver. Three classes 
of parameters will be identified: position, low-rate pseudorange data, and high-rate 

58	
Signal Estimation
pseudorange data. They are summarized in Table 4.1 and will be explained below. 
Nuisance parameters are introduced for formal reasons and extend the useful pa-
rameters to have a complete model for the deterministic part of the received signal. 
All parameters can either be constant during the signal-estimation process or 
be time-dependent. In the latter case, we assume that the time dependence can be 
described through a finite number of parameters. For example, if a moving user is 
considered, we assume that his or her trajectory can be modeled sufficiently well by 
a spline or similar curve, which is determined by a finite number of parameters.
4.1.1  Useful Parameters
The position is understood as the vector of parameters, that is, the final output of 
the navigation receiver. In the simplest case, this is the estimated position within 
a predefined-coordinate system. It may, however, include other parameters of in-
terest, such as the velocity, clock error, or atmospheric delays. Furthermore, the 
position vector may include parameters that are related to the aforementioned 
variables (e.g., multipath-signal parameters) and, in the most general case, it in-
cludes all parameters necessary to define the signal model. Therefore, the term posi-
tion is used here in a general way, but it defines the end product of the estimation 
scheme.
The term high-rate pseudorange data summarizes all parameters that are di-
rectly related to the received signal model. These parameters are those introduced 
in Section 1.8: delay, Doppler, carrier phase, and amplitude. 
The term low-rate pseudorange data is used to describe all data being passed 
from the signal-processing unit to the navigation filter within a GNSS receiver. 
Low-rate pseudorange data is derived directly from the high-rate pseudorange data, 
usually via a filtering procedure that reduces the amount of data to be processed by 
the navigation filter. 
4.1.2  Nuisance Parameters
The deterministic part of the received signal may depend, in addition to the useful 
parameters, upon further unknown parameters—the nuisance parameters ξ, which 
do not stand in any relation to the position; we are therefore not interested in their 
Table 4.1  Generalized Useful Parameters
Name
Symbol
Description
Position
x
End product of the estimation scheme. Normally includes the 
position estimate in a given coordinate system plus velocity 
and clock error/drift, but may also include atmospheric delays, 
transmitter positions, or any other quantity correlated with 
position estimate.
High-rate pseudorange
q
Short period signal parameters (typically delay, Doppler, carrier 
phase, amplitude) as introduced in Section 1.8 for line-of-sight 
and multipath signals.
Low-rate pseudorange
p
Reduced and filtered subset of high-rate data (e.g., only delay 
and Doppler) for a given measurement rate of for example, 
every 1 seconds.

4.2  Nonrandom Parameter Estimation	
59
estimated values. Typically, the nuisance parameters are a subset of the high-rate 
pseudorange data. Formally, the nuisance parameters can be estimated along with 
the other parameters.
For certain applications, the carrier phase and the signal amplitude can be 
treated as nuisance parameters. Another example of nuisance parameters includes 
signal parameters of possibly present multipath signals. However, for both exam-
ples it may be reasonable to consider them as useful parameters for a different set 
of applications, especially if correlations between them and the position estimates 
are important.
The nuisance parameters ξ are treated as random variables, described by a 
probability density function p(ξ). This implies that any parameter for which we are 
not able to give a probability density function must be treated as a useful parameter, 
even if we are not interested in its estimated value.
4.1.3  Relationship Between the Parameters
The deterministic part of the received signal, rµ, contains all available information 
for position estimation. It is reasonable to assume that the deterministic model 
depends upon the position, the low- or high-rate pseudorange data, and on the 
nuisance parameters as 
	
( , )
( , )
( , )
r
r
r
r
µ
µ
µ
µ
ξ
ξ
ξ
=
=
=
x
q
p
	
(4.1)
In each of these three cases, the same signal model is meant; it is just expressed 
as a function of different parameters. The nuisance parameters ξ are identical for 
all three cases. 
For the useful parameters, we assume that they represent different ways of 
expressing the user’s position. Therefore, high- or low-rate pseudorange data is 
uniquely defined by the position:
	
= ( ( ))
q
q p x 	
(4.2)
Equation (4.1), together with (4.2), states that the signal does not directly de-
pend on the position, but only through the pseudorange q, respectively through p 
and q. The vector q is typically of a higher dimension than p, which is itself of a 
higher dimension than x. Fulfilling (4.2) in a real-world situation can be compli-
cated; many modeling efforts are necessary to account for user dynamics, multipath, 
atmospheric effects, transmitter position/clock errors, and other effects. Neverthe-
less, for the theoretical discussion we assume that the condition (4.2)—called suf-
ficient modeling—is fulfilled.
4.2  Nonrandom Parameter Estimation
This section introduces several concepts of nonrandom parameter estimation that 
are illustrated by the positioning problem. The CRLB and some modified bounds 


4.2  Nonrandom Parameter Estimation	
61
in the sense that there should be no estimator having a smaller variance matrix. For 
a definition on how to compare two matrices, see (4.15). Consequently, the position 
estimator shall be a minimum variance unbiased estimator (MVUE). It is known 
that an MVUE is, in general, not optimal if the MSE (or RMS) value 
	
*
=
-
-
,
,
ˆ
ˆ
ˆ
MSE
( ( )
) ( ( )
)
S x
S x
x
x S
x
x S
x
	
(4.6)
is considered; that is, biased estimators may exist whose MSE is below the MSE of 
an MVUE (e.g., noise-variance estimation as described in IV.D.2 of [1] illustrates 
this case). Minimum MSE estimators are Bayesian estimators; they require a priori 
knowledge on the distribution of x and are discussed in Section 4.5.
Additionally, it should be noted that unbiased estimators are important in high-
precision navigation problems (see Table 4.2). There, the variance can, in general, 
be reduced by collecting more data by, or by using a longer time span to determine 
the position. Another option is to increase the bandwidth of the received navigation 
signal (e.g., change from a low-bandwidth front end to a high-bandwidth front end) 
and thus obtain more independent samples within the same observation period.  
The signal samples comprise a deterministic part, rm, and an additive stochastic 
component Nm,
	
( , )
( , )
S
r
N
µ
µ
µ
ξ
ξ
=
+
x
x
	
(4.7)
This type of estimation problem is called a signal-in-noise problem. 
For a fixed value of x and ξ, the expected value with respect to the signal 
samples equals the expected value with respect to the noise:
	
,
const.
ξ =
=
S
N
x
	
(4.8)
If ξ is treated as a random variable, then the expected value has to be computed 
with respect to the probability density functions of the noise and of the nuisance 
parameters:
	
ξ
=
=
,
const.
S
N
x
	
(4.9)
The stochastic component Nm represents the received noise and is modeled as a 
vector of complex-valued i.i.d. random variables. For purposes pursued in this sec-
tion, it is sufficient to consider a comparable simple Gaussian model; that is, 
	
µ
µ
Re{
}
(0,1),
Im{
}
(0,1)
N
N
N
N
∼
∼
	
(4.10)
Table 4.2  Desired Receiver Properties for High-Precision Applications
Property
Importance
Motivation
Position estimate is unbiased
High
To avoid systematic errors in positioning that cannot 
be reduced by further averaging and are not modeled 
by the position-variance matrix.
Small variance, small MSE
Medium
Should generally be as low as possible.

62	
Signal Estimation
where N(0,1) denotes a Gaussian distribution with zero mean and unit variance, 
such that (1.16) holds.
A Gaussian noise model is considered because only in that case can comparable 
simple analytical expressions for the CRLB be derived. The evaluation of the CRLB 
in non-Gaussian noise is cumbersome and, in most cases, analytically impossible 
[2]. Furthermore, thermal noise is well-described by a Gaussian model. A detailed 
discussion of non-Gaussian noise occurring during signal quantization is given in 
Section 6.1.
4.2.1  Position CRLB Without Nuisance Parameters
Making all those assumptions, the received signal is modeled as a sequence of com-
plex-valued random variables whose distribution depends on the true position x. 
Assuming for the following that either x completely describes the received signal 
or that the nuisance parameters have fixed known values [both assumption imply 
that (4.8) is valid], then the probability density function of the signal is given as (see 
Appendix A.1.2)
	
µ
µ
µ
π
=
=
-
-
2
1
1
1
( )
exp
( )
2
(2 )
L
L
p
s
r
x s
x
	
(4.11)
where L is the number of available complex-valued signal samples. It is known 
that the variance of any MVUE for the position is bounded from below by the 
inverse of the Fisher information matrix (see Section IV.E.1 from the book by 
Poor [1]):
	
; ,
log
( )
log
( )
i j
i
j
I
p
p
x
x
=
÷
÷
x
x
x
N
S
S
	
(4.12)
The derivative is evaluated as
	
( )
( )
1
log
( )
(
( ))
(
( ))
2
( )
( )
Re
(
( ))
Re
( )
Re
i
i
i
i
i
i
r
r
p
S
r
S
r
x
x
x
r
r
S
r
N
x
x
r
N
x
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
=
-
+
-
÷
=
-
=
÷
÷
=
÷
x
x
x
S
x
x
x
x
x
x
	
(4.13)
Thus, the Fisher information matrix evaluates to

4.2  Nonrandom Parameter Estimation	
63
	
; ,
,
( )
( )
Re
Re
( )
( )
1
( )
( )
4
( )
( )
1
( )
( )
4
Re
i j
i
j
i
i
j
j
i
j
i
j
r
r
I
N
N
x
x
r
r
r
r
N
N
N
N
x
x
x
x
r
r
r
r
N N
N N
x
x
x
x
r
µ
υ
µ
υ
µ
υ
µ
µ
υ
υ
µ
µ
υ
υ
µ
υ
µ
µ
υ
υ
µ
υ
µ
υ
µ υ
=
÷
÷
=
+
+
÷
÷
=
+
÷
=
x
N
N
N
x
x
x
x
x
x
x
x
x
x
( )
( )
i
j
r
x
x
µ
µ
µ
x
x
	
(4.14)
because of (1.16). A similar expression can be found in Section 15.7, Equation 
(15.52) in the book by Lehmann [3].
Equation (4.14) represents the best possible accuracy a navigation receiver can 
achieve in the sense that the variance of any unbiased estimator ˆ( )
x S  is bounded 
from below by
	
*
-
=
-
-
=
1
ˆ
ˆ
ˆ
var
( )
( ( )
)( ( )
)
CRLB( )
Ix
N
N
x S
x S
x x S
x
x
	
(4.15)
The difference matrix D,
	
-
=
-
1
ˆ
var
( )
D
Ix
N
x S
	
(4.16)
is nonnegative definite (i.e., all the eigenvalues of D are greater than or equal to 
zero). 
Any unbiased estimator that achieves the CRLB is called an efficient estimator. 
An MVUE is not necessarily efficient, because “minimum” does not mean equality 
holds on the Cramér–Rao inequality (4.15).
The equality to the CRLB of an unbiased estimate ˆ( )
x S  is achieved if and only if 
	
-
-
=
1
log
( )
ˆ( )
p
I
x
x
s
x s
x
x
	
(4.17)
at least somewhere around x; see Theorem 3.4 from the book by Porat [4].
4.2.2  Position Estimation with Nuisance Parameters
If nuisance parameters are present, the probability density function of the received 
signal samples takes the form 
	
ξ
µ
µ
µ
ξ
π
=
=
-
-
2
,
1
1
1
( )
exp
( , )
2
(2 )
L
L
p
s
r
x
s
x
	
(4.18)

64	
Signal Estimation
Formally, the dependency on the nuisance parameters can be eliminated if we 
calculate the expected value over the nuisance parameters 
	
2
1
2
1
1
1
( )
exp
( , )
2
(2 )
1
1
exp
( , )
( )
2
(2 )
L
L
L
L
p
s
r
s
r
p
d
µ
µ
µ
ξ
µ
µ
µ
ξ
π
ξ
ξ ξ
π
=
=
=
-
-
=
-
-
x s
x
x
	
(4.19)
This is the marginal distribution for disregarding the nuisance parameters. We 
could motivate this step as an emphasis that the nuisance parameters cannot be 
well estimated and modeling them as a random variable is a reasonable approxi-
mation.  However, it should be made clear that the marginal distribution is not an 
approximation (as long as the a priori nuisance parameter distribution is exact) 
and working with (4.19) gives exact results. We will show that (4.19) models the 
coupling between the different high rate pseudorange parameters better than (4.18) 
if the CRLB is considered.
Equation (4.19) allows calculation of the true CRLB via (4.12); in practice, 
however, this calculation is impracticable because a strict evaluation of (4.19) is, in 
most cases, impossible. Therefore, several less-strict bounds have been proposed in 
the literature that are much easier to calculate.
4.2.2.1  Modified Cramér–Rao Lower Bound
A scalar lower bound of the error variance of an unbiased parameter estimator with 
the presence of nuisance parameters has been proposed, with the name modified 
Cramér–Rao lower bound (MCRLB) [5]. This bound can be easily calculated and it 
is generally looser than the CRLB. In some cases of practical interest, it approaches 
the CRLB as computed for known nuisance parameters.
Gini et al. extended the MCRLB to the estimation of a vector of nonrandom 
parameters [6]. Like the conventional CRLB, the MCRLB relies on the definition 
of a properly modified Fisher information matrix, which is the expectation (with 
respect to the nuisance parameters) of the conventional Fisher information matrix 
as computed for fixed nuisance parameters. In the following, the results obtained 
by Gini et al. shall be summarized.
The modified Fisher information matrix 
; ,i j
Ix

 is defined as
	
; ,
; ,
; ,
( )
( ) ( )
i j
i j
i j
I
I
I
p
d
ξ
ξ
ξ
ξ ξ
=
=
x
x
x

	
(4.20)
where the conventional Fisher information matrix Ix;I,,j (ξ) is given by (4.12) using 
fixed values for the nuisance parameters ξ. A particularly simple case occurs if the 
conventional Fisher information matrix does not depend on ξ, in which case the 
MCRLB equals the CRLB.

4.2  Nonrandom Parameter Estimation	
65
The variance of any unbiased estimator ˆ( )
x S  is bounded from below 
	
1
,
,
ˆ
ˆ
ˆ
var
( )
( ( )
)( ( )
)
MCRLB( )
I
ξ
ξ
*
-
=
-
-
=
x
N
N
x S
x S
x x S
x
x

	
(4.21)
This is the mathematical formulation of the MCRLB. The MCRLB is generally 
looser than the true CRLB, calculated via (4.19). This is expressed as
	
-
-
1
1
CRLB( )
MCRLB( )
I
I
x
x
x
x

	
(4.22)
It should be noted that the CRLB of Sections 4.2.1 and 4.2.2 are not identical; 
only in the second case are nuisance parameters considered at all. 
The modified Fisher information matrix satisfies Fisher’s five properties and 
thus qualifies as an information quantity (see page 60 in the book by Porat [4]). 
Fisher’s idea was to express the information carried by the density px(S) about the 
parameters x in quantitative terms. Most important, the larger the sensitivity of 
px(S) to changes in x, the larger should be the information.
A necessary and sufficient condition for the equality in (4.21) of an unbiased 
estimate ˆ( )
x S  to hold is
	
,
1
log
( )
ˆ( )
p
I
ξ
-
-
=
x
x
s
x s
x
x

	
(4.23)
which corresponds to (4.17).
4.2.2.2  Asymptotic Cramér-Rao Lower Bound
In the work of Moeneclaey, the CRLB has been investigated for signal-in-noise 
problems in the limit of infinite high signal-to-noise ratios [7]. A single useful scalar 
parameter in the presence of a vector of nuisance parameters has been considered. 
The obtained bound is called asymptotic CRLB (ACRLB). The ACRLB is more fun-
damental than the MCRLB because the ACRLB is directly derived from the CRLB 
via a series expansion in the inverse signal-to-noise ratio, whereas the derivation of 
the MCRLB is more motivated by computational simplicity. However, Moeneclaey 
has shown that the ACRLB equals the MCRLB in the case where the parameter of 
interest and the nuisance parameters are uncoupled. In the following, the results of 
Moeneclaey shall be summarized.
The derivation of the ARCLB is based on a combined Fisher information ma-
trix containing the information for the useful parameter x (here only a scalar ran-
dom variable is considered) and the nuisance parameters ξ. This Fisher information 
matrix shall be represented as Ix,ξ and is obtained by (4.12) using (4.18). We assume 
that the parameters x together with ξ are ordered such that x is the first element in 
the vector used for the definition of Ix,ξ.
The derivation first expands the second derivative with respect to x of the 
logarithm of the averaged probability density function (4.19) into a second-order 
polynomial and then evaluates the expected value with respect to N for high signal-
to-noise ratios. 

66	
Signal Estimation
The ACRLB reads as
	
ξ
ξ
ξ
*
-
-
-
-
=
1
1
, SNR
,
1,1
1
ˆ
ˆ
( ( )
)( ( )
)
ACRLB( )
((
)
)
x
x
x
x
x
I
N
S
x
S
	
(4.24)
Simplified expressions for the calculation of the first element of the inverse com-
bined Fisher information matrix are given by Moeneclaey [7]. 
The ACRLB is generally stricter than the MCRLB: 
	
ACRLB( )
MCRLB( )
x
x 	
(4.25)
Equality is achieved if the parameter x is uncoupled to the nuisance parameters 
ξ (i.e., if the coupling elements of the combined Fisher information matrix vanish). 
This is expressed as
	
, ;1,
, ; ,1
0
1
x
n
x
n
I
I
n
ξ
ξ
=
=
> 	
(4.26)
Equality is also achieved if the nuisance parameters are considered to assume 
discrete values.
4.2.2.3  Joint Cramér–Rao Lower Bound
The work by Moeneclaey also introduces the joint CRLB (JCRLB) [7]. The JCRLB 
is obtained by: (1) treating the nuisance parameters as nonrandom parameters, 
(2) jointly estimating x and ξ, (3) computing the CRLB for the useful parameter 
of interest x using the full combined Fisher information matrix Ix,ξ of Section 
4.2.2.2, and (4) averaging the obtained bound over the nuisance parameters ξ.
It should be noted that joint estimation—defined by Steps (1) and (2) above—
implies a certain way to handle the nuisance parameters. Joint estimators are thus 
only a subset of all possible useful parameter estimators. 
The JCRLB is expressed as
	
1
,
1,1
,
(
( )
)(
( )
)
(
)
JCRLB( )
ˆ
ˆ
J
J
x
x
x
x
I
x
ξ
ξ
ξ
*
-
-
-
=
N
S
x
S
	
(4.27)
The JCRLB is larger than the ACRLB (ACRLB  JCRLB). When the combined 
Fisher information matrix is not a function of ξ, the ACRLB equals the JCRLB (and 
to the CRLB). When the combined Fisher information matrix does depend on ξ, the 
ACRLB is below the average (over ξ) of the JCRLB.
The JCRLB assumes a specific-estimation strategy (the joint estimation of x and ξ), 
which is indicated by the subscript J in (4.27). The JCRLB is less general than the true, 
asymptotic, or modified CRLB. The joint estimation does not make use of the a priori 
probability density function p(ξ). In the examples of Moeneclaey [7], not using this 
information yields suboptimal estimators, especially for low signal-to-noise ratios.
4.2.2.4  Discussion
With the presence of nuisance parameters, the computation of bounds for the use-
ful parameters becomes analytically difficult because of the complex evaluation 

4.2  Nonrandom Parameter Estimation	
67
of the true CRLB based on (4.19). However, it is important to recognize that the 
provided probability density function for the nuisance parameters represents use-
ful information that should enter the computation of any bound or the estimator 
design. Ignoring this information and treating the nuisance parameters as nonran-
dom parameters may incorrectly value the influence of the nuisance parameters and 
produce bounds or estimators diverging from the true CRLB.
The presented bounds are related to each other in the sense
	
JCRLB( )
ACRLB( )
MCRLB( )
x
x
x 	
(4.28)
and
	
CRLB( )
MCRLB( )
x
x 	
(4.29)
If the combined Fisher information matrix does not depend on ξ, then
	
=
=
=
JCRLB( )
ACRLB( )
MCRLB( )
CRLB( )
x
x
x
x 	
(4.30)
In the limit of infinitely high signal-to-noise ratio, the ACRLB equals the CRLB. 
The JCRLB equals the CRLB if only a subset of all possible estimators are consid-
ered (the jointly estimating ones).
4.2.3  Single-Step Maximum Likelihood Estimation
The ML principle provides a commonly used basis to estimate parameters. Given a 
set of measured signal samples s, the position parameters ˆ( )
x s  are chosen to maxi-
mize the probability density function, which is described as
	
=
ˆ( )
arg max
( )
px
x
x s
s
	
(4.31)
In this section, we again assume that either x completely describes the received 
signal sample distribution or that the nuisance parameters have fixed known values. 
Both assumptions imply that (4.8) is valid.
For sufficiently smooth probability density functions, a necessary condition for 
the ML estimate is the likelihood equation:
	
=
=
ˆ( )
log
( )
0
px
x x s
s
x
	
(4.32)
In general, the MLE (4.31) does not have the desired optimal properties (4.4) 
and (4.5). Thus, it is a priori not clear if the MLE is an MVUE. However, the fol-
lowing two facts make it a good candidate: First, finding the positions that make 
the observations most likely is a legitimate criterion on its own [1]. Second, within 
the limit of an infinite number of samples, it can be shown, under very general as-
sumptions, that the MLE is consistent (i.e., that the estimated position converges 
in probability to the true value and thus becomes unbiased, see proposition IV.E.1 
in the book by Poor [1]). Furthermore, under some regularity conditions for the 
derivates of rm(x) with respect to x, the variance of the estimated parameters ap-

68	
Signal Estimation
proaches the inverse of Fisher’s information matrix (see proposition IV.E.2 of [1]) 
and the estimated parameter’s probability density function approaches a Gaussian 
density; that is, 
1
ˆ
( ,
)
N
I -
x
x
x
∼
. This property is called asymptotic normality of the 
MLE. A high number of samples has a similar effect to a high signal-to-noise ratio, 
thus the statement can be rephrased in the sense that, for signal-in-noise problems 
like (4.7), the ML estimates are Gaussian and achieve the CRLB for high signal-to-
noise ratios (see Example 7.6 in the book by Lehmann [3]). 
For a finite number of samples and an arbitrary (not high) signal-to-noise ratio, 
no strict mathematical theorem is available that would state that the MLE is unbi-
ased or that its variance is optimal. 
Consistency and asymptotic normality also hold if the admissible values for x 
are limited; that is, L  n. It is, however, required that the solutions of the likeli-
hood equation (4.32) converge to an isolated root and cases where the likelihood 
equation has multiple roots may require a more careful analysis. 
In the case of Gaussian noise (4.11), the likelihood equation (4.32) is written as 
	
µ
µ
µ
µ
=
-
=
÷÷
ˆ
( )
ˆ
Re
(
( ))
0
j
r
s
r
x
x x
x
x
	
(4.33)
which is equal to the least-squares (LSQ) estimate of the position x based on the 
measured samples s. It minimizes the squared differences of the signal model minus 
the received samples in the observation space. It should be noted that the solution 
of the least-squares equations (4.33) retains, in the limit of an infinite number of 
samples or high signal-to-noise ratio, the properties of consistency and asymptotic 
normality (in the same sense as for the MLE), even if the noise is non-Gaussian 
distributed (see proposition IV.E.3 in the book by Poor [1]). However, in the non-
Gaussian case, the CRLB is not given by an expression like (4.14) and better esti-
mators than the LSQ may exist. In other words, for non-Gaussian noise, the LSQ 
estimated parameter distribution approaches an unbiased Gaussian distribution 
whose covariance matrix is given by (4.14); for the non-Gaussian case, (4.14) does, 
in general, not define the Fisher information matrix. It should also be pointed out 
that, for the general case of a finite number of samples and a finite signal-to-noise 
ratio, (4.33) may have no solution at all. 
Equation (4.31) can, in principle, be used to realize a special type of GNSS 
receiver that directly solves this equation by, for example, a brute-force maximiza-
tion routine. This could be done in a special operation mode, called snapshot mode. 
A number of samples are collected (e.g., several tens of milliseconds) and, starting 
from an approximate position value, (4.31) is iteratively solved. However, to the 
author’s knowledge, no such receiver has ever been realized, but results with simu-
lated data are presented in works by Closas [8]. Snapshot receivers exist [9], but 
they determine the pseudorange for single signals first and do not directly relate the 
received signal samples to the position [10]. 
Directly estimating the position from the samples provides a number of theo-
retical advantages because the number of estimated parameters is minimal since 
no intermediate pseudorange parameters are introduced. Optimum handling of 
signal interference caused by multiple transmitted signals is ensured because the 
ML principle tries to match the sum of all replica signals to the received signal 

4.2  Nonrandom Parameter Estimation	
69
samples. In contrast a typical GNSS receiver ignores the influence of other signals 
on parameter estimates of a specific signal. It may even happen that the likelihood 
function has a clear and unique peak only if the likelihood function is expressed 
as a function of x, but not if each signal is considered separately. In this sense, the 
single-step estimation optimizes the signal-to-noise ratio.
4.2.4  Cascaded Estimation
As a direct estimation of the position via (4.31) is virtually impossible, most navi-
gation receivers subdivide the problem into several estimation steps approximat-
ing (or even being equivalent to) the full LSQ problem. One speaks of a cascaded 
estimation.
The position estimate of (4.31) is then determined in a three-step procedure: 
Estimation of high-rate pseudorange data based on the signal samples;
Estimation (or filtering) to determine synchronized low-rate pseudorange 
data;
Positioning.
If the relationship between pseudorange and position is sufficiently linear, 
cascaded-position estimation based on a high-rate pseudorange MVUE yields a 
MVUE of the position. 
4.2.4.1  Least-Squares Estimation of High-Rate Pseudorange Data
To refine the definition of the generalized high-rate pseudorange data given in Sec-
tion 4.1, we recall that the received signal samples are the sum of the transmitted 
signals, each propagating along one or more propagation paths. We assume that 
each signal for each transmitter can be described by the same number of param-
eters (see Table 4.1 and Section 1.8). Those parameters are assumed to be constant 
during short intervals. This interval may, for example, be equal to the period of 
one PRN-code period if a GNSS signal is considered. For each interval and signal, 
the high-rate pseudorange data usually consists of one value per propagation path 
each for: pseudorange (or code phase), signal power, carrier phase, and Doppler 
frequency. Collecting these values for all intervals and signals, we obtain the vector 
of generalized high-rate pseudorange data q. The vector q depends on the position 
x [i.e., q = q(x)]. For the following, we assume that this dependence can be suffi-
ciently well-linearized (by contrast, the dependence of rm on q is, in general, highly 
nonlinear). Furthermore, we make the necessary assumptions to ensure that the 
high-rate pseudorange MLE is optimal. 
The presence of possibly present nuisance parameters (actually a subset of pa-
rameters q) is not explicitly discussed here, but the methods of Section 4.2.2 will be 
adapted properly in the next section. 
The index range of signal samples during which the high-rate pseudorange data 
for a specific transmitter is constant may be different for each signal and is denoted 
as La,i. The index a denotes the different signal sources and i denotes the successive 
1.
2.
3.

70	
Signal Estimation
intervals. Similarly, we denote the corresponding set of high-rate pseudorange data 
as qa,i.
The LSQ estimate of qa,i is given by solving for all a,i simultaneously
	
,
,
,
,
,
ˆ
,
(
)
ˆ
Re
(
( ))
0
a i
a i
a i
a
a i
a i
L
r
s
r
µ
µ
µ
µ
=
-
=
q
q
q
q
q
	
(4.35)
With a similar argument as given for the LSQ position estimator (4.33), it can 
be argued that, in the limit of an infinite number of samples or high signal-to-
noise ratio, the LSQ high-rate pseudorange data estimate is optimal [i.e., it is a 
MVUE (Gaussian noise assumed)]. In this case, the probability density function of 
the high-range pseudorange data estimate approaches the Gaussian multivariate 
density N(qa,i, Iq
–1) [1]. The symbol Iq
–1 denotes the Fisher information matrix for 
the high-rate pseudorange data q.
To obtain the position estimate from the high-rate pseudorange data via an LSQ 
adjustment, we start from the following observation equation
	
=
=
+
× D
+
0
0
ˆ
(
)
x x
q
q
q
q x
x
v
x
	
(4.36)
with the following stochastic model for the high-rate pseudorange measurement 
errors vq:
	
=
= S
0,
var
q
q
q
N
N
v
v
	
(4.37)
It should be noted that the LSQ estimate does not require that the distribution 
for vq is Gaussian. The LSQ is also the best linear unbiased estimator for non-
Gaussian distributions.
If the high-rate pseudorange estimates are optimal, then 
q = Iq
–1.
The symbol 
	
=
=
÷
0
,
i
j
i j
q
x
x x
q
x
	
(4.38)
denotes the design matrix. Note, the linear approximation in (4.36) needs to be a 
sufficient approximation and the linearization point x0 needs to be sufficiently near 
the true value x. The least-squares adjustment of the observations q with respect 
to the improvements in the parameters Dx yields the best linear unbiased estimator 
(see [11]),
	
-
-
D
=
S
-
1
1
0
ˆ
ˆ
(
(
))
J
q
q
x
q
q x
x
	
(4.39)
where J denotes the normal matrix
	
-
=
S
÷
1
T
J
q
q
q
x
x	
(4.40)

4.2  Nonrandom Parameter Estimation	
71
By employing this two-step procedure (first estimating ˆq and then ˆ
Dx ), we fi-
nally obtain an estimate for the position as
	
=
+ D
0
ˆ
ˆ
x
x
x 	
(4.41)
Appendix A.1 shows that 
	
-
=
=
1
ˆ
ˆ
,
cov
J
N
N
x
x
x
	
(4.42)
and the normal matrix can be rewritten as
	
-
=
S
1
,
,
,
(
)
k
l
i j
k l
i
j
k l
q
q
J
x
x
q
	
(4.43)
4.2.4.2  Bounds for Cascaded Estimation
We define an accuracy bound for an unbiased cascaded estimator (as defined in 
Section 4.2.4.1) as the obtained accuracy of the final estimate (i.e., the position 
estimate), provided that the first estimate (i.e., the high-rate pseudorange estimate) 
achieves a given accuracy bound. For the moment, we simply assume the existence 
of a high-rate pseudorange estimator achieving a given accuracy bound (e.g., the 
CRLB, MCRLB, ACRLB, or the JCRLB). In other words, the bound for the cas-
caded estimation analyzes the effect of the LSQ adjustment of the previous Section 
4.2.4.1 compared to single-step position estimation. 
If the high-rate pseudorange estimates achieve the CRLB and the relation be-
tween q and x is sufficiently linear, the cascaded position estimate achieves the 
CRLB. This is due to a general formulation of the CRLB that considers bounds of 
functions of parameters described by Theorem 3.4 in the book by Porat [4]. The 
reader is invited to prove this statement by relating (4.14) to (4.43) using (4.2).
Furthermore, it can be shown that the LSQ adjustment does not decrease the ac-
curacy when the high-rate pseudorange estimates achieve the MCRLB. For the case 
of the ACRLB and the JCRLB (when they differ from the CRLB or the MCRLB), 
accuracy degradation caused by the LSQ adjustment cannot be excluded. 
4.2.4.3  Discussion
This section has discussed different strategies to obtain position estimates and has 
introduced several bounds on them. It has been shown that, under certain assump-
tions, the single-step estimation of the position and cascaded procedure potentially 
achieve the same “‘performance,” (i.e., the CRLB is achieved for all approaches). If 
one of the assumptions is not valid, the single-step estimation might result in a bet-
ter positioning solution compared to the cascaded procedure. The question arises: 
which practical cases may cause a violation of those assumptions? 
To answer the question, we recall that for both cases (i.e., single-step and cas-
caded procedure) the signal model (4.1) must be correct. It relates the signal samples 
to the position parameters r = r(x). For example, if multiple propagation paths are 
present, they must be included in the model to obtain an unbiased solution. In that 
sense, the direct ML approach is not superior to the cascaded approach. 

72	
Signal Estimation
More interesting is the case when the assumption of sufficient modeling (4.2) 
cannot be achieved. This is the case that occurs if the signal samples are not a 
function of delay, Doppler frequency, and phase, but show a more complex de-
pendence on the position. This is, for example, the case when the propagation 
of electromagnetic waves emitted by the GNSS transmitters (satellites) cannot be 
described by geometric optics and when complex wave-phenomena occur. A prac-
tical example could be a signal creeping of GNSS signals along an aircraft body 
[12]. But generally, in that case, the direct solution of (4.33) seems to be extremely 
demanding. 
To achieve the optimum positioning result with the cascaded procedure, it is 
necessary that the full covariance matrixes are passed from the high-rate pseudor-
ange estimation to the position estimation and that the matrices are used in the LSQ 
adjustments. This condition, however, can often not be fulfilled in practice. 
It has been assumed that the high-rate pseudorange estimators are MVUEs, 
which is achieved by ML estimation under the assumption of a high signal-to-noise 
ratio or a large number of samples. Additionally, in Section 4.7.1 we will show that, 
for uncorrelated and uniformly distributed carrier phases, a modified MLE scheme 
(a single LSQ step under the assumption that the linearity conditions of Section 
4.3.2.10 are fulfilled) achieves the CRLB for arbitrary signal-to-noise ratio values. 
If the signal model considered here can be linearized, the MLE becomes a 
MVUE (even for low signal-to-noise ratio). Furthermore, Bayesian techniques 
(e.g., a Kalman filter) can be used easily after linearization. The prerequisite 
for linearization is that good approximate values for the parameters are avail-
able. If a Kalman filter is used, the approximate values are the predicted values. 
Then the prerequisite for linearization is that the predicted parameter values—
especially the carrier phase if a coherent Kalman filter is used—are precise (see 
Section 4.5.4).
The discussion of what happens if the MLE of (4.31) or of (4.35) is not a 
MVUE is difficult. Looking for an alternative to an MLE is not easy; in fact, it is 
not always guaranteed that a MVUE (or any better estimator than the MLE) exists. 
For example, the possible strategy to construct a MVUE via sufficient statistics and 
the Rao–Blackwell–Lehmann–Scheffe theorem is of little practical value [3]. In fact, 
the vast majority of practical estimators are MLEs [3].
If no optimum estimation scheme can be provided, we may speculate that, in 
this case, the direct solution of the position via (4.33) is superior to the cascaded 
procedure; this is due to the fewer degrees of freedom involved, which thereby in-
creases the effective signal-to-noise ratio.
4.3  LSQ Correlators/Discriminators
This section contains a further analysis of the LSQ estimators for high-rate pseudo-
range data that have been defined by (4.35) in Section 4.2.4.1. Estimators for code 
phase, Doppler, carrier phase, and signal power will be derived. The effect of the 
unknown carrier phase—causing the squaring loss—will be discussed. The impor-
tance of limiting the admissible range of the estimated values will be emphasized, 

4.3  LSQ Correlators/Discriminators	
73
and various solutions (single-channel tracking, vector tracking, and reiteration) will 
be compared. After a general introduction, the section concentrates on the case 
where only one line-of-sight signal is received; in Section 4.3.5, the results will be 
discussed in further detail for one line-of-sight signal and multiple propagation 
paths.
It has already been demonstrated that the ML solution can be treated un-
der the assumption of Gaussian noise as a complex LSQ adjustment problem 
whose solution is described in Appendix A.1. As discussed in Section 4.2.3, we 
expect the LSQ estimate to be optimal if the signal-to-noise ratio is high or if 
a sufficiently large number of samples is considered. If neither condition is ful-
filled or if the noise is non-Gaussian, the LSQ estimate is still defined via (4.35) 
but has to be treated as an engineering solution, which cannot be expected 
to be optimal without further analysis. This is especially true because the sig-
nal model defined in Chapter 1 is highly nonlinear. Only if the linearization is 
carried out sufficiently near or at the true parameter values will the LSQ so-
lution achieve the CRLB due to (4.17). The linearization will be discussed in 
Section 4.3.2.10.
4.3.1  Model for One or More Propagation Paths
We assume that the deterministic part rm of the received signal samples S is modeled 
during one integration interval, given by the index range m= 1, …, L, as (see Sections 
1.6 and 1.8)
	
;
1
1
(
)exp{ (
)}
M
M
m
m m
m
m
m
m
m
r
r
a c
t
i
t
µ
µ
µ
µ
τ
ω
ϕ
=
=
=
=
-
-
	
(4.44)
The signal is a superposition of transmitted signals originating from various 
transmitters with propagation along one or more propagation paths. The index 
m uniquely identifies transmitter, propagation path, and, eventually, signal com-
ponent (e.g., a GNSS data or pilot component emitted from the same transmit-
ter). For each index m, the four fundamental signal parameters a m (amplitude), 
tm (code pseudorange in seconds), wm (angular frequency in radians per second), 
and jm (carrier-phase delay in radians) are assumed to be constant. The symbol 
tm denotes the sampling epochs given by m divided by the sample rate plus a fixed-
time offset. These signals cm(t) fulfill the condition of unity power mentioned in 
Section 1.8.1. The other conditions of Section 1.8 are, in general, (e.g., for sig-
nals with a noncontinuous power distribution in time) not fulfilled, as it might 
be impossible to find a proper symmetric sampling interval m = 1, …, L for all 
signals if they are considered over a common interval. For example, the pulses 
might be located  non-symmetrically within this interval.
For simplicity, we consider that I- and Q-components of the signal have been 
sampled. In Appendix A.2, it is shown that this is mathematically equivalent to 
sampling only one component (e.g., the I-component) with twice the sample rate. 
Both representations of the sampled signal can be transformed into each other.

74	
Signal Estimation
It is convenient to define the complex-valued signal amplitude as
	
ϕ
ω
=
-
+
exp{
}
m
m
m mid
m
a
i
i
t
a 	
(4.45)
therefore
	
1
1
(
)exp{
(
)}
(
)exp{
}
M
M
m m
m
m
mid
m m
m
m
m
m
r
a c
t
i
t
t
a c
t
i
t
µ
µ
µ
µ
µ
τ
ω
τ
ω
=
=
=
-
-
=
-
	
(4.46)
with
	
1
and
2
L
mid
mid
t
t
t
t
t
t
µ
µ
+
=
-
=
	
(4.47)
The vector of high-rate pseudorange data is composed of
	
τ
ω
τ
ω
=
1
1
1
(
...
)T
M
M
M
a
a
q
	
(4.48)
It should be noted that, for the moment, we assume that the number of re-
ceived signals m is known from a priori; that is, however, not true because the 
number of multipath signals, in particular, is difficult to determine. Estimation of 
m will be touched upon later in Section 8.3.7. Furthermore, it should be men-
tioned that, for the moment, we treat all parameters as useful parameters (see 
Section 4.1). 
Analyzing (4.35), we obtain for the derivatives the following set of equations:
	
;
;
;
(
)exp{
}
(
)exp{
}
(
)exp{
}
m
m
m
m
m
m
m
m m
m
m
m
m
m
m m
m
m
m
m
r
r
c
t
i
t
a
a
r
r
a c
t
i
t
r
r
it a c
t
i
t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
ω
τ
ω
τ
τ
τ
ω
ω
ω
=
=
-
=
= -
-
=
=
-
	
(4.49)
These derivatives are used to set up the design matrix. Please note that the apos-
trophe denotes a derivate of a function c ( ... ) and it may also denote a separate 
symbol t , as in (4.58). The first index (row) of the design matrix is denoted by m 
and is used to index the samples; the second index m (the column index) is used to 
enumerate the vector of unknowns.
To perform the LSQ adjustment, it should be noted that the vector of unknowns 
is composed of the high-rate pseudorange parameters q. In the following, only the 
symbol q is used for the unknowns (and not x, as in Appendix A.1).
The design matrix takes the form
	
=
1
(
...
)
M
A
A
A
	
(4.50)
with Am as submatrices given by

4.3  LSQ Correlators/Discriminators	
75
	
τ
ω
τ
ω
τ
ω
τ
ω
τ
ω
τ
ω
÷
÷
÷
÷
÷
÷
÷
÷
÷
÷
=
=
÷
÷
÷
÷
÷
÷
÷
÷÷
÷
;1
;1
;1
1
1
1
;2
;2
;2
2
2
2
;
;
;
m
m
m
m
m
m
m
m
m
m
m
m
m
m
m
m
m
m
m
L
L
L
m L
m L
m L
m
m
m
m
m
m
r
r
r
r
r
r
a
a
r
r
r
r
r
r
a
a
A
r
r
r
r
r
r
a
a






	
(4.51)
The observations are given by the received signal samples S of (1.15), which are 
modeled as complex-valued random variables, each (the real and imaginary compo-
nent) having unit variance as defined in (1.16). The samples are composed of the de-
terministic part rm and the thermal noise N, which is expressed in vector notation as
	
S
r
N
µ
µ
µ
=
+
=
+
S
r
N
	
(4.52)
The covariance matrix for the composite complex-valued observations is (see 
Section 1.7)
	
; ,
,
(
)(
)
2
V
Q
S
S
S
S
N N
µ υ
µ
µ
υ
υ
µ
υ
µ υ
δ
=
-
-
=
=
N
N
N
N
	
(4.53)
and the normal matrix I takes the form
	
*
*
-
*
*
÷
÷
=
=
÷÷
1
1
2
1
*
1
1
2
2
2
1
2
V
A A
A A
I
A Q
A
A A
A A


 	
(4.54)
The normal matrix has the same form as the Fisher information matrix because 
Gaussian noise is assumed. Therefore, we choose the symbol I for the normal ma-
trix (and not N); this also distinguishes it from the noise symbol.
Because of the nonlinear signal model (4.46), the LSQ problem has to be solved 
iteratively. The iterative solution of the LSQ problem starts with calculating the 
derivates of (4.51) at a first linearization point q0 that shall be denoted as 
	
τ
ω
τ
ω
=
0
1,0
1,0
1,0
...
,0
,0
,0
(
)T
M
M
M
a
a
q
	
(4.55)
The observation equations are linear in the amplitude, such that no iteration is 
required for amplitude determination alone. However, iterations may be required 
in Doppler and code-phase dimensions.
For a single iteration, the estimated corrections of the high-rate pseudorange 
data read as
	
-
*
-
-
*
D
=
-
=
-
1
1
1
0
0
1
ˆ
(
(
))
(
(
))
2
V
I
A Q
I
A
q
S
r q
S
r q
	
(4.56)
As mentioned in Appendix A.1, the estimates are complex-valued random 
variables and, after computing, code phase, and Doppler are constrained to be 
real-valued. The complex-valued estimated amplitudes shall be separated into the 
real-valued amplitude and the estimated carrier phase after the adjustment. A real 
valued signal model might seem to be better because it avoids the use of complex-

76	
Signal Estimation
valued signal parameter, but Appendix A.1.4 shows that the separation can be 
performed very easily if the parameters are uncorrelated.
Equation (4.56) represents a signal-processing technique that fully accounts for 
signal correlations. Replica signals given by the term r(q0) are subtracted from the 
received samples before correlating them with the reference signals given by (4.49). 
This is equal to a parallel interference cancellation scheme [13]. Via the nondiago-
nal form of I, (4.56) accounts for correlations between the estimated parameters for 
different transmitted signals.
For a further evaluation of this LSQ problem, we need to make specific assump-
tions on the received signals. In Section 4.3.2, a detailed analysis for the case of 
m = 1 will be presented. 
4.3.2  Single Propagation Path
For the case of a single propagation path (m = 1), the normal matrix takes the form
	
*
=
1
1
1
2
I
A A 	
(4.57)
This is a complex-valued 3 × 3 matrix. 
Here, we assume that the integration interval is chosen symmetrically with respect to 
the received signal power such that all assumptions on c(t) made in Section 1.8 are ful-
filled. Because of the definition in (4.47), we write for the centered sampling epochs tµ′
	
1
2
s
L
t
f
µ
µ
+
=
-
÷
	
(4.58)
Starting from (4.55) and using the assumptions of Section 1.8, the elements of 
I read as
	
2
1,1
1
1,0
1
1
1
1
1,2
2,1
1,0
1
1,0
1
1,0
1
1
1
1
2
1,3
3,1
1,0
1
1,0
1
1
1
1
2
2,2
1,0
1
1
1
1
2
(
)
2
2
(
)
(
)
0
2
2
(
)
0
2
(
L
L
L
L
L
L
L
r
r
I
c t
L
a
a
r
r
I
I
a
c t
c
t
a
r
r
I
I
ia
t
c t
a
r
r
I
a
c
t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
τ
ω
τ
τ
=
=
=
=
=
=
=
=
=
-
=
=
= -
-
-
=
=
= -
-
=
=
1
1
2
2
2
1,0
1,0
,
1,0
,
1
2
3,2
2,3
1,0
1
1,0
1
1,0
1
1
1
1
2
2
2
3,3
1,0
1
1,0
1
1
1
1
3
3
2
1,
1,0
2
)
(0)
(0)
2
2
(
)
(
)
0
2
(
)
(
)
12
L
c c
c c
L
L
L
L
freq
freq
s
a
LR
a
LR
r
r
I
I
i a
t c t
c
t
r
r
I
a
t
c t
L a
L
L
a
f
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
ω
τ
τ
ω
ω
χ
χ
=
=
=
=
=
-
= -
=
=
=
-
-
=
=
-
-
2
0
2
12 sf
	
(4.59)

4.3  LSQ Correlators/Discriminators	
77
or in matrix notation as
	
χ
÷
÷
-
÷
÷
1
1
2
,
1,0
2
2
2
1,0
1
0
0
2
0
(0)
0
0
0
(12
)
c c
freq
s
I
L
R
a
a
L
f
	
(4.60)
The inverse normal matrix is given by
	
1
2
,
1,0
2
2
3
1,0
2
0
0
2
0
0
(0)
24
0
0
c c
s
freq
L
I
LR
a
f
a
L
χ
-
÷
÷
÷
÷
÷
-
÷
÷
÷
÷
	
(4.61)
Because I is a diagonal matrix, amplitude, code phase, and frequency estimates are 
independent of each other. This is a consequence of the assumptions of Section 1.8.
From this point forward, all approximate equal signs  will be replaced by 
equal signs ‘=’ for the sake of simplicity. 
4.3.2.1  Estimated Parameter Improvements
After setting up the design matrix, the LSQ adjustment can be started, taking (4.55) 
as the starting point. In each step, parameter improvements are calculated that are 
added to the a priori values. The following equations are formulated for the first 
iteration but can be extended for subsequent iterations.
The estimated improvement in the complex amplitude is given as
	
1,0
0
1
1
1
1,0
1,0
1,0 1
1,0
1,0
1
1
1,0
1,0
1,0
1
1
ˆ
(
(
))
1
(
)exp{
}(
(
)exp{
})
1
(
)exp{
}
L
L
L
r
a
S
r
L
a
c t
i
t
S
a
c t
i
t
L
c t
i
t
S
a
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
ω
τ
ω
τ
ω
=
=
=
D
=
-
=
-
-
-
-
=
-
-
-
q
	
(4.62)
and the estimated amplitude after the first iteration is given by
	
1,0
1,0
1,0
1
1,0
1,0
1
1
ˆ
ˆ
(
)exp{
}
L
a
a
a
c t
i
t
S
L
µ
µ
µ
µ
τ
ω
=
=
+ D
=
-
-
	
(4.63)

78	
Signal Estimation
For the estimated code-phase improvement, we obtain
	
1
1
1
1
1
1
1,0
0
2
1
1
,
1,0
1,0
2
,
1,0
1
1,0
1,0
1,0 1
1,0
1,0
1
1
1,0
1,0
1
,
1,0
,
1
ˆ
(
(
))
(0)
(0)
(
)exp{
}(
(
)exp{
})
1
1
(
)exp{
}
(0)
(0)
L
c c
c c
L
L
c
c c
c c
r
S
r
LR
a
a
LR
a
c
t
i
t
S
a
c t
i
t
c
t
i
t
S
R
LR
a
LR
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
ω
τ
ω
τ
ω
=
=
=
-
D
=
-
=
-
-
-
-
=
-
-
-
q
1
1
1
1
,
1
1,0
1,0
1
,
1,0
(0)
1
(
)exp{
}
(0)
c
L
c c
c
t
i
t
S
LR
a
µ
µ
µ
µ
τ
ω
=
=
-
-
	
(4.64)
and for the estimated frequency improvement:
	
1,0
0
2
3
1
1
1,0
1
1,0
1,0
1,0 1
1,0
1,0
3
1,0
1
1
1,0
1,0
3
1,0
1
3
12
ˆ
(
(
))
12
(
)exp{
}(
(
)exp{
})
12
(
)exp{
}
12
L
s
freq
L
s
freq
L
s
freq
s
freq
r
f
S
r
a
L
i
f
t c t
i
t
S
a
c t
i
t
a
L
i
f
t c t
i
t
S
a
L
i
f
t
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
ω
ω
χ
τ
ω
τ
ω
χ
τ
ω
χ
χ
=
=
=
D
=
-
-
=
-
-
-
-
= -
-
-
+
-
+
q
1
1,0
1
1,0
1
1
1,0
1,0
3
1,0
1
(
)
(
)
12
(
)exp{
}
L
L
s
freq
c t
c t
i
f
t c t
i
t
S
a
L
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
ω
χ
=
=
-
-
= -
-
-
	
(4.65)
The estimated frequency and code phase after the first iteration are given by
	
1,0
1,0
1,0
1,0
1,0
1,0
ˆ
ˆ
ˆ
ˆ
τ
τ
τ
ω
ω
ω
=
+ D
=
+ D
	
(4.66)

4.3  LSQ Correlators/Discriminators	
79
4.3.2.2  Iteration
Due to the nonlinear signal model (4.46), it is, in general, necessary to repeat a LSQ 
procedure until the estimated parameters converge. The iteration can be written for 
k > 0 as
	
1,
1
1,
1,
1,
1
1,
1,
1,
1
1,
1,
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
k
k
k
k
k
k
k
k
k
a
a
a
τ
τ
τ
ω
ω
ω
+
+
+
=
+ D
=
+ D
=
+ D
	
(4.67)
At this point it should be noted that, after the first iteration, the a priori values 
become themselves random variables because they depend on the signal samples. 
This will finally result in what is referred to as “squaring loss” and will be discussed 
in detail below.
Formally, the parameter iteration is written as
	
τ
τ
=
1,*
1,
ˆ
ˆ
lim
k
k
	
(4.68)
and is similar for Doppler and amplitude. 
4.3.2.3  How to Evaluate the LSQ Parameter Variance
Within the framework of a LSQ adjustment, the variance of the estimated param-
eters is given by the inverse of the normal matrix. The normal matrix (4.54) equals 
the Fisher information matrix, so in a first approximation we would expect that the 
estimated LSQ parameters achieve the CRLB. 
However, this is strictly true only if the linearization point q0 is a deterministic 
quantity and if the linearization point is sufficiently near the true values. During the 
iterations in the LSQ adjustment, the linearization point q0 becomes dependent on 
the estimated parameters (which themselves depend of the signal samples) and has 
to be regarded as a random variable. Therefore, the LSQ estimates generally have 
an increased variance when iterations are required.
In a standard LSQ adjustment, the influence of stochastic parameters used to 
setup the design matrix is ignored. This can be justified if the observation equations 
can be linearized and the linearization is a good approximation to the true nonlin-
ear observation equations. For a linear problem, the iteration converges after one 
step and (4.17) holds. In the case of the nonlinear high-rate pseudorange param-
eter-estimation problem discussed here, this linearity assumption is true if the signal 
power is high and the accuracy of the estimated parameters is high. Then the design 
matrix can be considered as nonrandom. This is in accordance with the asymptotic 
properties of any MLE, as discussed in Section 4.2.3. If the signal power becomes 
low, or errors in the estimated parameters are in a range that they cannot be ignored 
when building the design matrix, the standard LSQ error propagation method [see 
(A.29)] should not be used. This is especially important for the signal amplitude 
estimate. In that case, the formulas for the estimated parameter variance have to be 
modified and the squaring loss appears. The squaring loss generally increases the 

80	
Signal Estimation
variance and is interpreted as a contribution to the parameter variance because of 
signal-amplitude errors when setting up the design matrix.
It should be noted that the squaring loss is usually interpreted from an engineer-
ing point of view. As noted elsewhere [14, 15], the squaring loss originates from a 
nonlinear operation (e.g., multiplication) of a coherent discriminator with the punc-
tual correlator to remove the carrier-phase dependency of the discriminator [16]. 
4.3.2.4  Cramér–Rao Lower Bound Without Nuisance Parameters
In the next step, the variance of the estimated parameters assuming a nonrandom 
design matrix shall be evaluated. The obtained variances correspond to the CRLB 
if we treat all four parameters (code phase, Doppler, carrier phase, and amplitude) 
as useful nonrandom parameters. 
Bounds can only be computed for a Gaussian noise amplitude distribution, 
which shall be assumed here. Fisher’s information matrix is therefore given by the 
normal matrix (4.60). Equivalently, we treat the design matrix as a nonrandom 
quantity that is set up using the true parameter values. Therefore, it is sufficient to 
analyze the first iteration only. 
The definition of the stochastic noise properties in (4.53) relates the signal am-
plitude to the C/N0 value by (see also Section 1.8.1)
	
=
2
0 1
1
2(
/
)
s
C N
a
f
	
(4.69)
Recall that the index m = 1 enumerates the signal. 
The variances of the estimated signal parameters are the diagonal elements of 
the inverse normal matrix given by (4.61).
The variance of the estimated (complex-valued) signal amplitude is given by
	
D
=
1,0
2
ˆ
var
a
L
N
	
(4.70)
It should be recalled that the complex amplitude contains information on the 
C/N0 value and the carrier phase. Below, the complex amplitude will be separated 
into these two components and their variances will be discussed. First, however, the 
variance of the code phase and Doppler estimates will be calculated.
The variance of the estimated code phase is given by
	
1
1
1
1
1
1
1,0
2
,
0 1
,
1,0
,
0 1
2
ˆ
var
(0)(
/
)
(0)
1
(0)(
/
)
s
c c
c c
coh
c c
f
LR
C N
LR
a
T
R
C N
τ
D
=
=
-
-
=
-
N
	
(4.71)
where the coherent integration time Tcoh is the ratio of the number of samples L 
divided by the sample rate fs. Note that this variance applies to the complex-valued 

4.3  LSQ Correlators/Discriminators	
81
code-phase estimate. According to Appendix A.1, the variance of the real-valued 
code phase estimated is half of (4.71), which is the CRLB for the code-phase esti-
mate in square seconds
	
τ
D
=
-
1
1
1,0
,
0 1
1
ˆ
var Re{
}
2
(0)(
/
)
coh
c c
T
R
C N
N
	
(4.72)
Similarly, we obtain for the Doppler variance in square radians per second 
squared
	
ω
χ
D
=
2
1,0
3
0 1
6
ˆ
var Re{
}
(
/
)
coh
freq
T
C N
N
	
(4.73)
4.3.2.5  Cramér–Rao Lower Bound with Nuisance Parameters
Fisher’s information matrix (4.60) is diagonal and depends on the signal power but 
not on the carrier phase. Therefore, if we consider the carrier phase as a nuisance 
parameter, the MCRLB, ACRLB, and the JCRLB for code phase and Doppler are 
also given by (4.72) and (4.73). Note, however, that the true CRLB may be different 
from those expressions if the carrier phase is considered as a nuisance parameter.
If the signal power is also considered as a nuisance parameter, the MCRLB and 
the ACRLB equal each other because the amplitude is uncoupled with Doppler and 
code phase. Furthermore, the Fisher information matrix depends linearly on the 
signal power, such that the MCRLB is given by (4.72) and (4.73) if the C/N0 value 
is replaced by its expected value with respect to its a priori distribution. Consider-
ing the JCRLB, it is easy to recognize that, for example, the code phase JCRLB is 
written as
	
(
)
τ
D
=
-
1
1
1
0 1
0 1
0 1
,
1
1
ˆ
Re{
}
((
/
) ) ((
/
) )
(
/
)
2
(0)
coh
c c
JCRLB
p C N
d C N
C N
T
R
	
(4.74)
where p((C / N0)1) is the a priori probability distribution for the signal-to-noise 
ratio. In contrast to the MCRLB or the ACRLB, the JCRLB depends not only on 
the mean signal-to-noise ratio, but also on its distribution. The less stringent the 
distribution, the larger the difference between the JCRLB and the MCRLB. If (C / 
N0)1 is from N(C, σ 2), then for small values of σ 2, 
	
1
1
2
1
2
,
1
ˆ
(Re{
})
1
2
(0)
coh
c c
JCRLB
C
T
R
C
σ
τ
D
+
÷
-
	
(4.75)
4.3.2.6  Squaring Loss Affecting the Code-Phase LSQ Estimate
To assess the influence of the estimated parameters on the LSQ design matrix in 
the sense of Section 4.3.2.3, a simplified iteration procedure will be assumed. The 

82	
Signal Estimation
LSQ adjustment is iterated and in each step the design matrix is recalculated using 
the signal amplitude estimate from the last step. The influence of code-phase errors 
and Doppler errors on the design matrix is not considered, and the initial values t1,0 
and w1,0 are retained. Their influence will be discussed later in Section 4.3.2.10. The 
iteration starts at any nonzero value of the amplitude.
The simplified iteration procedure converges after the first iteration because the 
observation equation for the complex signal amplitude is linear. 
Let us examine (4.64), which describes the code-phase improvement. After the 
iteration has converged, this equation will take the form
	
1
1
1,*
1
1,0
1,0
1
,
1,*
1
ˆ
(
)exp{
}
ˆ
(0)
L
c c
c
t
i
t
S
LR
a
µ
µ
µ
µ
τ
τ
ω
=
D
=
-
-
	
(4.76)
where the subscript “*” denotes the converged values. The initial value for the 
complex amplitude a1,0 has been replaced by the converged estimated amplitude 
value 1,*
ˆa
. 
To calculate the variance of the code-phase estimate obtained with the con-
verged amplitude estimate, we rewrite (4.76) as
	
1
1
1
1
1,*
1,0
1,0
1,0
1,*
1,*
1
,
1
1
ˆ
ˆ
(
)exp{
}
ˆ
ˆ
(0)
L
c c
a
a
c t
i
t
S
a
a
LR
a
µ
µ
µ
µ
τ
τ
ω
τ
=
D
=
-
-
=
D
	
(4.77)
The estimated signal amplitude and the code-phase improvement are uncor-
related, as can be seen from (4.60). Because the expected value of the code-phase 
improvement vanishes, the following equation holds
	
τ
τ
τ
D
=
D
=
D
=
1
1
1,*
1,0
1,0
1,*
1,*
ˆ
ˆ
ˆ
0
ˆ
ˆ
a
a
a
a
	
(4.78)
Note that now and for the rest of the squaring loss discussion, the subscript N 
is omitted from the expectation values and all expectation values are understood 
with respect to the thermal noise.
For the variance we obtain
	
τ
τ
τ
D
=
D
=
D
2
2
2
2
1
1
1,*
1,0
1,0
1,*
1,*
ˆ
ˆ
ˆ
ˆ
ˆ
a
a
a
a
	
(4.79)
The first term of the product in the above equation is the squaring loss. If 
the estimated value of the signal amplitude is precise (i.e., 1,*
ˆa
= a1), the squaring 
loss will be 1 (= 0 dB). This stands in analogy to the JCRLB of Section 4.3.2.5. 

4.3  LSQ Correlators/Discriminators	
83
For the general case (i.e., 
1,*
1
ˆa
a ), we perform a Taylor series expansion 
as
	
2
2
2
2
1,*
1
1
1
1,*
1
1,*
1,*
1
1
1
1
2
1,*
1,*
1
1,*
1
2
1
1
1
ˆ(
)
1
1
ˆ(
)
ˆ
ˆ(
)
1
ˆ
var
ˆ
ˆ
(
)
(
)
1
2Re
1
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
-
=
=
-
-
-
+
+
-
-
=
-
+
=
+
	
(4.80)
Using (4.61) and (4.69), we obtain the squaring loss,
	
=
+
=
+
2
1
1,*
0 1
0 1
1
1
1
ˆ
(
/
)
(
/
)
s
coh
a
f
a
L C N
T
C N
	
(4.81)
The squaring loss decreases with increasing C/N0 and with an increasing coher-
ent integration time Tcoh.
Finally, the variance of the LSQ code-phase estimate (i.e., the real part of the 
complex-valued random variable) evaluates to
	
1
1
2
2
1
2
1,*
1,0
1,*
0 1
,
0 1
1
ˆ
ˆ
Re{
}
ˆ
2
1
1
1
(
/
)
2
(0)(
/
)
coh
coh
c c
a
a
T
C N
T
R
C N
τ
τ
D
=
D
=
+
÷
-
	
(4.82)
The first part of this equation is equal to the code-phase CRLB (without nui-
sance parameters), the second is the squaring loss. Similar equations are derived 
elsewhere [16, 17].
4.3.2.7  Squaring Loss Affecting the Doppler LSQ Estimate
Comparison of (4.65) with (4.64) shows that the squaring loss affecting the Dop-
pler frequency estimate has the same form as (4.81):
	
2
2
2
1
1,*
1,0
1,*
ˆ
ˆ
ˆ
a
a
ω
ω
D
=
D
	
(4.83)

84	
Signal Estimation
Taking the real component of the complex-valued random variable yields
	
2
2
1,*
2
3
0 1
1,0
3
3
3
0 1
0 1
0 1
0 1
12
1
ˆ
Re{
}
1
(
/
)
6
1
6
1
1
1
(
/
)
(
/
)
(
/
)
(
/
)
s
coh
freq
s
coh
coh
freq
coh
freq
f
T
C N
L a
f
T
C N
T
C N
L C N
T
C N
ω
χ
χ
χ
D
=
+
÷
=
+
=
+
÷
÷
	
(4.84)
Again, the Doppler variance is given by the product of the CRLB multiplied by 
the squaring loss. The factor χfreq measures the nonuniformity of the signal-power 
distribution in time and is defined in Section 1.8.3. The CRLB obtained here cor-
responds to equation (16) of the article by Rife and Boorstyn under the assumption 
that the phase is unknown [18]. 
4.3.2.8  Squaring Loss Affecting the Carrier-Phase LSQ Estimate
What remains is to analyze the squaring loss on the signal-amplitude LSQ es-
timate itself. First, we have to note that the real and imaginary components of 
the complex signal amplitude itself are not affected by a squaring loss because 
the estimated complex amplitude is independent on the assumed amplitude a 
priori value. However, the squaring loss enters when the magnitude and phase are 
evaluated.
To calculate the estimated phase we assume (without a loss of generality) that 
the imaginary part of the true signal amplitude vanishes. A second-order Taylor se-
ries expansion is performed in the difference of the estimated minus the true values. 
To formalize this series expansion, the temporary parameter e is introduced. The 
expansion is given as
	
1,*,
1
1,*
1,*,
1,*,
1,*,
1,*,
1,*,
1,
1
2
2
1,*,
1,
1,
1,
1,
ˆ
ˆ
tan
ˆ
ˆ
ˆ
ˆ
ˆ(
)
tan
ˆ(
)
im
re
im
im
im
re
re
re
re
re
re
re
a
a
a
a
a
a
a
a
a
a
a
a
ϕ
ε
ε
ε
ε
-
-
=
÷
-
=
+
÷
-
+
	
(4.85)
The parameter e is a pure auxiliary parameter for the Taylor series expansion. 
It tags the signal-amplitude estimation errors and is used to collect terms that are 
proportional to the estimation errors, terms that are proportional to the squared 
estimation errors, and so on. After performing the series expansion, the parameter 
e is ignored (set to 1) and we obtain
	
ϕ
-
+
1,*,
1,*,
1,*,
1,
1,*
2
1,
1,
ˆ
ˆ
ˆ(
)
ˆ
im
im
re
re
re
re
a
a
a
a
a
a
	
(4.86)
Real and imaginary signal amplitudes are unbiased and uncorrelated random 
variables, thus
	
ϕ1,*
ˆ
0	
(4.87)

4.3  LSQ Correlators/Discriminators	
85
The variance is given as 
	
2
1,*,
1,*,
1,*,
1,
2
1,*
2
1,
1,
2
2
2
2
1,*,
1,*,
1,*,
1,
1,*,
1,*,
1,
3
4
1,
1,
1,
2
1,*
1,*
1,*
1,*
2
4
2
2
1
1
1
1
ˆ
ˆ
ˆ(
)
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
(
)
(
)
2
ˆ
ˆ
ˆ
ˆ
var
var
var
var
1
2
4
2
2
im
im
re
re
re
re
im
im
re
re
im
re
re
re
re
re
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
ϕ
-
+
÷
-
-
=
+
+
÷
=
+
=
+
2
2
0 1
0 1
1
1
0 1
0 1
1
1
1
1
2 (
/
)
2 (
/
)
1
1
1
2
(
/
)
2
(
/
)
s
s
coh
coh
f
f
L C N
L C N
L a
L a
T
C N
T
C N
÷÷
=
+
=
+
÷
÷
÷
=
+
÷
	
(4.88)
Note that the following identify holds for a complex-valued random variable
	
=
-
=
1,*
2
2
1,*,
1,*,
1,
ˆ
var
ˆ
ˆ(
)
2
im
re
re
a
a
a
a
	
(4.89)
whose expected imaginary part vanishes. Furthermore, all random variables in-
volved in this expression are Gaussian due to the large number of involved samples. 
Uncorrelated Gaussian random variables are stochastically independent.
Again, a term similar to the squaring loss enters because, in general, 1,*,
1,
ˆ
re
re
a
a
. 
Otherwise, the second-order term in (4.85) would vanish.
Equation (4.88) gives the variance of a carrier-phase estimate, being the prod-
uct of the carrier-phase CRLB and the squaring loss. This equation also shows that 
the carrier-phase variance expressed in square radians is independent of the carrier 
frequency or the waveform c(t). An identical expression to (4.88) was derived in 
[16] using a different methodology and using a Taylor series expansion up to the 
third order.
4.3.2.9  Estimating the Signal Power
The estimated squared signal magnitude is related  to the C / N0 value and given by
	
2
2
2
2
1,*
1,*
1,*,
1,*,
1,
1,
2
2
2
1,*,
1,
1,*,
1,
1,
1,*,
1,
ˆ
ˆ
ˆ
ˆ
((
)
)
ˆ
ˆ
ˆ
2
(
)
(
)
im
re
re
re
im
re
re
re
re
re
re
b
a
a
a
a
a
a
a
a
a
a
a
a
=
=
+
-
+
=
+
-
+
+
-
	
(4.90)
We assume (without loss of generality) that the imaginary true value a1,im of 1,*
ˆa
 
vanishes. The squared signal-magnitude estimate evaluates to

86	
Signal Estimation
	
1,*
2
2
2
1,*
1
1,*
1
2
1
2
1
0 1
ˆ
var
ˆ
ˆ
var
1
1
1
(
/
)
coh
a
b
a
a
a
a
a
T
C N
=
+
=
+
÷÷
=
+
÷
	
(4.91)
A C / N0 estimator is obtained by scaling this expression with the sample rate:
	
=
+
=
+
÷
-
=
÷
0 1
0 1
2
1,*
0 1
2
1,*
0 1
2(
/
)
1
2(
/
)
2
ˆ
1
(
/
)
2
ˆ
(
/
)
2
s
coh
s
s coh
s
s coh
C N
C N
b
f
T
C N
f
f T
f
b
C N
f T
	
(4.92)
An unbiased C / N0 estimator is therefore given as
	
 =
-
÷
2
0
1,*
1
2
ˆ
(
/
)
2
s
s coh
f
C N
a
f T
	
(4.93)
The variance of the C / N0 estimator is given as
	

=
=
2
2
2
2
0
1,*
1,*
1
ˆ
ˆ
var (
/
)
var
var
4
4
s
s
f
f
C N
a
b
	
(4.94)
The variance of 
2
1,*
ˆb
 shall be evaluated in the following by expanding the com-
plex-valued random variable into its real- and imaginary-valued components 
	
(
)
(
)
2
2
2
2
2
2
1,*
1,*,
1,*,
1,*,
1,*,
2
2
2
2
2
1,*,
1,
1,*,
1,
1,*,
1,*,
1,
1,*,
1,
1,*,
2
2
1,*,
1,
1,
1,*,
1,
1,*,
1,*,
ˆ
ˆ
ˆ
ˆ
ˆ
var
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
(
)
2
(
)
2
ˆ
ˆ
ˆ
ˆ
(
)
2
(
)
(
re
im
re
im
re
re
re
re
im
re
re
re
re
im
re
re
re
re
re
im
re
b
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
=
+
-
+
=
-
+
+
-
-
+
+
=
-
+
-
+
-
-
(
)
2
2
2
1,
1,*,
ˆ
)
re
im
a
+
	
(4.95)
Because for any zero-mean Gaussian random variable any moment of uneven 
order vanishes, and because the real and imaginary part of the complex-amplitude 
estimate 1,*
ˆa
 are uncorrelated, we can rewrite the equation as

4.3  LSQ Correlators/Discriminators	
87
	
(
)
(
)
2
1,*
2
2
2
2
2
1,*,
1,
1,
1,*,
1,
1,*,
1,*,
1,
1,*,
2
2
1,*,
1,
1,*,
1,
1,
1,*,
1,
2
2
2
1,*,
1,*,
4
1,*,
1,
ˆ
var
ˆ
ˆ
ˆ
ˆ
ˆ
(
)
2
(
)
(
)
ˆ
ˆ
ˆ
(
)
(
)
2
(
)
ˆ
ˆ
ˆ
ˆ
(
)
(
re
re
re
re
re
im
re
re
im
re
re
re
re
re
re
re
im
im
re
re
b
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
=
-
+
-
+
-
-
-
=
-
-
-
+
-
+
-
=
-
-
2
2
2
2
1,*,
1,
1,
1,*,
1,
2
4
2
1,*,
1,*,
ˆ
)
4
(
)
ˆ
ˆ
re
re
re
re
re
im
im
a
a
a
a
a
a
-
+
-
+
-
	
(4.96)
Using the identity 
	
=
2
4
2
3
x
x
	
(4.97)
being a special case of
	
π
-
+
+ -
G
÷
=
2
/ 2
2
2
1
2
(1
( 1) )
2
n
n
n
n
n
x
x
	
(4.98)
which holds for any real-valued zero-mean Gaussian random variable, yields
	
=
-
+
-
+
2
2
2
2
2
2
2
1,*
1,*,
1,
1,
1,*,
1,
1,*,
ˆ
ˆ
ˆ
ˆ
var
2 (
)
4
(
)
2
re
re
re
re
re
im
b
a
a
a
a
a
a
	
(4.99)
and by (4.61) the equation is evaluated as
	
=
+
+
=
+
0 1
2
2
1,*
1,
2
2
2
2
1
2
4
8(
/
)
ˆ
var
4
re
s
C N
b
a
L
Lf
L
L
L
	
(4.100)
According to (4.94), the variance of the C / N0 estimator is obtained by multi-
plying (4.100) with fs
4 / 4, yielding
	

2
0 1
0 1
2
2
0 1
0 1
2
2
4
8(
/
)
var (
/
)
4
2 (
/
)
1
1
(1
2
(
/
) )
s
s
s
coh
s
coh
f
C N
C N
Lf
L
f
L C N
T
C N
f
L
T
=
+
÷
=
+
=
+
÷
	
(4.101)

88	
Signal Estimation
The same expression was obtained, experimentally analyzed, and compared to 
a differential C / N0 estimator in the work [19]. For the relative signal-power vari-
ance, the expression
	

=
+
÷
0 1
0 1
0 1
0 1
(
/
)
2
1
var
1
(
/
)
(
/
)
2
(
/
)
coh
coh
C N
C N
C N
T
T
C N
	
(4.102)
is derived from (4.101). It shows the same structure as for the code-phase, Doppler, 
and carrier-phase estimate; the term within the parenthesis could be interpreted as 
a squaring loss.
4.3.2.10  Doppler and Code-Phase Error Limits—Linearity Conditions
The above section showed that errors in the signal-amplitude LSQ estimate in-
crease the variance of other-parameter LSQ estimates (code-phase and Doppler) 
because the signal-amplitude estimate is part of the design matrix and normal 
matrix. The question arises whether additional errors in the Doppler or code-
phase estimate can cause an even further increase in the estimated parameter 
variances.
This section proves (under certain assumptions called linearity conditions) that 
this is not the case and that estimation errors in the code phase or Doppler do not 
increase the variance of other parameters. Therefore, there is no analog expression 
for the squaring loss in case Doppler or code-phase errors are considered. The rea-
son lies in the fact that the normal matrix (4.60) depends on the signal amplitude 
but not on the code phase or Doppler. This shall be discussed in the following 
statements.
We assume that q denotes the true parameter values and, although the design 
matrix Aq depends on q, the normal matrix I is independent of it. We assume that 
q contains the code-phase and the Doppler but not the signal amplitude. Thereby, 
we completely separate the complex amplitude estimation problem from the code-
phase/Doppler estimation problem. 
According to (4.17), the LSQ estimator using the true (but unknown) code-
phase and Doppler values to set up the design matrix and the signal model is written 
as
	
-
*
=
+ D
=
+
-
1
1
ˆ
ˆ
(
( ))
2 I
Aq
q
q
q
q
S
r q
	
(4.103)
and achieves the CRLB. However, this estimator cannot be used in practice and the 
normal matrix and the signal model is set up with different parameters that shall be 
denoted now as q0. The assumed parameter values differ from the true values by
	
δ
=
-
0
0
q
q
q	
(4.104)
The LSQ problem then yields the solution 
	
-
*
=
+ D
=
+
-
0
1
0
0
0
0
0
1
ˆ
ˆ
(
(
))
2 I
Aq
q
q
q
q
S
r q
	
(4.105)

4.3  LSQ Correlators/Discriminators	
89
In the following, we derive a condition that needs to be fulfilled to have 0
ˆ
ˆ
=
q
q; 
that is, to ensure that the Doppler and code-phase estimates are MVUEs even if the 
true code-phase and Doppler values are not used to set up the design matrix and 
the signal model.
Due to the assumptions of Section 1.8 for any value of q and m = 1,
	
*
=
( )
0
Aq r q
	
(4.106)
The requirement of equal estimates reads as
	
δ
-
*
*
=
-
=
+ D
-
- D
=
+
-
0
1
0
0
0
0
1
ˆ
ˆ
ˆ
ˆ
0
(
)
2 I
A
A
q
q
q
q
q
q
q
q
q
S
S
	
(4.107)
which translates using a model for the signal samples to
	
0
0
1
0
1
1
(
( ( )
)
( ( )
))
2
1
(
( ( )
))
2
I
A
A
I
A
A
δ
-
*
*
-
*
*
=
+
-
+
=
-
+
q
q
q
q
q
r q
N
r q
N
N
r q
N
	
(4.108)
Taking the expected value with respect to the noise, we obtain the linearity 
condition
	
δ
-
*
= -
0
1
0
1
( )
2 I
Aq
q
r q
	
(4.109)
an equation being independent of the noise terms that can rewritten as
	
δ
*
-
=
0
0
( )
2
A
I
q r q
q 	
(4.110)
Inserting (4.110) into (4.108) yields
	
*
*
=
-
0
0
(
)
A
A
q
q
N
N 	
(4.111)
Now we will prove that (4.111) is also fulfilled if (4.110) is fulfilled. We show 
that the variance of (4.111) vanishes because the derivative of (4.110) with respect 
to q yields
	
δ
*
*
-
=
=
0
0
0
(
( ))
(2
)
2
A
I
A
A
I
q
q
q
r q
q
q
q
	
(4.112)
Therefore,
	
0
0
0
0
0
0
0
var
(
)(
)
2(
)
0
A
A
A
A
A
A
A A
A
A
A
A
A A
*
*
*
*
*
*
*
*
*
*
-
=
-
-
=
+
-
-
=
q
q
q
q
q
q
q
q
q
q
q
q
q
q
N
N
N
N N
N
	
(4.113)

90	
Signal Estimation
Altogether, this shows that, as long as the linearity condition (4.110) is fulfilled, 
code-phase and Doppler errors in the setup of the design matrix do not degrade 
the estimation results and (4.107) is fulfilled. The discussion can also be seen as an 
interpretation of (4.17) in the context of LSQ adjustment.
An explicit expression for the linearity condition is derived by an analysis of 
the product of the design matrix with the deterministic signal model. Because the 
complex amplitude is assumed to be known, the product reads as
	
0
0
0
1
1
1
1
1
1
2
1
1
1,0
1
1
1
1,0
1
2
1
1
1,0
1
1
1
1,0
1
2
1
,
1,0
( )
( )
( )
( )
( )
(
) (
)exp{
(
)}
(
) (
)exp{
(
)}
(
L
L
L
L
c c
r
r
A
r
r
a
c
t
c t
it
i a
t c t
c t
it
a
LR
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
ω
τ
τ
ω
ω
τ
τ
ω
ω
τ
=
=
*
=
=
=
=
÷
÷
=
÷
÷
÷
-
-
-
-
÷
÷
=
÷
÷
-
-
-
-
÷
=
q q
q
q q
q
q
r q
q
q
1
1
1,0
2
1
1
1,0
1
1
1
1,0
1
) (
)
(
) (
)exp{
(
)}
L
i a
t c t
c t
it
µ
µ
µ
µ
µ
τ κ ω
ω
τ
τ
ω
ω
=
-
-
÷
÷
-
-
-
-
÷
	
(4.114)
On the other hand, (4.60) yields
	
1
1
2
,
1
1,0
1
0
2
3
1
1,0
1
(0)
(
)
2
(12 )(
)
c c
freq
s
LR
a
I
a
L
f
τ
τ
δ
χ
ω
ω
-
-
÷
=
÷
-
q
	
(4.115)
and we assume that the normal matrix I is set up using the true complex signal-
amplitude value. Setting both equations equal yields two equations: the code-phase 
linearity condition and the Doppler linearity condition.
The code-phase linearity condition is a linearity requirement for the first deri-
vate of the correlation function, written as
	
1
1
1
1
,
1,0
1
,
1,0
1
1
1,0
(0)(
)
(
) (
)
c c
c c
R
R
τ
τ
τ
τ κ ω
ω
-
=
-
-
	
(4.116)
The Doppler linearity condition reads as
	
µ
µ
µ
µ
µ
χ
ω
ω
τ
τ
ω
ω
=
-
=
-
-
-
3
2
1,0
1
1
1,0
1
1
1
1,0
1
(12
)(
)
(
) (
)exp{
(
)}
L
freq
s
L
f
i
t c t
c t
it
 	
(4.117)
In addition to these two conditions, a third linearity condition will be derived, 
which assesses the influence of the code phase and Doppler errors on the signal-
amplitude estimate. 

4.3  LSQ Correlators/Discriminators	
91
Looking at (4.61) and reviewing the discussion of Section 4.3.2.3, it might be 
reasonable to require that the expected estimated signal power obtained at the cor-
relation point is equal to true signal power; that is,
	
=
0
2
2
1
1
ˆa
a
q
	
(4.118)
Using (4.63), the amplitude linearity condition reads as
	
1
1
,
1,0
1
1
1,0
(
) (
)
1
c c
R
τ
τ κ ω
ω
-
-
= 	
(4.119)
This is another condition on the code phase and Doppler, which needs to be 
sufficiently fulfilled. 
Summarizing the derivations above, the three linearity conditions—(4.116), 
(4.117), and (4.119)—limit the range of tolerable Doppler and code-phase errors. 
Furthermore, if the conditions are sufficiently fulfilled, the resulting code-phase, 
Doppler, or amplitude estimates will be optimal. Note that a violation does not 
necessarily cause the estimates to be suboptimal. It should be noted that the condi-
tions are directly derived from the assumed navigation signal. Different navigation 
signals may be more or less sensitive to code-phase or Doppler errors. The linearity 
conditions presume that the navigation receiver performs optimal processing of 
the signal to achieve the CRLB. If, on the contrary, the signal processing within 
the receiver is different (e.g., a simple early–late tracking scheme is used), then the 
linearity conditions do not apply anymore (at least not in this form) but the receiver 
performance will also be suboptimal. 
4.3.3  Correlation Point
Calculating a LSQ estimate using equations like (4.63), (4.64), or (4.65) requires 
computation of correlation values of the signal samples with a receiver internally 
generated reference signal. The reference signal is computed using the code-phase 
and Doppler parameters given by the vector q0. This vector defines the correlation 
point used to obtain the estimated values. 
An important requirement of the correlation point is that it is near the true 
code-phase and Doppler values such that (4.116), (4.117), and (4.119) are fulfilled 
sufficiently. Fulfilling this requirement ensures that the obtained estimates are sto-
chastically independent of the correlation point and that, because of (4.17), the 
CRLB is achieved. In practice, the correlation point is generally a function of pre-
viously estimated code-phase and Doppler values. By avoiding a stochastic (non-
linear) dependence of the current estimates from the previous estimates, the total 
positioning problem can be treated analytically.
Furthermore, it should be pointed out that a key element for an efficient naviga-
tion software receiver implementation is the reuse of internally generated reference 
signals for multiple correlations (see Section 9.6). The reuse does not degrade the 
estimates as long as the correlation point is sufficiently near the true signal param-
eters such that the linearity conditions are fulfilled. When the difference becomes 
too large, the internal reference signals are refreshed, thereby shifting the correla-
tion point back to the true parameter values.
Within a navigation receiver, several concepts may be used to choose the 
correlation point, depending upon which kind of information is used and how 

92	
Signal Estimation
the correlation is implemented. The concepts are outlined below. It should be 
pointed out that the following considerations focus on the code-phase and Dop-
pler dimensions. The signal amplitude and carrier phase are less important be-
cause the estimation problem is effectively linear for those parameters if the 
complex-valued amplitude is used. Carrier-phase estimation will be discussed in 
Section 4.3.3.4.
4.3.3.1  Tracking Loop
Tracking loops are commonly used in GNSS receivers to control the estimation 
process within a receiver’s channel for one received signal. In the following, track-
ing loops are described in the framework of a LSQ adjustment. The description 
is slightly different (i.e., more conceptual) compared to other standard early–late 
tracking-loop descriptions [15, 20].
A tracking loop determines, for each integration interval, one set of correla-
tion values and uses it to determine code-phase, Doppler, and complex-amplitude 
estimates. We assume that a LSQ scheme is used, but the LSQ iteration (or an ap-
proximation of it) is stopped after the first iteration. More specifically, the following 
steps are performed for each interval:
Generate reference signals for the current correlation point;
Single-step LSQ;
Estimate signal amplitude using (4.63);
Estimate code-phase and Doppler improvements using (4.64) and (4.65);
Filter code-phase and Doppler corrections;
Apply filtered corrections and update correlation point.
By continuously estimating code-phase and Doppler improvements, the track-
ing loop follows the received signal. Obviously, the tracking loop has to be ini-
tialized with starting values. The key element is the loop filter, which fulfills two 
functions simultaneously. First, the correlation point is kept near the true values. 
Second, the filtered code-phase and Doppler values are of reduced noise. Both func-
tions are conceptually different and could, in general, be fulfilled using two different 
filters. A block diagram illustrating this modified procedure is shown in Figure 4.2. 
An optional smoothing filter is included. 
1.
2.
a.
b.
3.
4.
Figure 4.2  Tracking-loop block diagram.

4.3  LSQ Correlators/Discriminators	
93
The mathematical model for the “Single LSQ step” is based on the consider-
ations of Section 4.3.2, which can be summarized for a single estimation step as
	
ˆ
0
ˆ
εD
D
=
-
+
q
q
q
q
	
(4.120)
where eDqˆ is the single-step high-rate pseudorange estimation error. The high-rate 
pseudorange estimates are used to define the correlation point for the next interval
	
0
ˆ
=
q
q 	
(4.121)
The estimation is performed exactly once per integration interval. Applying the 
z-transform to analyze the temporal evolution of the tracking loop over multiple 
intervals yields
	
=
D
+
0
0
ˆ
( )
( )
( )
( )
( )
NCO
Loop
z
z
H
z H
z
z
z
q
q
q
	
(4.122)
which can be solved for the correlation point,
	
ˆ
0
0
0
ˆ
0
ˆ
0
( )
( )
( )( ( )
( )
( ))
( )
( )(
1
( )
( ))
( )
( )( ( )
( ))
( )
( ) ( )
( )
( )
( )
( )
(
1
( )
( ))
(
1
( )
( ))
NCO
Loop
NCO
Loop
NCO
Loop
NCO
Loop
NCO
Loop
NCO
Loop
NCO
Loop
z
z
H
z H
z
z
z
z
z
z z
H
z H
z
H
z H
z
z
z
H
z H
z
z
H
z H
z
z
z
z
H
z H
z
z
H
z H
z
ε
ε
ε
D
D
D
=
-
+
+
-
+
=
+
=
+
-
+
-
+
q
q
q
q
q
q
q
q
q
q
q
	
(4.123)
and for the final low-rate pseudorange estimate 
	
ˆ
( )
( )
( ) ( )
( )
( )
( )
( )
ˆ( )
(
1
( )
( ))
(
1
( )
( ))
Smooth
NCO
Loop
Smooth
NCO
Loop
NCO
Loop
NCO
Loop
H
z H
z H
z
z
H
z H
z H
z
z
z
z
H
z H
z
z
H
z H
z
D
=
+
-
+
-
+
q
q
p
ε
	
(4.124)
For many applications, the loop filter can be chosen such that no smoothing 
filter is required [e.g., HSmooth(z) = 1] because the requirement of obtaining smooth 
estimates is often much more stringent than the linearity condition (4.116) and 
(4.117). In other words, the accuracy of the measurements is much higher than the 
extension of the linearity region. An important exception is the case of occasional 
high line-of-sight dynamics. In that case, it is beneficial to design the loop filter with 
a wide bandwidth and the smoothing filter with a narrow bandwidth. This avoids 
loss-of-lock events during periods of high dynamics while maintaining accurate 
estimates during normal tracking. High line-of-sight dynamics may occur during 
acquisition-to-tracking handover, short blockage of the signals, or during specific 
user events. A smoothing filter is used in a patent by Thomas to improve the accu-
racy of the low-rate pseudorange estimates in case the low-rate pseudorange output 
rate is much slower (e.g., 30 seconds) than the inverse of the involved tracking-loop 
bandwidths (e.g., 1 Hz) [21]. 
The NCO-model HNCO(z) is introduced in Figure 4.2 because, in many practi-
cal implementations, the correlation-point update capabilities are limited. For ex-
ample, in some GNSS receivers, only the rate of change of q0 can be controlled, 
but not q0 directly. Typically HNCO(z) equals the coherent integration time Tcoh, 
indicating that the rate of change of q0 muliplied with Tcoh is added to the previous 
value of q0 [16].

94	
Signal Estimation
A number of different possibilities exist to realize the loop filter. For the ex-
ample of a GNSS receiver, Jaffe–Rechtin filters are often used [22] and are described 
in many textbooks [15, 20, 23, 24]. Jaffe–Rechtin filters optimize the sum of ther-
mal noise plus transient errors and they require only the rate of change of q0 to be 
controlled. 
Kaplan describes tracking-loop stability conditions that are formulated based 
on similar linearity requirements such as (4.116) and (4.117) [20]. Those conditions 
transfer the linearity requirement into allowable signal parameters (e.g., maximal 
dynamics, signal-to-noise ratio) that must be met to keep the correlation point near 
the true values. Because of the feedback, a tracking loop may become unstable for 
an unfortunate choice of the loop filter. A detailed investigation on this topic has 
been done by Eissfeller and Kazemi [25, 26]. A more recent approach is to realize 
the loop filter via a Kalman filter. The effective transfer function stands in very 
close relationship with a Jaffe–Rechtin filter, but the Kalman filter is optimal under 
certain assumptions. The Kalman filter approach requires direct control of q0, not 
only of the rate of change of q0 [27].
The variance of a scalar low-rate pseudorange parameter p is given as [16]
	
2
2
ˆ
0
ˆ
(
)
(
)
(
)
1
ˆ
var
var
2
(
1
(
)
(
))
2
var
i
i
i
Smooth
NCO
Loop
i
i
i
NCO
Loop
coh
L
H
e
H
e
H
e
p
d
e
H
e
H
e
T
B
π
ϑ
ϑ
ϑ
ϑ
ϑ
ϑ
ϑ
ε
ϑ
π
ε
D
=
D
=
-
+
=
N
q
N
q
	
(4.125)
where the noise equivalent bandwidth BL in [Hz] is defined as
	
π
ϑ
ϑ
ϑ
ϑ
ϑ
ϑ
ϑ
ϑ
π
=
=
-
+
2
2
0
(
)
(
)
(
)
1
4
(
1
(
)
(
))
i
i
i
Smooth
NCO
Loop
L
i
i
i
coh
NCO
Loop
H
e
H
e
H
e
B
d
T
e
H
e
H
e
	
(4.126)
Note that [16] additionally considered rate-of-change variation within the cor-
relation process.
4.3.3.2  Grid Search and LSQ Re-Iteration
The conventional tracking-loop approach of Section 4.3.3.1 relies on the assump-
tion that the correlation point can be kept near the true values. If this assumption 
is not fulfilled, a different tracking scheme can be employed for high C / N0 values 
that truly solves the MLE equation 
	
L
=
ˆ( )
arg max
( )
pq
q
q s
s
	
(4.127)
for a given a priori range L of admissible values for q. The algorithm may consist of 
two main steps, which are executed for each integration interval:
Brute force evaluation of (4.127) over a grid spanning all admissible 
values q;
1.




98	
Signal Estimation
with the modified high-rate pseudorange parameters to be estimated
	
τ
τ
ω
ω
D
=
D
D
=
D
m
m
m
m
m
m
m
a
a
a
	
(4.130)
If the estimation problem is expressed using the parameters (4.130), it be-
comes a truly linear problem. The relationship between the modified and 
unmodified high-rate pseudorange data is nonlinear. Thus, the modified high-
rate pseudorange data relates to the position (or to the low-rate pseudo-
range data) in a nonlinear way. Only in the case when the squaring loss can 
be ignored, can the relationship (4.130) between the normal and the modi-
fied high-rate pseudorange parameters be considered as effectively linear be-
cause, in that case, precise complex signal-amplitude estimates are available. 
The linearized signal model is the basis for the Kalman filter formulation in 
Section 4.5.2. 
4.3.5  Multiple Propagation Paths
In this section, the results obtained for a single propagation path of Section 4.3.2 
are extended to the case of propagation along two or more paths. 
To evaluate the normal matrix (or the Fisher information matrix) I given by 
(4.54), additional nondiagonal submatrices of the form Ak
*Al  with k  l have to be 
evaluated. The submatrices account for the coefficient’s coupling between different 
propagation paths.
If we define 
	
*
*
=
=
,
,
1
(
)
2
k l
l k
k
l
I
A A
I
	
(4.131)
then
	
,
,0
,0
,0
,0
1,1
1
1
,
,0
,0
,0
,0
,
,0
,0
,0
,0
,0
1,2
1
1
,0
,
2
(
) (
)exp{
(
)}
(
) (
)
2
(
)
(
)exp{
(
)}
(
k
l
k
l
L
L
k l
k
k
l
l
l
k
k
l
c c
k
l
l
k
L
L
k l
l
k
k
l
l
l
k
k
l
l
c c
r
r
I
c t
c t
it
a
a
LR
r
r
I
a
c t
c
t
it
a
a
LR
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
ω
ω
τ
τ
κ ω
ω
τ
τ
ω
ω
τ
=
=
=
=
=
=
-
-
-
-
-
=
= -
-
-
-
-
,0
,0
,0
,0
,0
,
,0
,0
,0
,0
,
,0
,0
,0
,0
,0
1,3
1
1
,0
,
,0
,0
,0
,0
,
) (
)
(
) (
)
2
(
) (
)exp{
(
)}
(
)
(
)
k
l
k
l
k
l
l
k
l
c c
k
l
l
k
L
L
k l
l
k
k
l
l
l
k
k
l
l
c c
k
l
l
k
a
a
LR
r
r
I
ia
t c t
c t
it
a
a
LR
L
µ
µ
µ
µ
µ
µ
µ
µ
ω
τ
τ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
ω
ω
ω
τ
τ
κ ω
ω
γ
=
=
-
-
= -
-
-
=
=
-
-
-
-
-
=
	
(4.132)

4.3  LSQ Correlators/Discriminators	
99
and
	
,
2,2
1
,0
,0
,0
,0
,0
,0
1
,0
,0
,
,0
,0
,0
,0
,
3,2
1
,0
,0
,0
,0
1
2
(
)
(
)exp{
(
)}
(
) (
)
2
(
)
(
)exp{
k
l
L
k l
k
l
L
k
l
k
k
l
l
l
k
k
l
c c
k
l
l
k
L
k l
k
l
L
k
l
k
k
l
l
r
r
I
a
a
c
t
c
t
it
a
a
LR
r
r
I
ia
a
t c t
c
t
i
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
ω
ω
τ
τ
κ ω
ω
ω
τ
τ
τ
=
=
=
=
=
=
=
-
-
-
-
-
-
=
=
=
-
-
,0
,0
,0
,0
,
,0
,0
,0
,0
,
,
3,3
1
2
,0
,0
,0
,0
,0
,0
1
,0
,0
,
,0
,0
,0
,0
(
)}
(
)
(
)
2
(
)
(
) (
)exp{
(
)}
(
)
(
)
k
l
k
l
l
k
k
l
c c
k
l
l
k
L
k l
k
l
L
k
l
k
k
l
l
l
k
k
l
c c
k
l
l
k
t
a
a
LR
L
r
r
I
a
a
t
c t
c t
it
a
a
LR
µ
ω τ
µ
µ
µ
µ
µ
µ
µ
µ
ω
ω
τ
τ
κ ω
ω
γ
ω
ω
τ
τ
ω
ω
τ
τ
κ
ω
ω
=
=
-
-
-
=
=
=
=
-
-
-
-
-
-
	
(4.133)
In this case, the nondiagonal submatrices Ik,l of the Fisher information matrix 
evaluate to 
ω
ω τ
ω
ω τ
τ κ
ω
τ κ
ω
γ
τ κ
ω
τ κ
ω
γ
γ
γ
τ κ
ω
=
D
D
-
D
D
÷
÷
D
D
-
D
D
÷
-
D
D
÷÷
,
,
,0
,
,
,0
,
,0
,0
,
,
,
,
,0
,0
,
2
(
) (
)
(
) (
)
(
) (
)
(
) (
)
(
)
(
)
k
l
k
l
k
l
k
l
k
l
k l
c c
l
c c
a
k
c c
k
l
c c
a
k
l
c c
I
L
R
a
R
a
R
a
a
R
a
a
R
	
(4.134)
with
	
ω
ω
ω
τ
τ
τ
D
=
-
D
=
-
,0
,0
,0
,0
l
k
k
l
	
(4.135)
The matrix Ik,l can be simplified if Doppler estimates decouple from code phase 
and amplitude estimates. This is the case if we assume
	
ω
ω τ
γ
γ
=
=
,
,
0
a
	
(4.136)

100	
Signal Estimation
which implies that the matrix Ik,l is block diagonal. The Doppler block is de-
coupled from the code-phase and amplitude block. As a consequence, the Dop-
pler parameter estimates are independent of the code-phase and amplitude 
estimates, because the submatrices (4.60) of the Fisher information matrix are 
diagonal. 
The complete Fisher information matrix can be written in block diagonal 
form as
	
τ
ω
=
÷
,
0
0
aI
I
I
	
(4.137)
The order of estimated parameters is ak, tk, al, tl, wk, wl if two propagation 
paths are considered.
For many applications, (4.136) is a reasonable assumption because the Dop-
pler differences between the direct and the reflected signals are much smaller than 
the inverse of the coherent integration time [this implies k′(Dw) = 0]. For example, 
Doppler differences of signals received by a static GNSS antenna are caused by the 
satellite motion and are of the order of (5–10 min)–1. For a moving receiver, the 
Doppler difference is bounded by 2 fRF vUSER / c, which evaluates to 10.5 Hz on 
GPS L1 for a pedestrian moving at 1 m/s. On the other hand, typical integration 
times range from 1 to 20 ms.
4.3.6  Two Propagation Paths: Code-Phase CRLB
In this section, the case of two propagation paths shall be evaluated in detail. The 
two propagation paths are denoted by the index k and the index l. The signal at 
baseband c(t) is identical for both propagation paths. It should be mentioned that 
it is not possible to, for example, assign the index k to the line-of-sight signal and 
the index l to the multipath signal. No estimator can distinguish between these 
signals because both signal models are identical. Instead, some other algorithm 
should be used for signal identification. For example, the signal with the shorter 
estimated delay or with the highest signal power can be identified as the line-of-
sight signal.
We assume that Doppler estimation decouples from code-phase/amplitude esti-
mation. Under (4.136), the Fisher information matrix for amplitude and code phase 
Ia,τ is expressed as
	
 
τ
ϑ
τ
ϑ
τ
ϑ
τ
ϑ
τ
ϑ
τ
ϑ
τ
ϑ
τ
ϑ
τ
=
D
-
D
÷
÷
-
D
-
D
÷
÷
D
D
÷
÷
-
D
-
D
-
,
,
,0
,
2
,
,0
,0
,
,0
,0
,
,
,0
,
2
,0
,
,0
,0
,
,
,0
2
1
0
(
)
(
)
0
(0)
(
)
(
)
(
)
(
)
1
0
(
)
(
)
0
(0)
a
c c
l
c c
c c
k
k
c c
k
l
c c
c c
k
c c
l
c c
k
l
c c
c c
l
L
I
R
a
R
R
a
a
R
a
a
R
R
a
R
a
R
a
a
R
R
a
(4.138)

4.3  LSQ Correlators/Discriminators	
101
where for notational simplicity we define a Doppler correlation coefficient as
	
,0
,0
(
)
l
k
ϑ
κ ω
ω
=
-
	
(4.139)
which assumes a value of 1 if both signals have the identical Doppler frequency.
The determinant D of Ia,τ divided by the squared magnitude of both signals is 
obtained via a symbolic mathematics program as
	
ϑ
τ
ϑ
τ
τ
τ
τ
θ
ϑ
τ
÷
D
÷
÷
÷
= +
D
D
+
D
D ÷÷
÷
÷
÷
+
-
D
÷
÷
2
2
,
,
2
2
4
,
,
,
,
2
2
2
,
,
2
(
)
(0)
(
)
(
)
2
(
)
(
)
(0)
(
)
c c
c c
c c
c c
c c
c c
c c
c c
R
R
D
R
R
R
R
R
R
	
(4.140)
and the submatrix of the inverse Fisher information matrix Ia,τ corresponding to the 
parameters (ak, τk) of the signal k is given as
	
(
)
1
,
2
,
,
,
,
2
2
2
2
,
,
,
,
,0
2
2
2
,
,
,
,
,
,
2
,0
,0
2
(
)
(
)
(
)
(0)
(
)
(0)
(0)
(
)
(
)
(
)
(
)
(0)
(
)
(0)
(
)
k
a
c c
c c
c c
c c
c c
c c
c c
c c
k
c c
c c
c c
c c
c c
c c
k
k
I
LD
R
R
R
R
R
R
R
R
a
R
R
R
R
R
R
a
a
τ
ϑ
τ
τ
τ
ϑ
τ
ϑ
τ
ϑ
τ
τ
τ
η
ϑ
τ
-
=
D
D
-
D ÷ ÷
+
D
-
D
÷
÷
÷
÷
D
D
-
D
+
D
÷
-
÷	
(4.141)
where the constant
	
η
ϑ
τ
=
-
D
2
2
,
1
(
)
c c
R
	
(4.142)
has been introduced to simplify the notation. The submatrix corresponding to the 
signal parameters l is identical (apart from exchanging k and l). Couplings between 
parameters for the signal path k and the path l shall not be considered here.
The CRLB (without nuisance parameters) for the code-phase estimate tk of the 
first signal k is being determined by the second diagonal term of (Ia,τ
 –1)k. The CRLB 
reads as
	
2
2
,
,
2
,0
2
2
,
,
0
(0)
(
)
1
(Re{
})
(0)
(
)
2(
/
)
c c
c c
k
k
c c
c c
k
coh
R
R
CRLB
L
a
D
R
R
C N
T
D
η
ϑ
τ
τ
η
ϑ
τ
+
D
= -
+
D
= -
	
(4.143)

102	
Signal Estimation
It should be noted that the CRLB for the signal k is independent of the signal 
strength or phase of the signal l. However, it depends on the code phase difference. 
For a further understanding of this statement, the reader is invited to compare the 
multipath mitigating and the multipath estimating discriminators in Chapter 8. 
Only the latter one has a multipath power independent performance.
4.3.6.1  Small Code-Phase Differences
For small code-phase differences Dt, the correlation function can be approximated 
because of the assumption in Section 1.8.1 as a second-order Taylor series
	
τ
τ
τ
D
D
=
+
D
2
, (
)
1
1
2
c c
r
R

	
(4.144)
Then, (4.143) reads as
	
ϑ
τ
τ
ϑ
ϑ
ϑ
+
D
-
-
-
-
2
2
4
2
2
2
2
2
,0
1
(4
)
4
(Re{
})
(
1)(
(
2)
4)
k
k
r
CRLB
L a
r
r
	
(4.145)
For identical Doppler (J = 1) this expression is singular for all code-phase dif-
ferences Dt as long as (4.144) holds. Thus, no unbiased estimator exists that jointly 
estimates all parameters of both signals if (4.144) holds and if both signals have the 
identical Doppler frequency. It should be mentioned that this does not exclude the 
existence of any other (not jointly estimating) unbiased delay estimator that directly 
estimates tk and treats the l-parameters as nuisance parameters.
4.3.6.2  Identical Doppler
For identical Doppler values (i.e., J = 1), the CRLB (4.143) for the code-phase esti-
mate of the first signal reads as
	
2
,0
2
2
,
,
,
4
2
2
2
2
,
,
,
,
,
,
,
,
1
(Re{
})
(0)(1
(
) )
(
)
(
)
2
(
) (
(0)
(
)
(
))
1
(
) )(
(0)
(
)
k
k
c c
c c
c c
c c
c c
c c
c c
c c
c c
c c
c c
CRLB
L a
R
R
R
R
R
R
R
R
R
R
R
τ
τ
τ
τ
τ
τ
τ
τ
τ
= -
-
D
+
D
D
+
D
-
D
D
+
-
D
-
D
÷
÷ 	
(4.146)
This equation was also derived in publication by Ávila Rodríguez and it was 
analyzed for different GNSS signals [37]. 
For further analysis, a parametric model for any correlation function in the 
vicinity of its origin shall be defined by
	
τ
τ
τ
τ
τ
τ
D
D
+
-
D
<
D
=
D
-
+
D
-
2
4
2
,
2
1
2
12
(
)
2
3
3
1
4
3
8
2
c c
r
r
m
m
R
rm
m r
m
m
mr
…
…
	
(4.147)

4.3  LSQ Correlators/Discriminators	
103
The correlation function is linear for |Dτ | being larger than the parameter 
m. The peak region is modeled by an even fourth-order polynomial. The pa-
rameter r represents the second derivative of the autocorrelation function at the 
origin.
For |Dτ | < m, the code-phase CRLB of the signal k is given for the correlation 
function model (4.147) as
	
τ
τ
-
D
4
2
4
,0
1
9
(Re{
})
k
k
m
CRLB
L a
r
	
(4.148)
The CRLB is nonsingular due to the fourth-order term, but strongly diverges as 
Dt approaches zero. 
4.3.6.3  Known Amplitudes and Carrier Phases Plus Identical Doppler
In cases where both signals have identical Doppler, and if only both code phases are 
estimated (but not the complex-valued amplitudes), then the CRLB for the code-
phase estimate of the signal k reads as
	
τ
τ
= -
-
D
,
2
2
2
,0
,
,
(0)
1
(Re{
})
(
(0)
(
) )
c c
k
k
c c
c c
R
CRLB
L a
R
R
	
(4.149)
This equation is obtained by inverting the 2 × 2 submatrix of (4.137) for the 
parameters (tk, tl).
The expression (4.149) is substantially simpler than (4.146), because (4.146) 
has to account for the coupling of all code-phase and complex-amplitude estimates. 
In an article by Lohan, a similar scenario was investigated and an expression similar 
to (4.149) was obtained [38]. However, in Lohan’s work the multipath parameters 
were not estimated; instead, the multipath signal was considered as a deterministic 
bias added to the received signal.
Using the correlation function model (4.147), (4.149) reduces to 
	
τ
τ
τ
τ
τ
D
<
D
- D
= -
D
-
4
2
2
2
2
,0
1
(2
)
(Re{
})
1
3
3
8
2
k
k
m
m
r
m
CRLB
La
m
m
r
mr
…
…
	
(4.150)
We see that, if both signals are separated by a delay large enough such that 
the correlation function becomes linear, then the delay estimates achieve the same 
CRLB as in the case of a single signal. If the complex amplitude is known, the 
singularity is less severe (second order instead of fourth order) than for joint es-
timation of the code-phase and complex amplitude. This suggests that the cou-
pling between the code-phase and the complex-amplitude estimates affect (4.146) 
significantly. 

104	
Signal Estimation
4.3.7  Two Propagation Paths: Doppler CRLB
Under the assumption (4.136), the submatrix of the Fisher information matrix 
(4.137) for the Doppler parameters (wk, wl) reads as
	
ω
χ
τ κ
ω
χ
τ κ
ω
-
D
D
÷
÷
=
÷
-
D
D
÷
÷
2
2
,0
,0
,
,0
2
2
2
,0
,0
,
,0
2
(
)
(
)
2
24
(
)
(
)
2
24
freq
k
l
c c
k
s
freq
k
l
c c
l
s
L
a
a
R
a
f
I
L
L
a
a
R
a
f
	
(4.151)
The Doppler CRLB for the signal k for joint estimation of both Doppler pa-
rameters reads as
	
(
)
ω
χ
χ
κ
ω
τ
=
-
D
D
2
2
2
2
2
4
4
,0
,
24
1
(
)
144
(
)
(
)
s
k
freq
k
freq
s
c c
f L
CRLB
a
L
f
R
	
(4.152)
where the Doppler is still considered as a complex random variable. Constraining 
it to be real-valued gives
	
(
)
(
)
(
)
ω
χ
χ
κ
ω
τ
χ
χ
κ
ω
τ
χ
χ
κ
ω
τ
=
-
D
D
=
-
D
D
=
-
D
D
2
2
2
2
2
4
4
,
2
2
2
2
2
4
,
2
2
2
4
0
,
12
1
(Re{
})
144
(
)
(
)
12
1
144
(
)
(
)
6
1
(
/
)
144
(
)
(
)
s
k
freq
k
freq
s
c c
freq
k
s
freq
c c
coh
coh
freq
k
freq
c c
coh
f L
CRLB
a
L
f
R
L
a
f
T
R
T
C N
T
R
	
(4.153)
For identical Doppler values (i.e., J = 1) and identical code-phase values, this 
expression diverges since 
2
0
(
)
12
freq
coh
T
ω
κ
ω
χ
D =
D
-
.
4.3.8  Two Propagation Paths: Remark on Other Bounds
Thus far, the multipath signals have been considered as additional parame-
ters that are estimated together with the line-of-sight parameters. For the case 
where the multipath parameters (and the carrier phase of the line-of-sight sig-
nal) are considered as nuisance parameters in the sense of Section 4.2.2, the cor-
responding expression for the MCRLB, ACRLB, and JCRLB are discussed in 
Section 4.3.8.1.
Here we will employ a two-step approach. In the first step, the carrier phase of 
both signals is considered as a nuisance parameter; in the second step, the delay and 
amplitude of the second signal is considered as a nuisance parameter.

4.3  LSQ Correlators/Discriminators	
105
4.3.8.1  Modified Cramér–Rao Lower Bound
The MCRLB for the code phase and amplitude is, according to Section 4.2.2.1, de-
termined from (4.138). Averaging over the carrier-phase values removes terms that 
depend on the complex amplitude. The modified Fisher information matrix is
	
τ
τ ϕ ϕ
ϑ
τ
ϑ
τ
=
=
D
÷
-
÷
÷
D
÷
÷÷
-
,
,
,
,
2
,
,0
,
2
,
,0
2
1
0
(
)
0
0
(0)
0
0
(
)
0
1
0
0
0
0
(0)
k
l
a
a
c c
c c
k
c c
c c
l
L
I
I
R
R
a
R
R
a

	
(4.154)
Code-phase estimates become independent from amplitude estimates. The 
MCRLB for the code-phase estimate is identical to the case of only the line of sight. 
This result may indicate that the MCRLB is rather weak for the considered settings. 
A further consideration of the multipath delay as a nuisance parameter does not 
change the code-phase MCRLB.
4.3.8.2  Asymptotic and Joint Cramér–Rao Lower Bound
The ACRLB for the code-phase estimate of the signal k in the case where both car-
rier phases are considered as nuisance parameters is given by averaging the inverse 
of the CRLB as described in Section 4.2.2.2. Because diagonal elements of the in-
verse Fisher information matrix (4.141)—including the determinate, (4.140)—are 
independent of the carrier-phase values, the ACRLB equals the JCRLB and is given 
by the expression (4.143).
If, in addition, the multipath delay Dt is considered as a nuisance parameter, the 
ACRLB and the JCRLB are different. A good starting point to analyze both bounds 
is (4.148). The ACRLB is the inverse of the averaged-inverse CRLB
	
τ
τ
τ
τ
-
-
=
D
D
1
1
(Re{
}) ( (
(Re{
}))
(
) (
))
k
k
ACRLB
CRLB
p
d
	
(4.155)
and the JCRLB is the averaged CRLB
	
τ
τ
τ
τ
=
D
D
(Re{
})
(Re{
}) (
) (
)
k
k
JCRLB
CRLB
p
d
	
(4.156)
Both use the a priori probability density function p(Dt) of the multipath delay. 
The probability density function often has the form of 
	
τ
τ
D
D
-
1
(
)
exp
p
d
d
∼
	
(4.157)
for delays Dτ > 0. Negative delays do not occur. 
This delay distribution is, however, insufficient to compensate for the singular-
ity of (4.148) at Dt = 0. Therefore, the JCRLB diverges. By contrast, the ACRLB 
will assume a high but finite value. 

106	
Signal Estimation
This implies that if an unbiased line-of-sight code-phase estimator exists at all 
when one multipath signal is present, then it will not be based on joint estimation 
of the line-of-sight and multipath signal parameters. 
4.4  Data Reduction
The LSQ estimator discussed in Section 4.3 is based on correlating the received 
signal samples with derivatives of the signal model. Provided that the correlation 
point is near the true values, only a few values (the correlation values) are sufficient 
to determine the parameter estimates. The correlation values represent compressed 
information and act as data reduction from the large amount of samples to a few 
values. 
This particular data-reduction method generally applies to many estimation 
techniques (MLE and Bayesian techniques) and is based on the definition of a suffi-
cient statistic. The goal of a sufficient statistics is to obtain identical estimates either 
from working directly with the signal samples or from working with the sufficient 
statistic values.
In the following section, this method will be discussed on the example of high-
rate pseudorange estimation from a given set of samples s, described by the prob-
ability density function pq(s). In contrast to the preceding sections, the case of 
nonwhite noise is considered. 
4.4.1  Sufficient Statistics
A statistics T(s) is defined as a (vector) function of the signal samples that does not 
directly depend on the true parameter values q. A statistic is itself a (multidimen-
sional) random variable with a uniquely defined probability distribution depending 
on pq(s). The dimension of the statistics is generally lower than the dimension of the 
signal samples (data reduction principle).
A statistics T(s) is said to be sufficient for the parameters q if the conditional 
distribution of s, under the condition T(s) = const., does not depend on q. If a statis-
tics is sufficient, the parameter q affects the probability density function pq(s) only 
through a function gq[T(s)]. Stated differently, knowledge of gq(T) is sufficient for 
determining pq(s).
The Neyman–Fisher factorization theorem gives a simple criterion of sufficiency 
(see Theorem 3.1 of [4]). A statistics T(s) is sufficient for q if and only if there exists 
a factorization of pq(s) of the form
	
=
( )
( ( )) ( )
p
g T
h
q
q
s
s
s 	
(4.158)
with positive functions gq and h. 
Sufficient statistics are closely related to ML estimation in the sense that the 
ML estimate of q is a function of any sufficient statistics (see Theorem 3.10 in the 
book by Porat [4]).
The factorization theorem shall now be applied to the high-rate pseudorange 
probability density function

4.4  Data Reduction	
107
	
µ
µ
µ
π
=
=
-
-
2
1
1
1
( )
exp
( )
2
(2 )
L
L
p
s
r
q s
q
	
(4.159)
This function is extended for the case of colored noise 
	
π
*
*
-
=
-
-
-
1
1
1
( )
exp
(
( ) )
(
( ))
2
det
(2 )L
p
Q
Q
q s
s
r q
s
r q
	
(4.160)
where Q is the colored noise covariance matrix,
	
,
0,
0,
2
N N
N N
N N
Q
µ
υ
µ
υ
µ
υ
µ υ
=
=
=
N
N
N
	
(4.161)
The quadratic form in the exponent of (4.160) is expanded into
	
1
1
1
1
1
1
1
(
( ) )
(
( ))
( )
( )
Re{ ( )
}
2
2
2
Q
Q
Q
Q
*
*
-
*
-
*
-
*
-
-
-
-
= -
-
+
s
r q
s
r q
s
s
r q
r q
r q
s
	
(4.162)
Only the last term of the above expression is relevant for the factorization theo-
rem, as the first term is independent of the parameters q (and thus goes into h) and 
the second term (being independent of s) can be trivially part of any function of gq. 
In the following section, two approximations are discussed that are commonly used 
to express the last term with the help of properly defined statistics.
4.4.2  Multicorrelator Approach
The multicorrelator approach relies on the evaluation of the statistics at selected 
points spanning the range L of admissible values for q. Between the selected points, 
the last term of (4.162) is obtained via interpolation. The last term of (4.162) is 
therefore approximated as 
	
α
*
-
=
1
( )
( )
( )
b
b
b
Q
T
r q
s
q
s
	
(4.163)
where
	
*
-
=
1
( )
(
)
b
b
T
Q
s
r q
s	
(4.164)
is the multidimensional test statistics evaluated via correlation of the signal model 
with the signal samples at selected control points qb (plus accounting for the noise 
covariance). The functions αb(q) are the interpolation coefficients. 
The signal model (4.46) is linear in the complex amplitude. Therefore, the in-
terpolation in the complex-amplitude dimension is trivial and the grid spanning all 
admissible values is effectively two-dimensional. It extends in the code-phase and 
Doppler dimension. 
4.4.3  First-Derivative Approach
A second possibility to express the last term of (4.162) as a function of properly 
defined statistics is a Taylor series expansion around a predefined correlation point. 

108	
Signal Estimation
For the sake of simplicity, this expansion shall be carried out only in the first order, 
but the generalization to higher-order terms is obvious.
The last term of (4.162) is approximated as
	
0
0
1
1
1
0
0
1
1
0
0
( )
( )
(
)
(
)
( )
(
)
( )
Q
Q
Q
Q
Q
T
*
*
-
*
-
*
-
=
*
*
-
*
-
*
=
+
-
=
-
+
q q
q q
r q
r q
s
r q
s
q
q
s
q
r q
r q
s
q
s
q
s
q
	
(4.165)
with the vector T(s) of test statistics defined as
	
*
-
=
=
0
1
( )
( )
T
Q
q q
r q
s
s
q
	
(4.166)
The first two terms of (4.165) are independent of q and thus go into h.
The test statistics of the first-derivative approach relies on the correlation of the 
received samples with the first derivates of the signal model (and accounts for the 
noise covariance). The derivative of the signal model (4.46) with respect to the com-
plex amplitude yields a correlation with the signal model itself, which will define the 
P-correlator. The derivatives with respect to the code phase and with respect to the 
Doppler define the D- and the F-correlators. All three correlators will be discussed 
in Section 7.3.
4.4.4  Colored Noise
The test statistics of the preceding two sections account for the noise correlations 
via the matrix Q. Consequently, the test statistics can be expressed as correlations 
of the signal samples with a modified signal model, defined as
	
-
=
1
( )
( )
Q
r q
r q

	
(4.167)
For example, the test statistics (4.166) are then given as
	
*
=
=
0
( )
( )
T
q q
r q
s
s
q

	
(4.168)
The modified signal model ( )
r q

 compensates for the colored-noise effects. For 
example, if the signal and noise are affected by the same low-pass filter, then the 
modified reference signal ( )
r q

 is obtained by applying twice the inverse filter (i.e., 
a high-pass filter) to the infinite-bandwidth reference signal. This and related tech-
niques will be further explored in Section 6.4.
4.5  Bayesian Approach
In the Bayesian approach, the estimated parameters (for example, the high-rate 
pseudorange parameters q) are assumed to be random quantities related statisti-

4.5  Bayesian Approach	
109
cally to the observations. The parameters are endowed with an a priori probability 
density function w(q), which is defined, even with the lack of actual observations. 
By contrast, the nonrandom-parameter estimation approach introduced in Section 
4.2 does not require any a priori distribution of the parameters. 
The second important difference between nonrandom-parameter estimation 
and the Bayesian approach is the use of a cost function in the latter case. The cost 
function measures the cost of estimating the true value q as ˆq; the more incorrect 
the estimate, the higher the cost. A Bayesian estimate minimizes the cost function, 
averaged over all admissible values for q. Bayesian estimates are not necessarily 
unbiased. ML estimation can be seen as a special case of Bayesian estimation for 
the case of a uniform distribution w(q) and a cost function that assumes 0 for ˆ =
q
q 
and otherwise one (see chapter IV.D in the book by Poor [1]). 
The Bayesian approach is generally less popular than the nonrandom param-
eter-estimation approach for the design of navigation signal-processing algorithms, 
probably because of two facts. First, the a priori probability density function w(q) 
is often hard to determine. Second, the coupling between w(q) and the estimated 
parameters complicates the determination of the statistical distribution of the esti-
mated parameters. An important exception to this is the case of linear observations 
and a linear dynamical model with Gaussian noise. The resulting Bayesian estima-
tor—the Kalman–Bucy filter—yields explicit expressions for the estimates and their 
probability density functions. 
In the following, minimum mean-squared error estimation will be introduced; 
the estimator will be expressed as a function of the sufficient statistics of Section 
4.4, regardless of the form of the underlying probability density functions or the 
relationship between parameters and observations. The necessary assumptions 
to apply the Kalman–Bucy filter theory, as well as a block diagram for a Kal-
man filter based on the sufficient statistics of Section 4.4, will be discussed in 
Section 6.5.2.
4.5.1  Minimum Mean-Squared Error Estimation
It is well known that the choice of the cost function should be related to the estima-
tion problem; in the following, we focus on a quadratic cost function 
2
ˆ -
q
q . The 
Bayesian risk 
ˆ( , )
R q s  for a particular set of observed samples s is defined as the aver-
aged cost function over all admissible parameter values conditioned to s as
	
L
=
-
=
-
2
2
ˆ
ˆ
ˆ
( , )
(
)
R
p
d
qs
q
q s
q
q
q
q
q s
q
	
(4.169)
This equation includes the conditional probability p(q | s) of observing q under 
the assumption S = s.
The Bayes estimate for the quadratic cost function is defined as
	
=
ˆ
ˆ
ˆ
( )
arg min ( , )
R
q
q s
q s
	
(4.170)
and evaluates according to Case IV.B.4 in the book by Poor to the conditional ex-
pected value of the parameters itself [1]; that is, 

110	
Signal Estimation
	
L
L
L
=
=
( ) ( )
ˆ( )
(
)
( ) ( )
p
w
p
d
d
p
w
d
q
q
q
q
q
q
s
q
q s
q q s
q
q
s
q
q
	
(4.171)
In the last step, the conditional probability p(q | s) is expressed using the sample 
probability density function pq(s) and the a priori probability density function w(q) 
using the Bayes theorem. 
From Section 4.4, it is clear that for fixed observed samples s, the probability 
density function pq(s) can be obtained via a sufficient statistics T(s). Therefore, af-
ter the data reduction from the signal samples to the statistics has been performed, 
the evaluation of (4.171) requires averaging over all parameter values without, 
however, performing further correlations. The MMSE parameter estimates can, for 
example, be obtained from the P-, D-, and F-correlator values introduced in Chap-
ter 7, and the integral 
	
L
L
=
( ( )) ( )
ˆ( )
( ( )) ( )
g T
w
d
g T
w
d
q
q
q
q
q
s
q
q s
q
s
q
q
	
(4.172)
represents a discriminator that converts correlation values into parameter estimates. 
Typically, the integration over complex-valued amplitude parameters can be carried 
out in closed form.
4.5.2  Kalman–Bucy Filter
The evaluation of (4.171) can be performed using linear algebra if a number of as-
sumptions on the probability density functions and the signal model are fulfilled. 
The resulting estimation scheme is called Kalman–Bucy (or simply Kalman) filter 
and shall be outlined here.
To apply the Kalman filter theory, we assume that the samples are Gaussian 
distributed and that the a priori probability density function of the parameters is 
Gaussian as well. Furthermore, we assume that the signal model is essentially linear 
in the estimated parameters in the sense of (4.129), with the relationship between 
modified and true signal parameters being sufficiently linear. The latter linearity 
condition requires knowing the complex-signal amplitude rather precisely. Accord-
ing to Example IV.B.3 in the book by Poor, the MMSE estimator of the parameters 
can be obtained using linear algebra expressions involving the observations, the 
mean values, and the covariance matrices [1]. Furthermore, for this particular set-
ting, the MMSE coincides to the minimum mean absolute error (MMAE) estimator 
and to the maximum a posteriori probability (MAP) estimator. 
The expressions can be further simplified if a dynamical model for the estimated 
parameters is assumed. The estimated parameters are time-dependent and the time 
dependence is realized by providing an identical set of parameters for each epoch 
separately. A dynamical model is a linear relationship between the true parameters 
of successive epochs including Gaussian process noise. Furthermore, each signal 
sample can be uniquely assigned to one epoch (i.e., the signal model for a particu-
lar sample depends on parameters of only one epoch). Then the whole estimation 


112	
Signal Estimation
A navigation receiver realized as a Kalman filter depicted in Figure 4.6 does 
not require more correlations of the received samples with internally generated 
reference signals compared to a conventional receiver based on, for example, 
tracking loops of Section 4.3.3.1. It is, however, required that the underlying dy-
namical model and the observation model are correct, as is the short-period signal 
model of Section 1.8 that relates batches of signal samples to one set of estimated 
parameters. The presented scheme estimates all four fundamental signal param-
eters (code phase, Doppler, carrier phase, and amplitude) and uses the predicted 
complex-valued amplitude to setup the design matrix of the current epoch. 
By contrast, the LSQ discriminators of Section 4.3.2 use the estimated com-
plex-valued amplitude of the current epoch to correct code-phase and Doppler 
estimates. Correct filtering and prediction of the carrier phase and amplitude is 
essential for this Kalman scheme. The Kalman filter intrinsically accounts for all 
correlations between the estimated parameters and signals, thereby causing an 
increased computational load. 
The Kalman filter of Figure 4.6 can also be expressed in terms of the position 
estimates x, instead of the high-rate pseudorange estimates q. In this case, the design 
matrix not only derives from the short-period signal model of Section 1.8 but also 
includes the observation model (4.2). Alternatively, a cascaded Kalman filter struc-
ture can be used that first estimates q and then x. Provided that all underlying mod-
els are sufficiently good and provided that the position-estimation filter correctly 
accounts for all correlations in the estimated high-rate pseudorange parameters q 
(also timely correlations), identical results are obtained. 
The major disadvantage of the scheme in Figure 4.6 is that it is an all-in-one 
solution and a single failure (e.g., incorrect carrier-phase filtering) may corrupt the 
whole estimation process. Furthermore, the Kalman filter relies on a proper lin-
earization of the signal model and its behavior is undefined if the correlation point 
diverges too much from the true value. 
4.5.3  Other Filters
The two estimation schemes (LSQ estimation plus subsequent filtering and the Kal-
man filter) must fulfil a number of assumptions to be optimal:
Gaussian noise; 
Gaussian a priori parameter distribution;
Linearity conditions fulfilled or linearized signal model.
The first assumption—Gaussian noise—can be considered to be fulfilled in most 
cases, especially if the navigation receiver is correlation-based. Then the law of large 
numbers applies. The Gaussian parameter distribution is a reasonable assumption 
and Markov models (e.g., for the user movement) can be provided. It is, however, 
more difficult to chose suitable parameters for the distributions.
In the author’s opinion, the most difficult assumptions to fulfill are the linear-
ity conditions. Although these conditions can only be violated if the signal power 
is weak (a high signal power allows ML estimation, thereby fulfilling the linearity 
conditions), reception of weak signals is a typical problem a navigation receiver 
1.
2.
3.

4.5  Bayesian Approach	
113
has to cope with. In the case of GNSS signals, a linearized signal model of Section 
4.3.4 is more difficult to obtain than fulfilling the linearity conditions of Section 
4.3.2.10. If full linearization (including products with the complex-valued ampli-
tude) of the signal model is not possible, but the linearity conditions are fulfilled, 
the LSQ estimation scheme or a noncoherent Kalman filter (see next Section 4.5.4) 
are still optimal. If the linearity conditions are also not fulfilled, nonlinear filters 
might be used.
Nonlinear filtering for navigation signal processing is a topic of ongoing re-
search. A tutorial on nonlinear and non-Gaussian filters was written by Arulam-
palan [40]. Nonlinear filters are Bayesian filters and use Monte Carlo methods to 
evaluate Bayesian estimation integrals like (4.171). Particle filters have been used 
by Closas for static multipath scenarios [41]. Dynamic multipath scenarios have 
been presented by Lentmaier [42]. In the latter work, it is evident how the particle 
filter combines the non-Gaussian parameter probability density function of the dif-
ferent epochs and circumvents the linearization problem. A demonstration of the 
practical use of nonlinear filters or a comparison with linear filters is not known to 
the author.
A related problem is the transition between different discrete states in an esti-
mation filter. Most importantly, the number of multipath signals has to be estimated 
correctly to set up the right signal model. Bayesian methods can be used for this 
purpose [42].
4.5.4  Use of Kalman Filters in GNSS Signal Processing
The use of a Kalman filter for signal tracking has become increasingly popular in 
recent years. Kalman filters are used to implement independent channel tracking 
loops [43] and may be used to improve the tracking performance during iono-
spheric scintillations [44]. At the independent tracking-loop level, a Kalman filter 
has a similar transfer-function structure as a carrier-aided DLL with an FLL-assisted 
PLL [27]. Kalman filters can also be found in ultratightly coupled GPS/INS systems 
that are based on vector tracking.
We categorize signal-processing Kalman filters according to the input data:
Navigation signal samples;
Correlator values;
Discriminator values.
A commonly used fourth type, working with pseudoranges, is not considered 
here because this type is considered to work at the navigation-processor level and 
not at the signal-processing level. Furthermore, the signal-processing Kalman filters 
are categorized according to the state vector:
(Low-rate) pseudorange parameters;
Position parameters.
Section 4.4 showed that categories 1 and 2 are equivalent if the correlator 
values represent a sufficient statistics. Category 1 and 2 are coherent Kalman fil-
1.
2.
3.
A.
B.

114	
Signal Estimation
ters because the input data depends on the carrier phase, whereas a category-3 
(noncoherent) Kalman filter may operate with code-phase and Doppler (and even-
tually with amplitude) discriminator values. 
A coherent Kalman filters needs to generate predicted complex-valued ampli-
tudes, which are used to set up the Kalman filter design matrix of the current epoch. 
By contrast, a noncoherent Kalman filter based on LSQ discriminators uses the com-
plex-valued amplitude estimate based on the current epoch’s samples to set up the 
LSQ design matrix. From the theoretical point of view, this is the main difference 
among category 1/2 and 3. The extent to which the predicted complex-valued ampli-
tude is more accurate than the estimated complex-valued amplitude depends primar-
ily on the signal characteristics (data/pilot) and dynamics (including clock jitter), the 
duration of the coherent integration and on the availability of aiding (IMU) data.
A coherent Kalman filter is optimal (e.g., squaring-loss free) but difficult to 
realize for low signal power [45]. Note that the squaring loss is irrelevant for high 
signal power. For GNSS receivers, predicting the complex-valued amplitude—in 
situations where carrier phase estimation is not possible—requires at least a cm-
accurate pseudorange prediction that needs a stable receiver oscillator (OCXO), 
a navigation-grade IMU, and a stable propagation channel (e.g., no atmospheric 
scintillations). Furthermore, predicting the carrier phase requires pilot signals or a 
data-bit wipe-off functionality. A more practical approach to incorporate an equiv-
alent amount of aiding information in a noncoherent Kalman filter is to increase 
the coherent integration time to macroscopic lengths (a few seconds) and to use 
the aiding information within the discriminators only. Effectively, the aiding infor-
mation compensates for nonlinear line-of-sight dynamics and allows for using the 
short-period signal model over longer time spans. Macroscopic long-integration 
times virtually eliminate the squaring loss. 
The use of the aiding data is simpler within the discriminators than within a 
coherent Kalman filter [46]. Only the second-order line-of-sight dynamics (e.g., the 
acceleration) need to be compensated over the integration interval, and each inter-
val is independent. By contrast, the aiding information for the Kalman filter needs 
to be stable at zeroth order over the whole period of operation. Both methods—a 
coherent Kalman filter or a long-coherent integration—predict the carrier phase of 
the line-of-sight signal and thereby mitigate contributions from multipath signals, 
which have a different carrier-phase behavior if the antenna is moving. This may 
involve predetection multipath suppression or a synthetic antenna array [47].
Category-A Kalman filters are used for independent channel tracking and cat-
egory-B filters are used for vector tracking. A category B/1 Kalman filter would be 
well-suited to realize an intrasystem interference-cancellation receiver. Finally, it 
should be noted that Kalman filters of all categories allow carrier-phase estimation 
(see Section 4.3.3.4).
4.6  Squaring Loss Revisited
The squaring loss introduced in Section 4.3.2 decreases the accuracy of high-rate 
pseudorange LSQ estimates compared to the CRLB (considering the carrier phase as 
a useful parameter). The squaring loss is caused by estimation errors of the complex-

4.6  Squaring Loss Revisited	
115
valued signal amplitude, which affect the setup of the design matrix. The squaring 
loss is intrinsically coupled to the underlying LSQ estimation scheme, which jointly 
estimates the complex-valued signal amplitude together with the code phase and 
Doppler. The complex-valued amplitude is treated as a nonrandom parameter. 
By contrast, if the carrier phase is treated as a nuisance parameter, none of the 
relevant bounds (e.g., the MCRLB or the ACRLB) is affected by a term that would 
correspond to the squaring loss, as has been shown in Sections 4.3.2.5 and 4.3.8. 
Therefore, further investigations shall be carried out in this section to clarify the 
question of whether the squaring loss is a specific artifact of LSQ estimation or 
if it is more fundamental. This is done in the following section by a mathemati-
cally exact treatment of the carrier phase as a nuisance parameter, which gives the 
true CRLB (TCRLB). A numerical evaluation of the TCRLB later shows that it is 
affected by the squaring loss, proving that the LSQ scheme is an optimal estimator 
(i.e., a MVUE).
To evaluate the TCRLB under the assumption that the carrier phase is a nui-
sance parameter, a simplified signal model shall be used that assumes zero Doppler. 
Based on (4.44), the following signal model shall be assumed
	
( , )
(
)exp{
}
,
( )
a
r
ac t
i
µ
µ
τ
ϕ
ϕ
τ
=
-
-
=
=
÷
q
q
ξ
ξ
	
(4.175)
where the code phase t and the real-valued amplitude a are considered as useful 
parameters q to be estimated, and the carrier phase j is treated as a nuisance pa-
rameter ξ. For the carrier phase, we assume that it is uniformly distributed between 
[0, 2π].
The probability density function of the signal samples is first expanded into
	
2
,
1
2
2
1
1
1
1
( )
exp
( , )
2
(2 )
1
1
1
exp
( , )
Re{
}
2
2
(2 )
L
L
L
L
i
i
L
p
s
r
s
r
ae
B
µ
µ
µ
ϕ
δ
µ
µ
µ
µ
π
π
=
+
=
=
=
-
-
=
-
-
+
q
s
q
q
ξ
ξ
ξ
	
(4.176)
where the constants 
	
1
1
(
)
angle
(
)
L
L
B
s c t
s c t
µ
µ
µ
µ
µ
µ
τ
δ
τ
=
=
=
-
=
-
	
(4.177)
represent the magnitude and phase of the correlation value of the received samples 
with the signal at baseband. 
According to Section 4.2.2, the probability density function of the signal sam-
ples, parameterized only by the useful parameters, is given by averaging (4.176) 
over all carrier phase values; that is,

116	
Signal Estimation
	
2
,
,
0
2
2
0
1
1
( )
( )
( )
2
1
1
exp
log(
(
))
2
2
(2 )
L
L
p
p
p
d
La
s
I aB
π
ϕ
µ
µ
ϕ
π
π
=
=
=
=
=
-
-
+
q
q
q
s
s
s
ξ
ξ
ξ
	
(4.178)
Here, Im denotes the mth-order modified Bessel function of first kind, defined 
as
	
2
0
exp{
cos( )}
2
( )
m
imx
x
d
I
x
π
ϕ
ϕ
ϕ
π
=
+
=
	
(4.179)
For large values of x, the following approximation holds
	
log(
( ))
m
I
x
x
x 	
(4.180)
To obtain the TCRLB of the code-phase estimate (under the assumption of a 
constant real-valued signal amplitude a), the derivative with respect to the code 
phase of the logarithm of (4.178) has to be computed as follows
	
τ
τ
τ
=
=
1
0
0
(
)
log
( )
log(
(
))
(
)
aI aB
B
p
I aB
I aB
q s
	
(4.181)
The derivative of B with respect to the code phase is given as
	
,
1
1
1
1
(
(
)
(
)
(
)
(
))
2
1 Re
(
)
(
)
L
L
L
B
S c t
S c t
S c t
S c t
B
S c t
S c t
B
µ
µ
ν
ν
µ
µ
ν
ν
µ ν
µ
µ
ν
ν
µ
ν
τ
τ
τ
τ
τ
τ
τ
=
=
=
= -
-
-
+
-
-
= -
-
-
	
(4.182)
It is useful to introduce the (simplified) P- and D-correlators (see Section 7.3) 
evaluated at the true parameter values as
	
1
1
1
1
(
)
exp{
}
(
)
(
)
(
)
L
L
L
L
P
S c t
aL
i
N c t
D
S c t
N c t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
ϕ
τ
τ
τ
=
=
=
=
=
-
-
+
-
=
-
-
	
(4.183)
and to write the derivative of the logarithm of (4.178) as
	
τ
= -
1
0
(
) Re{
}
log
( )
(
)
aI a P
PD
p
I a P
P
q s
	
(4.184)
This expression is substantially more complex than the corresponding expres-
sion (4.13), which treats the carrier phase as a useful parameter to be estimated. 

4.7  Numerical Simulation	
117
Overall, the TCRLB for the code phase under the assumption that the real-
valued amplitude is constant and that the carrier phase is a uniformly distributed 
nuisance parameter is given as
	
τ
-
=
÷÷
1
2
1
0
(
) Re{
}
( )
(
)
aI a P
PD
TCRLB
I a P
P
N
	
(4.185)
In case the real-valued signal amplitude is jointly estimated with the code phase, 
the two-dimensional Fisher information matrix has to be set up. Therefore, the 
derivative with respect to the amplitude of the logarithm of (4.178) has to be com-
puted as
	
= -
+
= -
+
1
0
0
(
)
log
( )
log(
(
))
(
)
BI aB
p
aL
I aB
aL
a
a
I aB
q S
	
(4.186)
Then the Fisher information matrix is given as 
	
τ
÷
-
÷
÷
÷
÷
÷
÷
=
÷
÷
-
-
÷
÷
÷
÷
÷
2
1
1
1
0
0
0
,
2
1
1
1
0
0
0
(
)
(
)
(
)
Re{
}
Re{
}
(
)
(
)
(
)
(
)
(
)
(
)
Re{
}
(
)
(
)
(
)
a
aI a P
P I a P
aI a P
PD
PD
aL
I a P
P
I a P
I a P
P
I
P I a P
aI a P
P I a P
PD
aL
aL
I a P
I a P
P
I a P
N	
(4.187)
The off-diagonal terms tend to average out due to the presence of the D-correlator, 
whose distribution is symmetric around zero-code delay, whereas the P-correlator 
values are centered around a. For large values of a, the approximation (4.180) can 
be used, yielding
	
τ
>>
÷
-
÷÷
÷
=
÷
÷
-
-
÷
2
,
2
Re{
}
Re{
}
(
)
Re{
}
(
)
(
)
a a
PD
PD
a
P
aL a
P
P
I
PD
P
aL a
P
aL
P
N	
(4.188)
The Fisher information matrix is best evaluated using a Monte Carlo simula-
tion at either the signal level or the correlator level. A specific example will be per-
formed in the next section. The code-phase TCRLB can then be computed from the 
first diagonal element of the inverse Fisher information matrix.
4.7  Numerical Simulation
By specifying a specific navigation signal structure, some formulas of preceding 
sections are explicitly evaluated and the obtained results discussed. Different code-
phase (ranging) CRLBs for the presented navigation signal are evaluated and com-
pared to each other. A Monte Carlo solution is used to assess the influence of the 

118	
Signal Estimation
starting correlation point on the obtained estimates and single-iteration results are 
compared to a converging iterative solution.
The simulation is based on the Gaussian double-pulse signal of Section 1.9.4.
4.7.1  Evaluation of Bounds
In the following, a number of code-phase CRLBs shall be evaluated. Additionally, 
the variance of an LSQ code-phase estimate with squaring loss based on a single it-
eration using the true values as correlation point is also included. More specifically, 
the following figures shall be considered:
CRLB: The code-phase CRLB (4.72), which is obtained by treating the car-
rier phase, code phase, Doppler, and amplitude as useful parameters to be 
estimated.
TCRLB: The true code-phase CRLB—the first diagonal element of the in-
verse matrix of (4.187)—obtained by treating the carrier phase as a nuisance 
parameter distributed uniformly in [0, 2π].
TCRLB, a = const.: The true code-phase CRLB (4.185) obtained by treating 
the carrier phase as a nuisance parameter distributed uniformly in [0, 2π] and 
assuming a known amplitude.
LSQ: The code-phase variance from an LSQ estimation (4.82). The correla-
tion points coincide with the true values.
All four procedures are based on an unbiased estimation scheme. The differ-
ences in the CRLBs originate from the different treatment of the individual param-
eters, which is summarized in Table 4.3. The TCRLB is the most realistic bound, 
and the CRLB is of importance if the carrier phase is known from a priori or if the 
carrier phase is estimated with high accuracy. 
Figure 4.7 shows the different code-phase variances (actually the square root of 
the variances) as a function of the signal power in a double logarithmic plot. The 
LSQ variance and the two TCRLBs coincide very well and exhibit the squaring 
loss below around 32 dBHz. The CRLB does not show the squaring loss and ef-
fectively underestimates the influence of the unknown carrier phase on code-phase 
estimation. 
Two important conclusions can be drawn from Figure 4.7 for the assumed 
exemplary navigation signal. First, the CRLB is too weak for low signal power 
levels. One of the TCRLBs should be used. The TCRLBs provide more realistic 
values (although they are significantly more difficult to calculate). Second, the LSQ 
estimate achieves the TCRLB and is thus an optimal estimator, even for low signal 
Table 4.3  Code Phase Cramér–Rao Lower Bounds 
Used in the Comparisons
Parameter
CRLB
TCRLB
TCRLB,  
a = const.
Code phase
Estimated
Estimated
Estimated
Doppler
Estimated
Known
Known
Carrier phase
Estimated
Nuisance
Nuisance
Amplitude
Estimated
Estimated
Known






124	
Signal Estimation
4.8  Discussion
This chapter presented and contrasted different theoretical principles to obtain po-
sition estimates from a received navigation signal: direct position estimation of 
Section 4.2.3, MLE or LSQ pseudorange estimation of Section 4.3, minimum mean-
squared error estimation of Section 4.5.1, or a Kalman filter operating on a suffi-
cient statistic of Section 4.5.2.
When comparing those theoretical principles to what is actually done in many 
GNSS navigation receivers for high-rate pseudorange estimation, it is interesting 
to note that normally none of these theoretical principles is directly applied. In-
stead, the receiver design is mostly based on an approximated single-iteration LSQ 
approach and the first derivative of the baseband signal is approximated by an 
early-minus-late replica difference. It is also common practice to determine mul-
tiple correlation values centered near the true values (e.g., a sufficient statistic) and 
then to construct code-phase, Doppler, carrier-phase, and amplitude estimators that 
are insensitive to certain effects, e.g., multipath, false-locks, carrier-phase loss, and 
many more. All those engineering approximations considerably improve the overall 
receiver performance, at the cost of an increased variance and the possible introduc-
tion of biases. 
If, by contrast, truly minimum variance and unbiased estimates are desired, the 
receiver should estimate high-rate pseudorange parameters as follows. First, the 
correlation point should be within the linearity region. Second, the LSQ estimation 
scheme of Section 4.3 should be used with a single iteration. The LSQ estimation 
scheme itself is well-implementable for a GNSS SDR because the LSQ computational 
processing demands are negligible compared to the signal correlation (at least for 
the CPUs considered in chapter 3). The numerical evaluation of the TCRLB showed 
that the LSQ discriminator is optimal. Ensuring that the correlation point follows 
the true values requires a sophisticated receiver design, especially if the targeted 
operation scenario of the receiver does not allow independent channel tracking (see 
Section 4.3.3.1). Vector tracking, along with aiding information (e.g., IMU, stable 
clock, map-matching) is useful. Furthermore, the number and the approximate de-
lays of possibly present multipath signals is valuable to overcome the singularity for 
near-range multipath mentioned in Sections 4.3.6 and 4.3.7. Section 8.3 introduces 
a multipath-estimating discriminator and gives practical implementation aspects. 
If the relation between position parameters and pseudorange parameters is suf-
ficiently linear (as is the case for GNSS signals), the optimality property of the LSQ 
pseudorange estimates transfers to the position estimates if all parameter correla-
tions are properly accounted for.
As long as no navigation problem with high dynamics and high signal power 
is considered, the LSQ equations should not be iterated and the LSQ estimates 
are based on one iteration for the chosen correlation point. The code phase and 
Doppler of the correlation point typically derive from a predicted value based on 
the previous estimates. By contrast, the complex-valued amplitude is irrelevant for 
the correlation point, but is needed to set up the design matrix. A predicted com-
plex-valued amplitude from previous estimates gives a coherent estimation scheme; 
estimating the complex-valued amplitude from the current epoch’s samples gives a 
noncoherent scheme.

4.8  Discussion	
125
If the correlation point cannot be expected to be within the linear region, the 
proposed LSQ scheme produces suboptimal estimates. Suboptimal estimates will 
also be produced if the number of multipath signals is incorrectly estimated. Both 
situations should not occur for high signal-to-noise ratios. If they occur, Bayesian 
techniques, such as (sequential) Monte Carlo methods, may still be optimal because 
they do not require fulfilled linearity conditions. An alternative to Bayesian tech-
niques is the increase of the coherent integration time. The increased integration 
time results in a synthetic antenna aperture, thereby already mitigating multipath 
signals. The long integration increases the energy of the received signals and the 
LSQ scheme might again be optimal. Pilot signals, short-term stable oscillators, a 
MEMS IMU, or difference correlators may help to increase the integration time.
References
  [1]	 Poor, H. V., An Introduction to Signal Detection and Estimation, New York: Springer, 
1988.
  [2]	 Zhou, G., and G. B. Giannakis, “Harmonics in Gaussian Multiplicative and Additive Noise: 
Cramér–Rao Bounds,” IEEE Trans. Signal Processing, Vol. 43, 1995, pp. 1217–1231.
  [3]	 Lehmann, E. L., Testing Statistical Hypothesis, 2nd ed., New York: Wiley, 1986.
  [4]	 Porat, B., Digital Processing of Random Signals, Theory & Methods, Englewood Cliffs, 
NJ: Prentice-Hall, 1994.
  [5]	 D’Andrea, A. N., U. Mengali, and R. Reggiannini, “The Modified Cramér–Rao Bound and 
Its Application to Synchronization Problems,” IEEE Trans. Commun., Vol. 42, 1994, pp. 
1391–1399.
  [6]	 Gini, F., R. Reggiannini, and U. Mengali, “The Modified Cramér–Rao Bound in Vector 
Parameter Estimation,” IEEE Trans. Commun., Vol. 46, 1998, pp. 52–60.
  [7]	 Moeneclaey, M., “On the True and the Modified Cramer-Rao Bounds for the Estimation of 
a Scalar Parameter in the Presence of Nuisance Parameters,” IEEE Trans. Commun., Vol. 
46, 1998, pp. 1536–1544.
  [8]	 Closas, P., et al., “Bayesian Direct Position Estimation,” Proc. 21st International Techni-
cal Meeting of the Satellite Division of the Institute of Navigation (ION-GNNS) 2008, 
Savannah, GA, September 16–19, 2008, pp. 183–190.
  [9]	 NXP Software, “NXP SnapSpot GPS Technology and JOBO photoGPS Capture a Location 
in an Instant,” http://www.software.nxp.com/?pageid=139, 2007.
[10]	 Brown, A., P. Brown, and J. Griesbach, “GeoZigBee: A Wireless GPS Wristwatch Track-
ing Solution,” Proc. 19th Int. Technical Meeting of the Satellite Division of the In-
stitute of Navigation (ION-GNNS) 2006, Fort Worth, TX, September 26–29, 2006, 
pp. 2883–2888.
[11]	 Blewitt, G., “GPS Data Processing Methodology: From Theory to Applications,” in GPS for 
Geodesy, pp. 233–270, Teunissen, P. J. G., and A. Kleusberg, (eds.), New York: Springer, 
1998.
[12]	 Biberger, R., Error Modelling of Pseudolite Signal Reception on Conducting Aircraft Sur-
faces, University FAF Munich, Werner-Heisenberg-Weg 39, D-85577 Neubiberg, http://
www.unibw.de/unibib/digibib/ediss/bauv, 2006.
[13]	 Varanasi, M. K., and B. Aazhang, “Multistage Detection in Asynchronous Code-Division 
Multiple-Access Communications,” IEEE Trans. Commun., Vol. 38, 1990, pp. 509–519.
[14]	 van Dierendonck, A. J., P. Fenton, and T. Ford, “Theory and Performance of Narrow Cor-
relator Spacing in a GPS Receiver,” NAVIGATION, Journal of The Institute of Naviga-
tion, Vol. 39, No. 3, 1992, pp. 265–283.

126	
Signal Estimation
[15]	 Misra, P., and P. Enge, Global Positioning System: Signals, Measurements, and Perfor-
mance, 2nd ed., Lincoln: Ganga-Jamuna Press, 2006.
[16]	 Pany, T., and B. Eissfeller, “Code and Phase Tracking of Generic PRN Signals with Sub-
Nyquist Sample Rates,” NAVIGATION, Journal of The Institute of Navigation, Vol. 51, 
No. 2, 2004, pp. 143–159.
[17]	 Spilker, J. J., Jr., “GPS Signal Structure and Theoretical Performance,” in Global Position-
ing System: Theory and Applications, Vol. I, pp. 57–120, Parkinson, B. W., and J. J. Spilker, 
(eds.), Washington, D.C.: American Institute of Aeronautics and Astronautics Inc., 1996.
[18]	 Rife, D., and R. Boorstyn, “Single Tone Parameter Estimation from Discrete-Time Obser-
vations,” IEEE Trans. Information Theory, Vol. 20, No. 5, 1974, pp. 591–598.
[19]	 Pany, T., and B. Eissfeller, “Use of a Vector Delay Lock Loop Receiver for GNSS Signal 
Power Analysis in Bad Signal Conditions,” PLANS 2006, IEEE/ION Position, Location 
and Navigation Symposium, San Diego, CA, April 25–27, 2006, pp. 893–903.
[20]	 Kaplan, E. D., and C. J. Hegarty, (eds.), Understanding GPS: Principles and Applications, 
2nd ed., Norwood, MA: Artech House, 2006.
[21]	 Thomas, J. B. Jr., inventor. California Institute of Technology, assignee, “Digital Signal 
Processor and Processing Method for GPS Receivers,” U.S. Patent No. 4821294, 1989.
[22]	 Jaffe, R., and E. Rechtin, “Design and Performance of Phase-lock Circuits Capable of Near-
Optimum Performance over a Wide Range of Input Signal and Noise Levels,” IEEE Trans. 
Information Theory, Vol. 1, 1955, pp. 66–76.
[23]	 van Dierendonck, A. J., “GPS Receivers,” in Global Positioning System: Theory and Ap-
plications, volume I, pp. 329–407, Parkinson, B. W., and J. J. Spilker, (eds.), Washington, 
D.C.: American Institute of Aeronautics and Astronautics Inc., 1996.
[24]	 Tsui, J. B. Y., Fundamentals of Global Positioning System Receivers: A Software Approach, 
2nd ed., New York: Wiley, 2005.
[25]	 Eissfeller, B., Schriftenreihe der Universität der Bundeswehr (55): Ein dynamisches Fehler-
modell für GPS Autokorrelationsempfänger. University of Federal Armed Forces Munich, 
Werner-Heisenberg-Weg 39, D-85577 Neubiberg, 1997.
[26]	 Kazemi, P. L., “Optimum Digital Filters for GNSS Tracking Loops,” Proc. 21st Int. Tech-
nical Meeting of the Satellite Division of the Institute of Navigation (ION-GNNS) 2008, 
Savannah, GA, September 16–19, 2008, pp. 2304–2313.
[27]	 Won, J. H., T. Pany, and B. Eissfeller, “Design of a unified MLE tracking for GPS/Gali-
leo software receivers,” Proc. 19th Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation (ION-GNNS) 2006, Fort Worth, TX, September 26–29, 2006, 
pp. 2396–2406.
[28]	 Nunes, F. D., F. M. G. Sousa, and J. M. N. Leitao, “BOC/MBOC Multicorrelator Receiver 
with Least-Squares Multipath Mitigation Technique,” Proc. 21st Int. Technical Meeting of 
the Satellite Division of the Institute of Navigation (ION-GNNS) 2008, Savannah, GA, 
September 16–19, 2008, pp. 652–662.
[29]	 Won, J. H., T. Pany, and B. Eissfeller, “Implementation, Verification and Test Results of a 
MLE-Based F-Correlator Method for Multi-Frequency GNSS Signal Tracking,” Proc. 20th 
Int. Technical Meeting of the Satellite Division of the Institute of Navigation (ION-GNNS) 
2007, Fort Worth, TX, September 25–28, 2007, pp. 2237–2249.
[30]	 Spilker, J. J. Jr., “Fundamentals of Signal Tracking Theory,” in Global Positioning System: 
Theory and Applications, Vol. I, pp. 245–328, Parkinson, B. W., and J. J. Spilker, (eds.), 
Washington, D.C.: American Institute of Aeronautics and Astronautics Inc., 1996.
[31]	 Alban, S., D. M. Akos, and S. M. Rock, “Performance Analysis and Architectures for INS-
Aided GPS Tracking Loops,” Proc. Institute of Navigation National Technical Meeting 
(ION-NTM) 2003, San Diego, CA, January 22–24, 2003, pp. 611–622.
[32]	 Landis, D., et al., “A Deep Integration Estimator for Urban Ground Navigation,” PLANS 
2006, IEEE/ION Position, Location and Navigation Symposium, San Diego, CA, April 
25–27, 2006, pp. 927–932.

4.8  Discussion	
127
[33]	 Groves, P. D., C. J. Mather, and A. A. Macaulay, “Demonstration of Non-Coherent Deep 
INS/GPS Integration for Optimised Signal-to-Noise Performance,” Proc. 20th Int. Techni-
cal Meeting of the Satellite Division of the Institute of Navigation (ION-GNNS) 2007, Fort 
Worth, TX, September 25–28, 2007, pp. 2627–2638.
[34]	 Lashley, M., D. M. Bevly, and J. Y. Hung, “Performance Analysis of Vector Tracking Al-
gorithms for Weak GPS Signals in High Dynamics,” Journal of Selected Topics in Signal 
Processing (J-STSP) (GNSS and Robust Navigation), 2009.
[35]	 Anghileri, M., et al., “An Algorithm for Bit Synchronization And Signal Tracking In Soft-
ware GNSS Receivers,” Proc. 19th Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation 2006, Fort Worth, TX, September 26–29, 2006, pp. 1836–1848.
[36]	 Ziedan, N. I. and J. L. Garrison, “Bit Synchronization and Doppler Frequency Removal at 
Very Low Carrier to Noise Ratio Using a Combination of the Viterbi Algorithm with an Ex-
tended Kalman Filter,” Proc. 16th Int. Technical Meeting of the Satellite Division of the Insti-
tute of Navigation (ION-GPS) 2003, Portland, OR, September 9–12, 2003, pp. 616–627.
[37]	 Ávila Rodríguez, J. Á., T. Pany, and G. Hein, “Bounds on Signal Performance Regarding 
Multipath-Estimating Discriminators,” Proc. 19th Int. Technical Meeting of the Satellite 
Division of the Institute of Navigation (ION-GNNS) 2006, Fort Worth, TX, September 
26–29, 2006, pp. 1710–1722.
[38]	 Lohan, E.-S., R. Hamila, and M. Renfors, “Cramer Rao Bound for Multipath Time Delays 
in a DS-CDMA System,” Proc. 4th Int. Symp. Wireless Personal Multimedia Communica-
tions (WPMC’01), Aalborg, September 2001, pp. 1043–1047.
[39]	 Minkler, G., and J. Minkler, Theory and Application of Kalman Filtering, Palm Bay: Magel-
lan Book Company, 1993.
[40]	 Arulampam, M. S., et al., “Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian 
Bayesian Tracking,” IEEE Trans. Signal Processing, Vol. 50, 2002, pp. 174–188.
[41]	 Closas, P., et al., “Multipath Mitigation Using Particle Filtering,” Proc. 19th Int. Technical 
Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 2006, Fort 
Worth, TX, September 26–29, 2006, pp. 1733–1740.
[42]	 Lentmaier, M., et al., “Dynamic Multipath Estimation by Sequential Monte Carlo Meth-
ods,” Proc. 20th Int. Technical Meeting of the Satellite Division of the Institute of Naviga-
tion (ION-GNSS) 2007, Fort Worth, TX, September 25–28, 2007, pp. 1712–1721.
[43]	 Psiaki, M. L., “Block Acquisition of Weak GPS Signals in a Software Receiver,” Proc. 14th 
Int. Technical Meeting of the Satellite Division of the Institute of Navigation (ION-GPS) 
2001, Salt Lake City, UT, September 11–14, 2001, pp. 2838–2850.
[44]	 Humphreys, T. E., et al., “GPS Carrier Tracking Loop Performance in the Presence of 
Ionospheric Scintillations,” Proc. 18th Int. Technical Meeting of the Satellite Division of 
the Institute of Navigation (ION-GNNS) 2005, Long Beach, CA, September 13–16, 2005, 
pp. 156–167.
[45]	 Petovello, M. G., C. O’Driscoll, and G. Lachapelle, “Weak Signal Carrier Tracking Using 
Extended Coherent Integration With an Ultra-Tight GNSS/IMU Receiver,” Proc. European 
Navigation Conference (ENC-GNSS) 2008, Toulouse, April 22–25, 2008.
[46]	 Niedermeier, H., et al., “Reproduction of User Motion and GNSS Signal Phase Signatures 
Using MEMS INS and a Pedestrian Navigation System for HS-GNSS Applications,” Proc. 
4th ESA Workshop on Satellite Navigation User Equipment Technologies, NAVITEC, 
Noordwijk, the Netherlands, December 10–12, 2008.
[47]	 Pany, T., M. Paonni, and B. Eissfeller, “Synthetic Phased Array Antenna for Carrier/Code 
Multipath Mitigation,” Proc. European Navigation Conference (ENC-GNNS) 2008, Tou-
louse, April 22–25, 2008.

129
c h a p t e r  5
Signal Detection
Position determination is essentially an estimation problem, using the received sig-
nal samples to obtain a good position estimate, as described in Chapter 4. Position 
estimation also includes the estimation of signal power values (see Section 4.3.2.9) 
and one may use this information to decide if the received navigation signals are 
sufficient in number and strength so that the obtained position estimate can be con-
sidered valid. On the other hand, this argument can be seen as a signal-detection 
problem: deciding between different hypotheses whether one or more navigation 
signals are received at all or if only noise is received. 
In the following discussion, a statistical test (more specifically, a binary- 
hypothesis-testing problem) is set up, where a hypothesis H0 is contrasted to a hy-
pothesis H1. They are defined as:
­H0: Only noise is received
­H1: A navigation signal is received
A definition of the term navigation signal in the context of signal detection is 
given in Section 5.2. Mathematically, a statistical test is a function F(S) of the signal 
samples S that may take two values: zero or one. If F(S) assumes the value zero, 
the test decides that the signal samples stem from a distribution belonging to the 
hypothesis H0 and vice versa. The probability of correctly identifying that H1 is true 
shall be called probability of detection pd (or power) and is given as
	
1
( )
: signal parameters comply to
d
p
H
= F
S
S
S
	
(5.1)
The probability to incorrectly decide for H1 although H0 is true is called false 
alarm rate pfa (or significance level or size) and is given as
	
0
( )
: signal parameters comply to
fa
p
H
= F
S
S
S
	
(5.2)
Different detection schemes can be chosen that are either optimized according 
to certain criteria described in Section 5.1.1 or follow an engineering approach 
based on the ML estimation of Section 5.7. The latter approach also gives esti-
mated signal parameter values that can be used as starting values for an estimation 
algorithm. 
5.1  Detection Principles
The basic statistical groundwork for the design of detectors of a signal-in-noise 
problem follows directly from the theory of hypothesis testing. One approach, 

130	
Signal Detection
which will be addressed, is simple hypothesis testing in which the distribution of 
the signal samples S is assumed to be completely known. By contrast, for composite 
hypothesis testing, the distribution of the signal samples depends on one or more 
unknown parameters, such as the code phase or Doppler.
5.1.1  Simple Hypothesis Testing
Simple hypothesis testing is a less-commonly used approach in a navigation re-
ceiver because the basic signal sample distribution is parameter-dependent, as can 
be seen, for example, in (1.18). However, a parameter-independent distribution can 
be obtained by integrating the parameters out. This requires knowledge of the a 
priori distribution of the unknown parameters. The resulting sample distribution 
function is parameter-independent and cannot be used for any parameter estima-
tion technique. However, the simple hypothesis-testing approach gives theoretical 
insight into the detection problem and may have practical applications for signal 
detection verification.
A probability density function under H1 that is suitable for simple hypothesis 
testing is obtained from the parameterized distribution px(S) of (4.11) by treating 
all parameters as nuisance parameters (see Section 4.1.2) and integrating them out 
as described in Section II.E of the work by Poor [1] 
	
1( )
( ) ( )
H
p
p
p
d
L
=
x
x
S
S
x
x
	
(5.3)
The integral is performed over all admissible values for x and the a priori dis-
tribution p(x) of the parameters x has to be known. The parameters can either be 
position parameters or high-rate pseudorange parameters, as discussed in Section 
5.2. In the simple hypothesis-testing approach, we test against a distribution that is 
valid if no signal is present (hypothesis H0). For both hypotheses, we assume that 
the noise parameters (e.g., its variance) are known; then, the sample distribution 
under H0 does not depend on any parameter. The simple hypothesis approach is 
summarized as
	
1
0
1
0
( )
( )
H
H
H
p
H
p
S
S 	
(5.4)
Bayesian and Neyman–Pearson detectors can be employed for this problem. 
The first detector minimizes the Bayesian risk; the second is based on the Neyman– 
Pearson criterion and optimizes the detection probability under the constraint of 
a limited false-alarm rate. Both tests are based on the likelihood ratio L(s) and 
compare this ratio to a threshold γ. The thresholds are different, depending on the 
chosen approach (Bayesian or Neyman–Pearson) as described, for example, in Sec-
tion 3 of Kay’s book [2]. For a given set of measured sample s, the hypothesis H1 
is chosen if
	
1
0
( )
( )
( )
H
H
p
L
p
γ
=
>
s
s
s
	
(5.5)

5.1  Detection Principles	
131
otherwise H0 is chosen. Both detectors, Bayesian and Neyman–Pearson, are optimal 
(minimum risk or maximum probability of detection) and are comparably simple. 
However, a significant computational difficulty arises because it is virtually impos-
sible to evaluate (5.3) in a closed form. For a more detailed introduction to simple 
hypothesis testing, the reader is referred to the textbooks by Poor and Kay [1, 2].
5.1.2  Composite Hypothesis Testing
Composite hypothesis testing refers to a situation where the sample distribution 
depends on one or more parameters. In the case of a navigation signal, this is the 
normal situation under H1 because the fundamental signal parameters (position or 
code phase, Doppler, amplitude, and carrier-phase values) are generally unknown. 
In the following, we use the notation 
	
(
)
1
( )
H
p
px
S x
S 	
(5.6)
to denote the sample distribution dependency on the parameters x. The hypothesis 
H1 is represented by a family of distributions indexed by the values of the signal 
parameters x. All admissible parameter values x for H1 must correspond to a situa-
tion where a signal is actually present (i.e., the signal amplitude must be larger than 
zero). By contrast, the hypothesis H0 may describe either a situation where only 
noise is received or a situation where noise plus further signals (e.g., signals from 
different transmitters) are received. Thus, the H0 sample distribution may either be 
completely known or parameter-dependent. 
5.1.2.1  Conversion from Composite to Simple Hypothesis Testing
If the a priori distributions of the signal parameters are known, then the composite 
hypothesis-testing problem can be converted to a simple hypothesis-testing problem, 
as described in Section 5.1.1, by integrating the parameters out. Therefore, simple and 
composite hypothesis testing are related. Elimination of signal parameters from the 
sample distribution may also be done for only a subset of parameters, as described in 
Sections 5.4, 5.7.1, 5.7.2.1, and 5.7.4.1. Finally, we understand under a true compos­
ite hypothesis-testing problem a situation in which the sample distribution depends 
on at least one parameter (i.e., a situation where not all parameters are integrated 
out). In Section 5.1.2.2, true composite hypothesis-testing problems are treated as 
Neyman–Pearson problems in an attempt to optimize the detection probability.
5.1.2.2  Nonexistence of a Uniform Most Powerful Test
For a true composite hypothesis-testing problem, it would be desirable to construct 
a test whose performance is optimal for all possible signal parameters. Because 
the signal parameters are unknown, the formula for the test statistics needs to be 
obviously independent of the (unknown) signal parameter’s values and needs to be 
a function only of the signal samples. Furthermore, if the test yields a maximum 
detection probability (under the assumption of a limited false alarm rate) it would 
be called a uniform most-powerful test.

132	
Signal Detection
It seems impossible, however, to construct a composite hypothesis test that is 
optimal for all admissible signal parameters if navigation signal parameters like 
code phase and Doppler are unknown. A uniform most powerful test would exist 
only if the distribution depends on only a single parameter, the test is single-sided, 
and the likelihood ratio is a monotone nondecreasing function of a test statistic 
(see Section 4.7 of [3] or Theorem 2 in Chapter 3 of Lehmann’s work [4]). Such 
a case, however, is not applicable here. See also Chapter 3 of Lehmann’s work for 
a discussion of dual-sided tests. Sections 5.4 and 5.7.2.2 further discuss uniform 
most-powerful tests for navigation signal detection. 
5.1.2.3  Uniform Most-Powerful Unbiased Test
A simple condition that one may wish to impose on a hypothesis test is that, for all 
admissible parameter values, the probability of detection should be larger than the 
false alarm rate. Unless such a condition is satisfied, there would exist specific signal 
parameter values where it is more likely to not detect the signal when it is present 
than to incorrectly detect it when it is not present. Such a test would not make 
sense, and this class of tests can be excluded from our considerations. 
More specifically, we adopt the definition from Chapter 4 of Lehmann for an 
unbiased test [4]. A hypothesis test that fulfills
	
1
fa
d
p
p
α
-
	
(5.7)
for some constant α between zero and one is called unbiased.
If we limit ourselves to tests that are unbiased, an optimal test (i.e., a uniform 
most-powerful test) can be found more easily. This kind of test is then called a uni-
form most-powerful unbiased test (UMPUT) and is the best possible test among all 
unbiased tests. 
5.1.2.4  Generalized Likelihood-Ratio Test
A common approach to handle a composite hypothesis-testing problem is to con-
struct a generalized likelihood-ratio test (GLRT). A GLRT is based on the likeli-
hood ratio (5.5) and replaces the unknown parameters with their ML estimates. 
Although there is no optimality associated with the GLRT, it appears to work quite 
well and is the commonly used basis for signal acquisition in a GNSS receiver (see 
Section 6.4.2. in the book by Kay [2]). For a given set of measured sample s, the 
GLRT decides H1 if 
	
(
)
(
)
1
1
1
0
0
ˆ
ˆ
,
( )
ˆ
H
H
H
H
H
p
L
p
γ
=
>
s x
s
s
ξ
ξ
	
(5.8)
Here, the parameters have been divided into x and ξ, where x refers to param-
eters of the signal to be detected and ξ refers to parameters related to additional sig-
nals or to noise. The symbol ^ indicates that the ML estimates are used to evaluate 
the sample distribution (see Section 4.2.3). The ML estimates for ξ obtained under 
the assumption H0 or H1 are, in general, different. This detection approach also 

5.3  Preprocessing	
133
provides the estimated parameter values xˆ  that can, in turn, be used for starting a 
signal estimation algorithm.
5.2  Detection Domains
Similar to Sections 4.2.3 and 4.2.4, the detection problem can be formulated in 
terms of generalized position parameters or in terms of generalized pseudorange 
parameters. In the first case, the navigation signal is defined on the position do­
main, whereas, in the latter case, the navigation signal is defined on the pseudo­
range domain. 
5.2.1  Pseudorange Domain Detection
Navigation signal detection in the pseudorange domain usually implies that the 
fundamental signal parameters are code phase, Doppler, carrier phase, and signal 
amplitude, as described in Section 1.8. If pseudorange domain detection is consid-
ered—the standard case for a GNSS receiver—a situation arises where a superpo-
sition of many navigation signals is received and their mutual influence has to be 
properly accounted for; this will be described in Section 5.7.3. 
5.2.2  Position Domain Detection
For position domain detection, the signals of all transmitters collapse into one sig-
nal, which is the superposition of all signals. The combined signal parameters are 
the generalized position parameters, as introduced in Section 4.1.1. Signal detection 
in the position domain has similar advantages as single-step position estimation 
for snapshot processing, as described in Section 4.2.3. The signal power of the in-
dividual signals accumulates and the combined signal has a higher signal-to-noise 
ratio than the single signals. 
5.3  Preprocessing
If the implementation of signal-detection (or acquisition) algorithms in a navigation 
receiver is considered, two important issues are considered. First, signal detection is 
computationally cumbersome if the signal amplitude is below or similar to the noise 
amplitude. The detection involves a search in the space of unknown parameters and 
a multitude of test parameters have to be evaluated before the presence of a naviga-
tion signal can be declared. Second, during signal detection it is generally sufficient 
to estimate signal parameters with a low accuracy. In the context of ML estimation, 
signal detection can be considered to be a coarse synchronization and signal estima-
tion provides, via fine synchronization, precise parameter estimates. 
Consequently, it proves useful to employ a number of preprocessing steps dur-
ing signal detection that aim at a computational burden reduction at the cost of 
a decreased accuracy of the coarse synchronization parameters. Those steps may 
include the following points in a suitable order:

134	
Signal Detection
­Frequency conversion (e.g., from IF to baseband);
­Resampling (e.g., to allow FFT techniques);
­Filtering (e.g., to reduce the signal bandwidth and consequently the working 
sample rate).
The first two points are more technical but may introduce losses in the effective 
signal power due to implementation constraints. Those effects are not discussed 
here. By contrast, filtering is of special importance because the immense computa-
tional load can be drastically reduced if the signal bandwidth can be reduced. This 
allows for using a lower sample rate. For example, a GNSS signal acquisition algo-
rithm exists that makes use of only a fraction of the full signal bandwidth. Typically 
this occurs when the spectral main lobe is used to acquire a BPSK signal. The BOC 
side-lobe acquisition algorithm effectively uses only one side lobe of a BOC signal 
and discards the second lobe [5]. For a BOC(n,n) signal, the sample rate is reduced 
by a factor of two, the signal power loss is around 3 dB, and the working correla-
tion function has a simple triangular shape compared to the full BOC autocorrela-
tion function. For direct GPS P(Y) code acquisition, it might be convenient to work 
with only a fraction m of the bandwidth of the main lobe (the bandwidth being 
centered around the carrier frequency). The work sample rate can then be reduced 
by a factor of m and the signal power is also reduced by a factor of m. This signal 
power loss can, however, be compensated by increasing the coherent integration 
time by m. The same detection sensitivity is achieved, but during a signal acquisition 
step a m-times-larger portion of all code-phase values is tested [6–8]. 
In Section 5.4, these preprocessing steps will not be mentioned explicitly, but 
it should be noted that the considered navigation signal might have been subject to 
one or more of the above-mentioned preprocessing steps. 
5.4  Clairvoyant Detector for Uniformly Distributed Phase
The term clairvoyant detector was introduced in Chapter 6 of Kay’s book and refers 
to a true composite hypothesis-testing problem [2]. The detector makes use of the 
otherwise unknown signal parameter values. Generally, the clairvoyant detector is 
of a hypothetical nature and does not exist in practice. 
The clairvoyant detector has theoretical importance and may serve as a refer-
ence detector in the same sense as the Cramér–Rao lower bound defines a reference 
for several estimation strategies. In addition, the clairvoyant detector can be used 
if the unknown signal parameters are available from an external source. This is of 
particular importance if vector tracking, as described in Section 4.3.3.3, is used. 
To give an example of a clairvoyant detector, we assume that a single navigation 
signal is present (or not) and the signal parameters (see Section 1.8) as well as the 
Gaussian noise distribution parameters (see Section 1.7) are assumed to be known. 
The sample distribution under H1 is
	
, ,
,
exp
(
)exp{
}
p
a
s
a c t
i t
i
τ ω ϕ
τ
ω
ϕ
=
-
-
-
-
(
)
1
2
1
1
1
2
(2 )
L
H
L
µ
µ
µ
µ
π
=
s
	
(5.9)

5.4  Clairvoyant Detector for Uniformly Distributed Phase	
135
Here, a  denotes the real-valued signal amplitude.
For this example, we assume that the carrier phase ϕ is uniformly distributed 
between 0 and 2π. The sample distribution for a uniformly distributed carrier phase 
is obtained by integrating out the carrier phase, yielding
	
(
)
1
2
2
1
0
2
2
2
2
1
1
1
0
1
2
2
1
1
1
1
1
, ,
exp
(
)exp{
}
2
2
(2 )
1
1
exp
(
)
2
2
(2 )
Re{
(
)exp{
}}
1
1
exp
2
2
(2 )
L
H
L
L
L
L
L
L
L
p
a
s
a c t
i t
i
d
a
s
c t
a
s c t
i t
i
d
La
s
π
µ
µ
µ
µ
ϕ
π
µ
µ
µ
µ
ϕ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
ϕ
ϕ
π
π
τ
π
τ
ω
ϕ
ϕ
π
=
=
+
=
=
=
=
+
=
=
-
-
-
-
=
-
-
-
+
-
-
=
-
-
s
(
)
2
1
0
2
2
0
1
exp
Re{
(
)exp{
}}
1
1
exp
( , )
2
2
(2 )
L
L
L
a
s c t
i t
i
d
La
s
I
a P
L
π
µ
µ
µ
µ
ϕ
µ
µ
τ
ω
ϕ
ϕ
τ ω
π
=
=
=
-
-
=
-
-
	
(5.10)
with the definition for the correlator value P(τ,ω) as
	
1
1
( , )
(
)exp{
}
L
P
s c t
i t
L
µ
µ
µ
µ
τ ω
τ
ω
=
=
-
	
(5.11)
The likelihood ratio (5.5) evaluates to
	
(
)
(
)
1
0
2
2
0
1
2
1
2
0
1
exp
( , )
2
2
( )
( )
( )
1
exp
2
exp
( , )
2
L
H
L
H
La
s
I
a P
L
p
L
p
s
La
I
a P
L
µ
µ
µ
µ
τ ω
τ ω
=
=
-
-
=
=
-
=
-
s
s
s
	
(5.12)
Because a  > 0 and I0 (the modified-Bessel function of first kind and order zero) 
is a monotone increasing function, the clairvoyant detector decides H1 if
	
2
( , )
P τ ω
γ
>
	
(5.13)

The threshold γ has to be chosen according to the desired optimality criterion. In 
the following discussion, the Neyman–Pearson principle will be employed and it will 
be shown with (5.15) that the threshold γ  is independent of the signal amplitude a . 
Under hypothesis H0, P is the sum of L complex zero-mean Gaussian random 
variables because, in this case, Sm = Nm. The sum is itself a zero-mean Gaussian ran-
dom variable with a complex variance of two because
	
2
2
0
1
,
1
2
1
1
:
( , )
(
)exp{
}
1
(
) (
)exp{
(
)}
2
(
)
2
L
L
L
H
P
N c t
i t
L
N N c t
c t
i
t
t
L
c t
L
µ
µ
µ
µ
µ
υ
µ
υ
µ
υ
µ υ
µ
µ
τ ω
τ
ω
τ
τ
ω
τ
=
=
=
=
-
=
=
-
-
-
=
-
=
N
N
N
	
(5.14)
Here, we assume that the assumption of Section 1.8.1 holds true. According 
to Appendix A.4.6, |P(τ,ω)|2 follows a central chi-squared distribution with two 
degrees of freedom and the false alarm rate is given as
	
(
)
2
2
2
0
;2
( ,
)
|
( )
fa
p
P P
H
Q
e
γ
χ
τ ω
γ
γ
-
=
>
=
=
	
(5.15)
Under hypothesis H1, P(τ,ω) retains the same variance but the squared magni-
tude of its mean value equals La 2 because
	
2
2
1
1
2
1
2
1
1
:
( , )
(
(
)exp{
}
) (
)exp{
}
1
(
(
) (
)exp{
}
(
)exp{
})
1
exp{
}
(
)exp{
}
L
L
L
H
P
a c t
i t
i
N
c t
i t
L
a c t
c t
i
N c t
i t
L
La
i
N c t
i t
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
ϕ
τ
ω
τ
τ
ϕ
τ
ω
ϕ
τ
ω
=
=
=
=
-
-
-
+
-
=
-
-
-
+
-
=
-
+
-
	
(5.16)
Using the definitions of Section 2.2.3 of Kay’s book summarized in Appendix 
A.4.6, |P(τ,ω)|2 belongs to the noncentral chi-squared distribution with two degrees 
of freedom and a noncentrality parameter La 2. Therefore, the probability of detec-
tion is
	
(
)
2
2
0
2
2
2
0
0
2
1
2
/
;2,
;2,
;2,2
/
;2,2
/
( , )
|
( )
( )
( )
( 2log
)
s
coh
coh
d
LC N
La
f
fa
T
C N
T
C N
p
P P
H
Q
Q
Q
Q
p
χ
χ
χ
χ
τ ω
γ
γ
γ
γ
=
>
=
=
=
=
-
	
(5.17)
136	
Signal Detection

5.5  Energy Detector	
137
Here, we used the relationship between the signal amplitude a  and the signal-
to-noise ratio C / N0 from Section 1.8.1.
5.5  Energy Detector
The energy detector uses the sum of squared signal samples to determine if a signal 
is present. The averaged sum of the squared signal samples is an estimate of the 
received signal energy. The energy detector is eventually the simplest detector that 
can be used to detect the presence of a navigation signal. The energy detector’s 
performance is comparably low. The design of the energy detector is not related 
to any optimality criterion and it belongs to the class of simple hypothesis-testing 
detectors. 
The energy detector decides for H1 if 
	
2
1
L
E
sµ
µ
γ
=
=
>
	
(5.18)
for a suitable chosen threshold γ. Here, the Neyman–Pearson principle will be em-
ployed to determine the threshold.
Under the hypothesis H0, the energy E is the sum of L complex Gaussian 
samples, whose real and imaginary components are each of variance one and zero 
mean,
	
2
0
1
:
L
H
E
nµ
µ=
=
	
(5.19)
According to Appendix A.4.6, E belongs to a central chi-squared distribution 
with 2L degrees of freedom and the false alarm probability is given as
	
2
0
;2
2
(
|
)
( )
4
fa
L
L
p
P E
H
Q
Q
L
χ
γ
γ
γ
-
=
>
=
÷	
(5.20)
Equation (5.20) indicates that the chi-squared probability density function can 
be well approximated by the right-tail probability function of the normal distribu-
tion because of the usually large number of involved samples. 
Under the hypothesis H1, the energy E can be written as
	
2
1
1
2
1
2
1
:
(
)exp{
}
(Re{
(
)exp{
}}
Re{
})
(Im{
(
)exp{
}}
Im{
})
L
L
L
H
E
a c t
i t
i
n
a c t
i t
i
n
a c t
i t
i
n
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
ω
ϕ
τ
ω
ϕ
τ
ω
ϕ
=
=
=
=
-
-
+
=
-
-
+
+
+
-
-
+
	
(5.21)

138	
Signal Detection
According to Appendix A.4.6, E belongs (under hypothesis H1) to the non-
central chi-squared distribution with 2L degrees of freedom and a noncentrality 
parameter λ of
	
2
2
1
2
2
0
1
(Re{
(
)exp{
}}
Im{
(
)exp{
}} )
(
)exp{
}
2
/
L
L
coh
a c t
i t
i
a c t
i t
i
a c t
i t
i
La
T
C N
µ
µ
µ
µ
µ
µ
µ
µ
λ
τ
ω
ϕ
τ
ω
ϕ
τ
ω
ϕ
=
=
=
-
-
+
-
-
=
-
-
=
=
	
(5.22)
The detection probability is given by (5.23) and can be well approximated by the 
right-tail probability function of the normal distribution due to the usually large 
number of involved samples 
	
2
0
0
1
;2 ,2
/
0
2
2
/
(
|
)
( )
4
8
/
coh
coh
d
L
T
C N
coh
L
T
C N
p
P E
H
Q
Q
L
T
C N
χ
γ
γ
γ
-
-
=
>
=
÷
+
	
(5.23)
5.6  Bayesian Detector
In this section, a Bayesian detector will be derived; this requires the a priori distribu-
tions of the signal parameters. Particular assumptions will be made that allow for 
the derivation of a partly closed expression for the detector. The Bayesian detector 
integrates all parameters out and can be considered a simple hypothesis-testing 
detector. It will be shown that, for a uniform code-phase and Doppler a priori dis-
tribution, the Bayesian detector equals the generalized likelihood-ratio detector of 
Section 5.7.
We assume that the carrier phase is uniformly distributed between 0 and 2π. 
The sample probability density function under H1 has already been derived for this 
case in Section 5.4 and is given by (5.10). The Bayesian detector is based on the 
likelihood ratio (5.12), but in addition to the carrier phase, the real-valued ampli-
tude a , the code phase τ, and the Doppler ω also have to be integrated out. This 
integration can be directly performed with the likelihood ratio because the sample 
distribution under H0 is independent of the signal parameters. The likelihood ratio 
of the Bayesian detector is given as
	
(
)
1
0
2
0
, ,
( )
( )
( )
( , , )exp
( , )
2
H
H
a
p
L
p
La
p a
I
a P
L da d d
τ ω
τ ω
τ ω
τ ω
=
=
-
s
s
s
	
(5.24)
The detector is based on the same correlator value P(τ,ω) as in Section 5.4
	
1
1
( , )
(
)exp{
}
L
P
s c t
i t
L
µ
µ
µ
µ
τ ω
τ
ω
=
=
-
	
(5.25)

5.6  Bayesian Detector	
139
The real-valued amplitude a , the code phase τ, and the Doppler ω are assumed 
to be statistically independent, 
	
( , , )
( ) ( ) ( )
p a
p a p
p
τ ω
τ
ω
=
	
(5.26)
To further evaluate (5.24), specific expressions for the a priori distributions will 
be given. The distributions aim at a detector for a multipath signal that is expected 
to appear within a certain code phase and Doppler range. The a priori distribution 
for code phase p(τ) and the Doppler p(ω) within the admissible range shall be left 
unspecified. The multipath signal amplitude shall be Rayleigh distributed. The aver-
age power of the multipath signal is assumed to be known.
For an average received multipath signal power of 2s 2a  the probability density 
function of a Rayleigh fading signal is, according to Lee [9], given as
	
2
2
2
( )
exp
2
2
a
a
a
a
p a
σ
σ
=
-
	
(5.27)
Using a tool for analytical mathematics, integration of (5.24) can be carried out 
explicitly, yielding 
	
(
)
(
)
2
2
2
0
2
2
0
( , )
1
( )exp
( , )
exp
2
1
2 1
a
a
a
a
P
L
La
p a
I
a P
L da
L
L
τ ω
σ
τ ω
σ
σ
=
-
=
+
+
	
(5.28)
The integrations with respect to the code phase or Doppler can only be done 
numerically. The obtained likelihood ratio is given as
	
(
)
2
2
2
2
( , )
1
( )
( ) ( )exp
1
2 1
a
a
a
P
L
L
p
p
d d
L
L
τ ω
σ
τ
ω
τ ω
σ
σ
=
+
+
s
	
(5.29)
The Bayesian detector shall be denoted by B and decides for H1 if B exceeds a 
certain threshold
	
(
)
2
2
2
( , )
( ) ( )exp
2 1
a
a
P
L
B
p
p
d d
L
τ ω
σ
τ
ω
τ ω
γ
σ
=
>
+
	
(5.30)
According to Section 3.7 of Kay’s book, the value for the threshold is given by [2]
	
(
)
10
00
0
2
01
11
1
(
) (
)
2
1
(
) (
)
a
C
C
p H
L
C
C
p H
γ
π
σ
-
=
+
-
	
(5.31)
where Cij is the cost if Hi is chosen but Hj is true. The symbol p(H0) denotes the a 
priori probability that H0 is true and p(H1) denotes the a priori probability that H1 
is true. Overall, the Bayesian detector minimizes the cost function
	
(
)
1
,
0
(
)
ij
i
j
j
i j
R
C p H H
p H
=
=
	
(5.32)

140	
Signal Detection
where p(Hi | Hj) is the probability that Hi is detected and Hj is true. The Bayesian 
detector is an optimum detector with respect to this criterion. Note that the 
Neyman-Pearson expression (5.15) was based on pfa and not on any cost function.
If we assume that C10 = C01 = 1 and C00 = C11 = 0, the corresponding Bayesian 
detector minimizes the sum of missed detections plus false detections
	
(
)
(
)
0
1
1
1
0
0
1
0
(
)
(
)
(1
) (
)
(
)
d
fa
R
p H H
p H
p H H
p H
p p H
p p H
=
+
=
-
+
	
(5.33)
It is therefore called a minimum probability of error detector. For a large num-
ber of samples (i.e., Ls 2a >>1), the Bayesian detector can be approximated as
	
2
2
1
( , )
( ) ( )exp
2
a
L
P
B
p
p
d d
σ
τ ω
τ
ω
τ ω
=

	
(5.34)
that is independent of the mean received multipath signal power. The Bayesian 
detector uses contributions from all admissible correlation values, combines them 
properly, and compares the result against a threshold. By contrast, generalized 
likelihood-ratio detectors compare only the maximum correlation value against a 
threshold. As a consequence, the Bayesian scheme does not provide any code-phase 
or Doppler estimates. 
For a uniform distribution of code phase and Doppler, the Bayesian detector 
and a generalized likelihood detector are equivalent because the functional depen-
dency of P as a function of Doppler and code phase is fixed. Only the value of the 
peak and its position in the code-phase/Doppler plane varies. Therefore, being given 
the value of the peak of P allows the calculation of B, as long as the whole support 
of P is located within the admissible code-phase and Doppler values. This depen-
dency can be expressed as 
	
2
,
max
( , )
B
B
P
τ ω
τ ω
=
÷	
(5.35)
Furthermore, B is a monotone increasing function of the peak value of P and, 
thus, the Bayesian test (5.30) equals, for uniform-distributed code-phase and Dop-
pler values, the generalized likelihood-ratio test (5.42). Only in the case of a non-
uniform code-phase and Doppler distribution does the Bayesian test differ from the 
ML scheme. By focusing the search on regions where the signal is more likely to 
appear, it outperforms the generalized likelihood-ratio test (5.42). 
5.7  Generalized Likelihood-Ratio Detector
As mentioned in the introduction, the generalized likelihood-ratio detector is by 
far the most common method to detect a signal in a navigation receiver. In Sec-
tion 5.7.1, different examples for this detector will be given that correspond to 
different signal models and different levels of the signal parameter’s information 
availability. 

5.7  Generalized Likelihood-Ratio Detector	
141
5.7.1  Single Coherent Integration
The (probably) most elementary generalized likelihood-ratio detector is obtained 
when all four fundamental signal parameters described in Section 1.8 are treated as 
unknown constants. The resulting detector is a correlation detector that maximizes 
the correlation function and is derived in the following way. 
Assume a signal model based on a complex signal amplitude a as introduced in 
Section 4.3. The sample distribution is given as
	
(
)
1
2
1
1
1
1
, ,
exp
(
)exp{
}
2
(2 )
L
H
L
p
a
s
ac t
i t
µ
µ
µ
µ
τ ω
τ
ω
π
=
=
-
-
-
s
	
(5.36)
The complex signal amplitude maximum (5.36) has already been obtained in 
(4.63) and is given as
	
1
1
ˆ
(
)exp{
}
L
a
c t
i t
s
L
µ
µ
µ
µ
τ
ω
=
=
-
-
	
(5.37)
The complex signal amplitude estimate is related to the correlator P given in 
Section 5.4 via
	
2
2
( , )
( , )
ˆ
ˆ
P
P
a
a
L
L
τ ω
τ ω
=
=
	
(5.38)
Inserting this expression into (5.36) yields
	
(
)
1
2
2
1
1
2
2
1
2
2
2
2
1
1
ˆ
1
1
ˆ
ˆ
, ,
exp
Re
(
)exp{
}
2
2
(2 )
ˆ
1
1
ˆ ˆ
exp
Re{
}
2
2
(2 )
ˆ
( , )
1
1
1
1
exp
exp
2
2
2
2
(2 )
(2 )
L
L
H
L
L
L
L
L
L
L
L a
p
a
s
a
s c t
i t
L a
s
Laa
L a
P
s
s
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
π
π
τ ω
π
π
=
=
=
=
=
=
-
-
+
-
=
-
-
+
=
-
+
=
-
+
s
	
(5.39)
and the ML estimates for code phase and Doppler are 
	
2
,
ˆ ˆ
,
arg max
( , )
P
τ ω
τ ω
τ ω
=
	
(5.40)
The generalized likelihood ratio is formed as
	
(
)
1
0
2
ˆ ˆ
ˆ, ,
ˆ ˆ
( , )
exp
( )
2
H
H
p
a
P
p
τ ω
τ ω
=
s
s
	
(5.41)

142	
Signal Detection
and the generalized likelihood-ratio detector decides for H1 if
	
2
ˆ ˆ
( , )
P τ ω
γ
>
	
(5.42)
is fulfilled. The detector is basically identical to the clairvoyant detector, apart from the 
difference that the clairvoyant detector uses known code-phase and Doppler values. 
5.7.2  Multiple Coherent Integrations
The number of samples involved in a single coherent integration cannot be arbi-
trarily large because, for a large coherent integration time, the short-period signal 
model described in Section 1.8 will no longer hold. The assumption of a linear 
carrier phase (a constant Doppler) and constant amplitude are likely to fail due to 
variations in the propagation channel, transmitter or receiver motion, clock insta-
bilities, or simply due to the presence of a navigation data bit. 
It is therefore convenient to model a longer duration of received signal samples 
by a concatenation of two or more short-period signal models. This assumes that 
the code phase and Doppler are constant over the whole period, but the carrier 
phase is allowed to jump at the boundaries.
5.7.2.1  Uniformly Distributed Carrier Phase and Constant Amplitude
For the following detector, we split the received samples into two parts. The first 
part comprises the sample indices ranging from 1, … ,L. The second part comprises 
the sample index range from L + 1, … ,2L. Code phase, Doppler, and real-valued 
signal amplitude are assumed to be unknown, constant, and identical for both 
parts. The carrier phases for both parts are modeled as two independent uniformly 
distributed random variables between 0 and 2π.
The corresponding sample distribution is given as
(
)
(
)
1
1
2
2
2
2
1
2
1
1
2
2
,
0
2
2
1
2
2
2
0
1
2
1
1
1
, ,
(2 )
(2 )
(
)exp{
}
1
exp
2
(
)exp{
}
1
1
exp
( , )
2
(2 )
H
L
L
L
L
L
L
p
a
s
a c t
i t
i
d
d
s
a c t
i t
i
s
La
I
a P
L I
µ
µ
µ
π
µ
ϕ ϕ
µ
µ
µ
µ
µ
µ
τ ω
π
π
τ
ω
ϕ
ϕ
ϕ
τ
ω
ϕ
τ ω
π
=
=
= +
=
=
-
-
-
+
÷
÷
-
÷
÷
+
-
-
-
÷
=
-
-
s
(
)
0
2( , )
a P
L
τ ω
	
(5.43)
where a procedure identical to that in Section 5.4 has been used to integrate out the 
carrier phases. 

5.7  Generalized Likelihood-Ratio Detector	
143
It is convenient to define correlator values, each for one sample segment, as
	
1
1
2
2
1
1
( , )
(
)exp{
}
1
( , )
(
)exp{
}
L
L
L
P
s c t
i t
L
P
s c t
i t
L
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
τ ω
τ
ω
=
= +
=
-
=
-
	
(5.44)
The ML estimate for the real-valued signal amplitude is formally written as
	
(
)
(
)
(
)
2
0
1
0
2
ˆ ( , )
arg max
log
( , )
log
( , )
a
a
La
I
a P
L
I
a P
L
τ ω
τ ω
τ ω
=
-
+
+
	
(5.45)
and, in general, this expression has to be evaluated numerically, yielding an ampli-
tude estimate based on the two correlator values P1 and P2. Code-phase and Dop-
pler estimates are obtained by a further maximization step that is written as
	
(
)
(
)
2
,
0
1
0
2
ˆ ( , )
ˆ ˆ
,
arg max
ˆ
ˆ
log
( , )
( , )
log
( , )
( , )
La
I
a
P
L
I
a
P
L
τ ω
τ ω
τ ω
τ ω
τ ω
τ ω
τ ω
-
+
÷
=
÷
+
+
	
(5.46)
The likelihood ratio is evaluated using the ML estimates and the detector de-
cides for H1 if 
	
{
} (
) (
)
1
0
2
0
1
0
2
ˆ ˆ
ˆ
(
, , )
ˆ ˆ
ˆ ˆ
ˆ
ˆ
ˆ
exp
( , )
( , )
( , )
( )
H
H
p
a
La
I a P
L I a P
L
p
τ ω
τ ω
τ ω
τ ω
γ
=
-
>
s
s
	
(5.47)
is fulfilled. The detector (5.47) compares to the single coherent integrator of Section 
5.7.1 or to the noncoherent detector of the next section. It is based on the same cor-
relator values but involves nonlinear operations to combine both correlator values 
to form a test statistic.
5.7.2.2  Uniform Most-Powerful Test
The following discussion will use the probability density function (5.43) and will 
assume that code phase and Doppler are known and that only the real-valued signal 
amplitude is unknown. Both carrier phases are assumed to be uniformly distributed 
between 0 and 2π. Whether the test of Section 5.7.2.1 is uniform most powerful 
with respect to all real-valued signal amplitude values will be investigated.
According to Corollary 2 of Section 3.3 of Lehmann, a uniform most powerful 
exists if the probability density function can be written in such a form as
	
{
}
(
)
( )exp
( ) ( )
( )
p
a
C a
Q a T
h
=
s
s
s 	
(5.48)
where C(a ) and Q(a ) are functions of the amplitude and T(s) and h(s) are func-
tions of the signal samples [4]. The function Q must be strictly monotone. The 
function T(s) acts as a sufficient statistic, as described in Section 4.4.1. The uniform 
most-powerful test is then given by testing T(s) against a threshold γ. Note that the 

144	
Signal Detection
functions C and h cannot be part of the exponential whose argument needs to be a 
product of a s- and an a¢-expression.
Unfortunately, the density function (5.43) is not of the form (5.48) because the 
correlator values appear separately as arguments of the two modified-Bessel func-
tions. However, within the limit of vanishing signal amplitudes, the density function 
(5.43) can be approximated via a Taylor series expansion as
	
1
1,2
2
2
2
2
2
2
1
2
2
1
( , )
(
, , )
1
1
1
exp
( , )
( , )
2
4
(2 )
H
L
L
La P
p
a
s
La
La
P
P
µ
µ
τ ω
τ ω
τ ω
τ ω
π
=
-
-
+
+
s

	
(5.49)
That is of the form (5.48). Based on this approximation, a uniform most- 
powerful test is given by
	
2
2
1,2
1
2
( , )
( , )
( , )
La P
P
P
τ ω
τ ω
τ ω
γ
+
>

	
(5.50)
The sum of the squared correlator values is formed similar to Section 5.7.2.3 
and is compared against a threshold γ.
For an infinitely large signal amplitude, the asymptotic form of the modified Bessel 
function
	
0
1
( )
exp{ }
2
x
I x
x
x
π

	
(5.51)
can be used to approximate (5.43) as
	
(
)
{
}
1
1,2
2
1
2
2
2
2
1
2
1
( , )
(
, , )
exp
( , )
( , )
1
1
exp
2
(2 )
2
( , )
( , )
H
L
L
La P
p
a
La
P
P
s
La
a
L P
P
µ
µ
τ ω
τ ω
τ ω
τ ω
π
π
τ ω
τ ω
=
+
-
-
s

	
(5.52)
This approximation fits also into (5.48) using the assignments
	
{
}
2
2
1
2
2
2
1
2
1
1
1
( )
exp
2
(2 )
( )
( )
( , )
( , )
1
1
( )
exp
2
( , )
( , )
L
L
C a
La
a
Q a
La
T
P
P
h
s
L P
P
µ
µ
π
π
τ ω
τ ω
τ ω
τ ω
=
=
-
=
=
+
=
-
s
s
	
(5.53)
and a uniform most-powerful test given by T(s) tests the sum of the magnitudes of 
the correlator values against a threshold γ. The test is written as
	
1,2
1
2
( , )
( , )
( , )
La P
P
P
τ ω
τ ω
τ ω
γ
+
>

	
(5.54)

5.7  Generalized Likelihood-Ratio Detector	
145
To further analyze which approximation is valid, the arguments of the modified 
Bessel functions are rewritten as
	
2
1,2
0 1,2
0 1,2
0 1,2
1
( , )
1
4
(
/
)
1
2
(
/
)
1
4
(
/
)
coh
coh
coh
La P
La
T
C N
T
C N
T
C N
τ ω
=
+
÷
=
+
÷
N
	
(5.55)
whose minimum value equals ½ for a vanishing signal power. For this value, 
the Bessel function evaluates to log I0(0.5) = 0.0615 and the approximation used 
to obtain (5.49) evaluates to ¼ 0.52 = 0.0625. Thus, for low signal power values, 
(5.49) seems to be a reasonable approximation.
The calculation can be loosely summarized as “if small signal amplitudes are 
expected, the squared correlators shall be added.” If large signal amplitudes are ex-
pected, the absolute values of the correlators are added to obtain (for the respective 
range of amplitude values) a uniform most-powerful test. 
A consequence of this investigation is that, for an unknown signal amplitude 
(plus the other assumptions made in Section 5.7.2.1), no uniform most-powerful 
detector exists, because without a priori knowledge of the signal amplitude we do 
not know how to add the correlator values for threshold comparison. It should be 
mentioned that, for the case of a single signal segment, a uniform most-powerful 
detector exists: the clairvoyant detector of Section 5.4.
5.7.2.3  Unknown Carrier-Phase Distribution and Unknown Amplitude
The following detector uses the same assumptions as in Section 5.7.2.1, the only 
difference is that the carrier phases are treated as unknown and their ML estimates 
also need to be determined. We use two independent complex signal amplitude 
values for the different signal segments and the amplitudes are treated as unknown 
constants.
Overall, the probability density function is given as
	
1
2
1
2
1
2
1
2
2
2
1
1
1
(
,
, , )
exp
(
)exp{
}
2
(2 )
1
exp
(
)exp{
}
2
L
H
L
L
L
p
a a
s
a c t
i t
s
a c t
i t
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
π
τ
ω
=
= +
=
-
-
-
-
-
-
s
	
(5.56)
The complex signal amplitudes maximizing (5.56) are for a fixed code-phase 
and Doppler value completely independent of each other and are obtained in anal-
ogy to (4.63) as
	
1
1
2
2
1
1
ˆ
(
)exp{
}
1
ˆ
(
)exp{
}
L
L
L
a
c t
i t
s
L
a
c t
i t
s
L
µ
µ
µ
µ
µ
µ
µ
µ
τ
ω
τ
ω
=
= +
=
-
-
=
-
-
	
(5.57)

146	
Signal Detection
The amplitude estimates are related to the correlator definitions of (5.44) via
	
2
2
( , )
ˆ
1,2
k
k
P
a
k
L
τ ω
=
=
	
(5.58)
Similar to Section 5.7.1, the probability density function using the ML signal 
amplitude estimates is obtained as
	
1
2
2
2
1
2
1
2
2
1
1
1
1
1
ˆ
ˆ
(
,
, , )
exp
( , )
( , )
2
2
2
(2 )
L
H
L
p
a a
s
P
P
µ
µ
τ ω
τ ω
τ ω
π
=
=
-
-
-
s
	
(5.59)
and the ML code-phase and Doppler estimates are derived by maximizing the fol-
lowing expression
	
2
2
1
2
,
ˆ ˆ
,
arg max
( , )
( , )
P
P
τ ω
τ ω
τ ω
τ ω
=
+
	
(5.60)
The likelihood ratio derives then as
	
1
0
2
2
1
2
1
2
ˆ ˆ
ˆ
ˆ
(
,
, , )
1
1
ˆ ˆ
ˆ ˆ
exp
( , )
( , )
( )
2
2
H
H
p
a a
P
P
p
τ ω
τ ω
τ ω
=
-
-
s
s
	
(5.61)
and the detector decides for H1 if the sum of the squared correlator values exceeds 
a properly chosen threshold; that is 
	
2
2
1
2
ˆ ˆ
ˆ ˆ
( , )
( , )
P
P
τ ω
τ ω
γ
+
>
	
(5.62)
This detector can be easily extended to a multitude ν of signal segments yielding 
a standard noncoherent detector S given as
	
2
1
ˆ ˆ
( , )
n
n
S
P
υ
τ ω
γ
=
=
>
	
(5.63)
For completeness, the false alarm probability and the detection probability 
shall be evaluated under the assumption that the true code phase and Doppler are 
known. The evaluation is in line with the derivation for the clairvoyant detector of 
Section 5.4 but the number of involved random variables is increased from 2 to 2ν. 
The false alarm probability is given as
	
2
0
;2
(
|
)
( )
fa
p
P S
H
Qχ
υ
γ
γ
=
>
=
	
(5.64)
Under hypothesis H1, and using the definitions in Section 2.2.3 of Kay’s book 
summarized in Appendix A.4.6, S belong to the noncentral chi-squared distribution 
with 2ν degrees of freedom and a noncentrality parameter νLa′ 2. Therefore, the 
probability of detection is
	
2
2
2
0
1
;2 ,
;2 ,2
/
(
|
)
( )
( )
coh
d
La
T
C N
p
P S
H
Q
Q
χ
υ υ
χ
υ
υ
γ
γ
γ
=
>
=
=
	
(5.65)

5.7  Generalized Likelihood-Ratio Detector	
147
Both formulas can be found in many textbooks on GNSS receivers such as that of 
van Dierendonck [10]. 
It should also be mentioned that the assumption of a constant code phase for all 
signal segments needs to be modified if a very long overall signal time span is con-
sidered. In fact, the code phase may drift among the different segments and this has 
to be accounted for in the noncoherent summation of (5.63). However, the drift is 
uniquely determined by the Doppler and therefore, during Doppler estimation, the 
drift is also estimated (only if code and carrier are generated coherently). Inclusion 
of the code-phase drift is thus only of a technical nature and does not change the 
theoretical performance of the detector.
5.7.3  Considering Navigation Signal Interference
Detection of a navigation signal in the pseudorange domains is generally degraded 
by the presence of further signals from other transmitters [11]. These additional 
signals should be accounted for in the detection process.
In the following discussion, a generalized likelihood-ratio detector will be eval-
uated to detect the possible presence of the signal “1”, while a background signal 
“2” is present. Consequently, under hypothesis H1 two signals (“1” and “2”) are 
present, while under hypothesis H0 just one signal (“2”) is present. Both signals 
shall be described by the short period signal model of Section 1.8 and a complex 
valued signal amplitude representation shall be used.
The generalized likelihood ratio is given as
	
(
)
(
)
1
0
1
1
1
2
2
2
2
2
2
,
,
,
,
,
( )
,
,
H
H
p
a
a
L
p
a
τ
ω
τ
ω
τ
ω
=
s
s
s
	
(5.66)
where the sample probability density function under H1 is evaluated as
	
(
)
(
)
1
1
1
1
2
2
2
2
1 1
1
1
2 2
2
2
1
2
2
2
1
2
1
1
1
1
1
2
2
2
2
,
,
,
,
,
1
1
exp
(
)exp{
}
(
)exp{
}
2
(2 )
1
1
exp
2
2
(2 )
exp
Re{
(
)exp{
}}
Re{
(
)exp{
}
H
L
L
L
L
p
a
a
s
a c t
i
t
a c
t
i
t
L
s
a
a
a s c t
i
t
a s c t
i
t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
τ
ω
τ
ω
π
π
τ
ω
τ
ω
=
=
=
-
-
-
-
-
=
-
-
+
-
+
-
s
1
1
1 2 1
1
2
2
1
2
1
}
exp
Re{
(
)
(
)exp{ (
)
}}
L
L
L
a a c t
c
t
i
t
µ
µ
µ
µ
µ
µ
τ
τ
ω
ω
=
=
=
-
-
-
	
(5.67)
According to Section 5.7, the generalized likelihood ratio (5.66) needs to be 
evaluated using the ML estimates of the signal parameters. To further evaluate 

148	
Signal Detection
(5.66) the following important assumption has to be made: The ML parameter 
estimates of the signal “2” are not influenced by the presence of the signal “1.”
Under this assumption, the ML parameter estimates of signal “2” are identical 
under hypothesis H1 and hypothesis H0. This assumption is basically fulfilled if the 
cross-correlation between the two navigation signals is low and if the signal ampli-
tude of signal “1” is not much larger than the amplitude of signal “2.” Signal “2” 
is considered to be a high-power signal, which is acquired first, and signal “1” is a 
low-power signal, which is acquired after acquisition of signal “2.”
If the navigation system under consideration has a low cross-correlation protec-
tion, or for other reasons the mutual influence of the two navigation signals cannot 
be ignored, the following procedure cannot be applied and other detection schemes 
should be employed. One of them could be detection in the positioning domain as 
described above. Alternatively, multiuser detectors such as a decorrelating detector 
or a minimum mean-squared error detector can be employed [12]. If the waveforms 
of all received navigation signals are known, position domain detection is prefer-
able because it optimally combines the received signals, whereas multiuser detectors 
only minimize the influence of the other signals. To the author’s knowledge, both 
techniques are seldom used. 
Assuming the parameters of the signal “2” are identical under the hypothesis 
H1 and hypothesis H0, the likelihood ratio is given as
	
µ
µ
µ
τ
ω
=
-
+
-
-
-
-
{
}
1
0
2
1
1
1
2
2
2
1
1
1
1
1
2
2
2
1
1 2 1
1
2
2
1
2
1
(
,
,
,
,
,
)
exp
Re{
(
)exp{
}}
(
,
,
)
2
exp
Re
(
)
(
)exp{ (
)
}
L
H
H
L
p
a
a
L a
a s c t
i
t
p
a
a a c t
c t
i
t
µ
µ
µ
µ
µ
τ ω
τ
ω
τ
ω
τ
τ
ω
ω
=
=
s
s
	
(5.68)
which can be rephrased as a signal “2” cancellation scheme expressed as
	
1
0
1
1
1
2
2
2
2
2
2
2
1
1 1
1
1
2 2
2
2
1
(
,
,
,
,
,
)
(
,
,
)
exp
Re{
(
)exp{
}(
(
)exp{
})}
2
H
H
L
p
a
a
p
a
L a
a c t
i
t
s
a c t
i
t
µ
µ
µ
µ
µ
µ
τ
ω
τ
ω
τ
ω
τ
ω
τ
ω
=
=
-
+
-
-
-
s
s
	
(5.69)
A replica signal “2” is subtracted from the received signal samples and the dif-
ference signal is used to determine the possible presence of signal “1.” Following 
the discussion of a single coherent integration of Section 5.7.1, an interference- 
corrected correlator is defined as
	
(
)
1
1
2
2
2 2
2
2
1
1
1
1
1
(
,
;
,
)
(
)exp{
}
(
)exp{
}
L
P
s
a c t
i
t
c t
i
t
L
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
τ
ω
τ
ω
=
=
-
-
-
	
(5.70)
Interference-corrected correlators have been implemented in GNSS hardware 
[13] and software receivers [11]. 

5.7  Generalized Likelihood-Ratio Detector	
149
The ML estimates for the code phase and Doppler of signal “1” are obtained 
via maximizing 
	
1
1
2
1
1
1
1
2
2
,
ˆ
ˆ
,
arg max
(
,
;
,
)
P
τ ω
τ
ω
τ ω
τ
ω
=
	
(5.71)
The presence of signal “1” is declared if the correlator exceeds a threshold like
	
2
1
1
2
2
(
,
;
,
)
P τ ω τ
ω
γ
>
	
(5.72)
Provided that the signal “2” parameter estimates are accurate, this detector 
achieves the same performance as the single coherent detector of Section 5.7.1.
5.7.4  Data and Pilot
Modern GNSS signals often exhibit a dual component structure composed of a data 
and pilot signal. This signal structure optimizes the carrier tracking performance 
due to the presence of the pilot signal but still allows broadcasting of the navigation 
data message. Within the transmitter, different multiplexing schemes may be used. 
For certain multiplexing schemes, the received signal may be modeled as
	
1
2
(
(
)
( )
(
))exp{
}
s
a
c t
d c t
i t
µ
µ
µ
µ
β
τ
αψ
τ
ω
=
-
+
-
	
(5.73)
where the c1(t) is used to transmit the pilot signal and c2(t) is used to transmit the 
data signal. Here, a complex signal amplitude representation is used. The relative 
power of the data component is given by α2 and the relative power of the pilot com-
ponent is given by β 2. The sum of the relative signal powers is unity
	
2
2
1
α
β
+
= 	
(5.74)
The cross-correlation between c1 and c2 is assumed to vanish
	
1
2
1
(
)
(
)
0
L
c t
c t
µ
µ
µ
τ
τ
=
-
-
=
	
(5.75)
which can be easily fulfilled by the system designers as the relative code phase and 
Doppler between data and pilot is constant. The data content is coded into the phase 
function ψ (d) that assigns a certain phase to the data signal as a function of the 
broadcast data bit d, which is either +1 or 0. For a QPSK signal, a phase function
	
1
( )
0
i
d
d
i
d
ψ
=
=
-
=
	
(5.76)
is typically used. For the interplex modulation (as, for example, used for the Galileo OS 
on E1) or for time-multiplexed signals (like the L2 civil signal), the phase function
	
1
1
( )
1
0
d
d
d
ψ
=
=
-
=
	
(5.77)
can be used.

150	
Signal Detection
It should be noted that we use the mentioned modulation schemes in a very 
loose sense only to introduce the phase function. The phase function alone is suf-
ficient to describe the relationship between the data and the pilot component. 
Other peculiarities, especially the intermodulation product of the interplex modu-
lation, are ignored here, as that signal component has a low cross-correlation co-
efficient with either the pilot or the data signal and has a much lower power. As 
an alternative to using a different phase function, one could substitute c2(t) with 
ic2(t).
5.7.4.1  Uniformly Distributed Data-Bit Values
If we assume that a “0” data bit and a “1” data bit occur with the same probability, the 
data-bit dependency of the sample distribution function can be integrated out, 
yielding
	
{
}
1
1
2
1
2
0
1
1
2
2
0
1
1
2
1
2
1
(
, , )
1
1
exp
(
(
)
( )
(
))exp{
}
2
2(2 )
1
1
1
exp
2
2
2(2 )
Re
(
(
)
( )
(
))exp{
}
1
1
1
exp
2
2
2(2 )
H
L
L
d
L
L
d
L
L
L
p
a
s
a
c
t
d c
t
i t
s
L a
as
c
t
d c
t
i t
s
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
β
τ
αψ
τ
ω
π
π
β
τ
αψ
τ
ω
π
=
=
=
=
=
=
=
-
-
-
+
-
=
-
-
+
-
+
-
=
-
-
s
2
1
1
1
2
0
1
2
2
1
1
1
2
Re{
(
)exp{
}}
exp
Re{
( )
(
)exp{
}}
1
1
1
exp
Re{
(
)exp{
}}
2
2
2(2 )
exp
Re{
(0)
(
)exp{
L
L
d
L
L
L
L a
a s c t
i t
a
d s c
t
i t
s
L a
a s c
t
i t
a
s c
t
i
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
β
τ
ω
α ψ
τ
ω
β
τ
ω
π
α ψ
τ
ω
=
=
=
=
=
+
-
-
=
-
-
+
-
-
1
2
1
}}
exp
Re{
(1)
(
)exp{
}}
L
L
t
a
s c
t
i t
µ
µ
µ
µ
µ
µ
αψ
τ
ω
=
=
+
-
÷÷
	
(5.78)
For the QPSK phase function, this expression can be further simplified to

5.7  Generalized Likelihood-Ratio Detector	
151
	
{
}
{
}
{
}
{
}
1
2
2
1
1
1
2
1
2
2
1
2
1
(
, , )
1
1
1
exp
Re
(
)exp{
}
2
2
2(2 )
2cosh
Re
(
)exp{
}
1
1
1
exp
Re
( , )
cosh(Re
( , ) )
2
2
(2 )
H
L
L
L
L
L
L
p
a
s
L a
a s c
t
i t
ia s c
t
i t
s
L a
a L P
ia L P
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
β
τ
ω
π
α
τ
ω
β
τ ω
α
τ ω
π
=
=
=
=
=
=
-
-
+
-
-
÷
=
-
-
+
s
	
(5.79)
and it is convenient to define two correlators, each for the data and for the pilot 
signal as
	
1
1
1
2
2
1
1
( , )
(
)exp{
}
1
( , )
(
)exp{
}
L
L
P
s c t
i t
L
P
s c t
i t
L
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
τ
ω
τ ω
τ
ω
=
=
=
-
=
-
	
(5.80)
The ML estimate for the complex signal amplitude results from
	
1
ˆ( , )
arg max
(
, , )
H
a
a
p
a
τ ω
τ ω
=
s
	
(5.81)
This maximization can be carried out analytically by differentiating the log- 
likelihood function with respect to the complex conjugate signal amplitude, yield-
ing the equation 
	
     
{
}
(
)
1
2
1
2
1
1
2
2
2
1
2
log
(
, , )
1
Re{
( , )}
logcosh(Re{
( , )})
2
1
(
( , )
( , )) logcosh
(
( , )
( , ))
2
2
2
sinh Re
( , )
1
( , )
2
2
cosh Re
(
H
d
p
a
da
d
L a
LaP
i La P
da
d
L
L
Laa
aP
aP
iaP
iaP
da
ia L P
L
La
P
ia L P
τ ω
β
τ ω
α
τ ω
β
α
τ ω
τ ω
τ ω
τ ω
α
τ ω
β
τ ω
α
τ
=
=
-
+
+
÷
=
-
+
+
+
-
÷
÷
= -
+
-
s
{
}
(
)
!
2( , ) 0
2
, )
i
L P
α
τ ω
ω
=
(5.82)
This derivative needs to vanish in order to achieve a maximum in the log-likeli-
hood function. It can be rewritten as
	
{
}
(
)
(
)
1
2
2
( , )
( , )tanh Re
( , )
La
L
P
i P
ia L P
β
τ ω
α
τ ω
α
τ ω
=
-
	
(5.83)

152	
Signal Detection
The ML estimate for the complex signal amplitude is formally a function of the 
two correlator values being expressed as
	
1
2
ˆ
ˆ
( , )
(
( , ),
( , ))
a
a P
P
τ ω
τ ω
τ ω
=
	
(5.84)
An approximate solution for (5.83) is obtained by iteration. For the first itera-
tion we set P2 = 0 and obtain a first amplitude estimate as
	
0
1
( , )
( , )
a
P
L
β
τ ω
τ ω
=

	
(5.85)
Inserting the first iteration into the right hand side of (5.83) yields a refined ap-
proximation expressed as
	
{
}
(
)
(
)
{
}
(
)
(
)
1
1
2
0
2
1
2
1
2
1
( , )
( , )
( , )tanh Re
( , )
( , )
1
( , )
( , )tanh Re
( , )
( , )
a
P
i P
ia
L P
L
P
i P
iP
P
L
τ ω
β
τ ω
α
τ ω
τ ω
α
τ ω
β
τ ω
α
τ ω
αβ
τ ω
τ ω
=
-
=
-


	
(5.86)
The equation can be further iterated and converges well. In the following ex-
ample, we stop after the second iteration and use this value as a complex amplitude 
ML estimate:
	
1
ˆ( , )
( , )
a
a
τ ω
τ ω

	
(5.87)
The likelihood ratio is given as 
	
{
}
{
}
(
)
1
0
2
1
2
(
, , )
(
, , )
( )
1
exp
Re
( , )
cosh Re
( , )
2
H
H
p
a
L
a
p
L a
a L P
ia L P
τ ω
τ ω
β
τ ω
α
τ ω
=
=
-
+
s
s
s
	
(5.88)
and the log-likelihood ratio using the complex amplitude ML estimate evaluates 
to
	
{
}
{
}
(
)
2
1
2
1
ˆ
ˆ
log (
, )
( , )
Re
( , )
( , )
2
ˆ
logcosh Re
( , )
( , )
L
L a
a
L P
ia
L P
τ ω
τ ω
τ ω
β
τ ω
τ ω
α
τ ω
= -
+
+
+
s
	
(5.89)
The code-phase and Doppler ML estimates are obtained via maximizing
	
,
ˆ ˆ
,
arg maxlog (
, )
L
τ ω
τ ω
τ ω
=
s
	
(5.90)
and the detector decides for H1 if the detector (in this case the log-likelihood ratio) 
exceeds a suitable chosen threshold γ
	
ˆ ˆ
log (
, )
L
τ ω
γ
>
s
	
(5.91)

5.7  Generalized Likelihood-Ratio Detector	
153
Analyzing (5.86), the detector softly decides between the two data-bit possibili-
ties based on the tanh function. For high signal power levels, the tanh evaluates to 
either +1 or –1, depending on the true data-bit value. Data and pilot information 
are then properly combined and the data bit is removed for the complex ampli-
tude estimate. By contrast, if the signal power is low, the tanh evaluates to a small 
number and the complex amplitude estimate is based only on the pilot correlator 
value P1. 
The presented method of integrating out the data-bit distribution can also be 
applied to design signal tracking algorithms. The resulting code and phase discrimi-
nators are optimal and are discussed in an article by Wang [14].
5.7.4.2  Unknown Data-Bit Value Distribution
The ML principle has to be employed for the data bit, if the distribution of the data-
bit values is unknown and the data-bit distribution cannot be integrated out. The 
data-bit value is then part of the signal sample distribution being written as
	
1
2
1
2
1
2
2
1
1
2
1
(
, , , )
1
1
exp
(
(
)
( )
(
))exp{
}
2
(2 )
1
1
1
exp
2
2
(2 )
Re
(
(
)
( )
(
))exp{
}
H
L
L
L
L
L
p
a
d
s
a
c t
d c t
i t
s
L a
s a
c t
d c t
i t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ ω
β
τ
αψ
τ
ω
π
π
β
τ
αψ
τ
ω
=
=
=
=
-
-
-
+
-
=
-
-
+
-
+
-
s
	
(5.92)
The generalized likelihood ratio evaluates to
	
   
(
)
(
)
1
0
2
1
2
1
, , ,
, , ,
( )
1
exp
Re
(
(
)
( )
(
))exp{
}
2
H
H
L
p
a
d
L
a
d
p
L a
s a
c
t
d c
t
i t
µ
µ
µ
µ
µ
τ ω
τ ω
β
τ
αψ
τ
ω
=
=
=
-
+
-
+
-
s
s
s
(5.93)
and the log-likelihood ratio to
	
(
)
2
1
2
1
log
, , ,
1
Re
(
(
)
( )
(
))exp{
}
2
L
L
a
d
L a
s a
c
t
d c
t
i t
µ
µ
µ
µ
µ
τ ω
β
τ
αψ
τ
ω
=
= -
+
-
+
-
s
	
(5.94)
A data-bit value dependent correlator can be defined as 	

154	
Signal Detection
	
1
2
1
1
( , , )
(
(
)
( )
(
))exp{
}
L
P
d
s
c t
d c t
i t
L
µ
µ
µ
µ
µ
τ ω
β
τ
αψ
τ
ω
=
=
-
+
-
	
(5.95)
and it is related to the correlators (5.80) of the previous section via
	
1
2
( , , )
(
( , )
( )
( , ))
P
d
P
d P
τ ω
β
τ ω
αψ
τ ω
=
+
	
(5.96)
Similar to a single coherent integration of Section 5.7.1, the ML estimate for the 
complex signal amplitude is obtained as
	
1
ˆ( , , )
( , , )
a
d
P
d
L
τ ω
τ ω
=
	
(5.97)
which can be inserted into the log-likelihood function (5.94), resulting in
	
2
2
τ ω
τ ω
τ ω
τ ω
τ ω
= -
+
=
{
}
2
2
1
1
log (
, , )
( , , )
Re
( , , ) ( , , )
( , , )
L
d
P
d
P
d P
d
P
d
s
	
(5.98)
Based on this expression, the ML estimates for code phase, Doppler, and data-bit 
value are obtained via maximization
	
2
, ,
, ,
ˆ
ˆ ˆ
, ,
arg maxlog (
, , )
arg maxlog
( , , )
d
d
d
L
d
P
d
τ ω
τ ω
τ ω
τ ω
τ ω
=
=
s
	
(5.99)
and the detector decides for H1 if the squared correlator values exceed a threshold 
γ, which is written as
	
2
ˆ
ˆ ˆ
( , , )
P
d
τ ω
γ
>
	
(5.100)
5.8  System-Detection Performance
Most implementations of generalized likelihood-ratio detectors presented in previ-
ous sections follow an identical approach. First, a grid of test-parameter values is 
set up and the likelihood ratio is evaluated for all grid points. The grid may extend 
in the code-phase, Doppler, and amplitude direction. The point corresponding to 
the maximum value is chosen as the reference point and its likelihood ratio is com-
pared against a threshold. Due to computational limitations, the grid is occasionally 
subdivided into several subgrids and during one acquisition step, the test points in 
a subgrid are evaluated. The number of grid points to be tested, the size of the sub-
grid, and the chosen detector define the performance of the system in signal detec-
tion. This system-detection performance shall be analyzed in Section 5.8.1. 
The system-detection performance is based on the detection probabilities de-
rived in Sections 5.4 and 5.7.2.3, which assume known code-phase and Doppler 
values. These probabilities are called single-bin detection probabilities. In contrast, 
system-detection probabilities characterize the whole (false) detection performance 
for a given search strategy. The system-detection probabilities derive from the sin-
gle-bin detection probabilities. 

5.8  System-Detection Performance	
155
Another figure of merit to characterize the system-detection performance is the 
mean acquisition time. The mean acquisition time is based on the dwell time, which 
is the time needed for the search algorithm to search one subgrid. The mean acquisi-
tion time is the average time of the algorithm to detect the signal. Mean acquisition 
time and dwell time can be defined as signal time (i.e., the time span defined by the 
number of the received signal samples being processed) or as processing time (i.e., 
the actual processing time of the CPU or the ASIC). In certain cases, processing time 
and signal time may coincide. 
The evaluation of the system-detection probabilities may become a complex 
task because a multitude of correlation values for all grid points are involved, and 
those correlation values are generally correlated random variables, making it dif-
ficult or impossible to derive closed-form expressions [15] for the system-detection 
performance [2]. Often only Monte Carlo methods can be used to evaluate the 
system probabilities. For simplified assumptions, which shall be outlined below, the 
mean acquisition time and the system-detection probabilities will be evaluated.
5.8.1  Idealized Assumptions
To evaluate the system performance, we assume that the search grid spanning all ad-
missible parameter values contains NG points. During one acquisition step, a num-
ber of MG points can be evaluated. The evaluation takes DW seconds. We assume 
that for all grid points the correlation values are evaluated, and for each grid point 
the detector has a single-bin detection probability of pd and a false-alarm probability 
of pfa. We assume that the true signal parameters lie exactly on one of the grid points 
and that the correlation values for all other grid points follow an H0 distribution. 
In other words, if the signal is present on one grid point, it is not present on all oth-
ers. The position of the true grid point is uniformly distributed over all grid points. 
Finally, we assume uncorrelated correlation values on different grid points.
The correlation function of two correlator values is discussed in Section 7.3.1. 
The results presented there imply that, to fulfill the last two assumptions, the grid 
spacing needs to be larger than half of the support of the correlation function (e.g., 
larger than one chip for a PRN code signal) and the Doppler grid spacing is a mul-
tiple of 1/Tcoh. Both requirements are generally not fulfilled in real implementations, 
and shorter grid spacing might be used. In this case, the results presented below 
overestimate the system performance slightly [15]. A further performance degra-
dation arises because, in reality, the true code phase and Doppler do not exactly 
lie on the grid points. Those two simplications will be discussed in Sections 5.8.4 
and 5.8.5.
5.8.2  Mean Acquisition Time
Based on the above assumptions, the mean acquisition time TACQ has been evalu-
ated in the work by Lozow as [16]
	
(1
(1
)
)
1
2
2
G
M
fa
d
ACQ
G
W
d
G
k
p
p
T
N D
p
M
-
-
+
-
=
÷
÷
	
(5.101)

156	
Signal Detection
Here, k is a penalty factor to characterize the time of the system to detect a false 
acquisition. If a signal is falsely detected, the system is assumed to spend kDW sec-
onds to detect its error and then to continue with the normal acquisition procedure. 
The mean acquisition time decreases with an increasing pd. However, an increased 
pd is normally accompanied by a longer dwell time DW, which compensates for the 
decrease. 
5.8.3  System Probabilities
To derive the system-detection probabilities, we assume that NG/MG acquisition 
steps are carried out and that all search-grid values are tested. The probability that 
the signal is detected on the correct grid point (the system-detection probability) 
is denoted as πd. The probability that the system detects a signal although none is 
present is denoted as πfa. 
According to Borio, the system false-detection probability πfa is given as 
	
1
(1
)
G
N
fa
fa
p
π
=
-
-
	
(5.102)
and is independent of the size MG of the subgrid [15]. 
The detection probability πd is given as 
	
(
)
1
1
(1
)
1
( )
( )
1
(1
)
G
G
G
N
M
fa
G
d
fa
d
M
G
fa
p
M
p
q
d
N
p
γ
γ
π
γ
γ
γ
-
=
-
-
=
-
-
-
	
(5.103)
Here, qd(γ  ) is the single-bin probability density function of the detector under 
H1, depending on a variable threshold γ  . The symbol γ  is the detector threshold 
used to obtain the single-bin detection probability
	
( )
d
d
p
q
d
γ
γ
γ
γ
=
=
	
(5.104)
Furthermore, the single-bin false-alarm probability pfa(γ  ) depends also on the 
variable threshold γ  . For small pfa, the single-bin detection probability and the sys-
tem-detection probability are equal to each other, which can be shown by applying 
l’Hôpital’s rule.
5.8.4  Independent Bin Approximation
The assumption of uncorrelated correlation values used in the previous sections 
is often overly simplistic because a grid compatible with this assumption needs to 
have a large grid spacing. In this case, however, the code-phase and Doppler losses 
(as discussed in Section 5.8.5) might become unacceptably large. Therefore, a prac-
tical signal-acquisition scheme using a parallel search technique is normally based 
on correlated correlator values. The fact that adjacent correlator values are corre-
lated reduces the number of independent search bins that primarily affect the false-
detection probability. By contrast, the probability of detection is less influenced by 
the number of bins to be searched.

5.8  System-Detection Performance	
157
In the following discussion, an effective number of independent bins NG′ and 
MG′ will be introduced; it is argued that these effective numbers are used to evalu-
ate formulas of the mean acquisition time (5.101) and of the system false-detection 
probability (5.102). The detection probability remains unchanged. The effective 
number of bins is based on the covariance function of two correlator values, as de-
rived in Section 7.3.1. In the following example, the covariance function is denoted 
by R(Dτ,Dω), where the arguments represent the code-phase and Doppler difference 
of two correlators. The suggested procedure uses Monte Carlo methods using only 
hypothesis H0 signal configurations and consists of the following steps:
­Generate K representative sets of correlator values Pk(τ,ω) on a code-phase/
Doppler grid whose covariance is R(Dτ,Dω). The index k is used to distin-
guish the different runs and ranges from 1 to K. Correlator values belonging 
to two different sets are independent.
­Based on a specific grid point (τ0,ω0), determine a single-bin threshold for 
the squared correlator statistics |Pk(τ0,ω0)|2 and for a chosen single-bin false 
detection probability pfa.
­Using the multibin statistics maxτ,ω |Pk(τ,ω)|2 determine the system false- 
detection probability πfa.
­Determine the effective bin size as
	
log(1
)
log(1
)
fa
fa
p
S
N
π
-
=
-
	
(5.105)
Here, N denotes the number of grid points per set involved in the above proce-
dure. This equation is directly derived from (5.102).
The effective number of bins used to calculate the mean acquisition time or the 
system-detection probabilities are then given as 
	
,
G
G
G
G
N
M
N
M
S
S
=
=
	
(5.106)
The higher the correlation between the bins, the lower the number of effective 
bins and the smaller the increase in the false-detection probability. 
5.8.5  Code-Phase and Doppler Losses
The assumption that the true signal parameters lie exactly on one of the grid points 
under consideration is used in the previous section to derive the mean acquisition time 
or the system-detection probability. This assumption is, however, not normally ful-
filled in practical implementations because computational efforts to search the multi-
tude of grid points (caused by the necessarily fine grid spacing) would be too high. 
It is generally more convenient to work with a larger grid spacing at the cost 
of a decreased detection probability. The decrease in the detection probability 
is caused by the fact that the correlation value is reduced if the true signal pa-
rameters do not lie exactly on the grid point. The reduction of the correlation 
can be expressed based on the expected correlator value, which is derived in 
Section 7.3.1.

158	
Signal Detection
The code-phase and Doppler loss Lτ,ω in decibels can be expressed as
	
0
0
0
0
/ 2
/ 2
,
10
0
0
/ 2
/ 2
1
20log
( , )
(
,
)
L
P
d d
P
τ
δτ
ω
δω
τ ω
τ τ
δτ
ω ω
δω
τ ω
τ ω
δτδω
τ
ω
+
+
=
-
=
-
÷
=
÷
N
N
	
(5.107)
where τ0, ω0 denote the true code-phase and Doppler values. The symbols δτ, δ ω 
denote the code-phase and Doppler spacing. In the limit of infinitesimal spacing, the 
code-phase and Doppler loss is 0 dB.
The code-phase and Doppler loss can be seen as an implementation loss and 
effectively reduces the available power when detecting the signal.
5.9  Long Integration Times and Differential Detectors
The previous discussion clearly demonstrated that by using a long coherent integra-
tion time, nearly arbitrarily weak signals can be detected. The signal information 
contained in each received sample is optimally exploited. For most practical detec-
tion implementations, the use of a coherent integration implies that the short-period 
signal model of Section 1.8 is valid, which corresponds to a linear carrier-phase 
dependency on time (e.g., a constant Doppler is required). In principle, coherent in-
tegration can also be performed over nonconstant Doppler signals, but this requires 
external aiding information that provides the relative antenna motion—a so-called 
m-trajectory—during the integration interval [17]. Long coherent integration also 
requires pilot signals or a data wipe-off functionality. If a linear phase model is 
considered, a number of physical effects limit the coherent integration time, spe-
cifically, transmitter and receiver clock jitter, nonlinear line-of-sight dynamics (e.g., 
user accelerations), or phase fluctuations in the propagation channel. Those effects 
have been assessed, for example, in the articles by Sıçramaz Ayaz, López-Risueño, 
and Niedermeier [17–19]. If a high-quality oscillator (e.g., OCXO) is used, if the 
line-of-sight signal is received (and not a reflection), and if nonlinear line-of-sight 
dynamics are not present or compensated for by an IMU, then the coherent inte-
gration time can be up to a few seconds. If a linear phase dependency can not be 
assumed (and no aiding is available), then it is useful to split up the integration into 
several shorter periods, assuming within each period a linear phase dependency. If 
the carrier phases of each period are modeled as independent random variables, the 
noncoherent integration scheme of Section 5.7.2 is optimal. 
A more stringent requirement on the maximum duration of the coherent integra-
tion time is often imposed by computational limitations. In a first approximation the 
number of bins to be searched increases linearly with the coherent integration time (if 
the timing uncertainty is limited, the number of code phase bins is constant; the num-
ber of Doppler bins increases linearly). Furthermore, the dwell time within each bin 
also increases linearly with the coherent integration time. By using sophisticated al-
gorithms, as described in Sections 9.5.5 and 9.5.6, the increase can be partly reduced 
but, nevertheless, the computational burden is probably the most severe constraint.
A possibility to reduce the computational burden by reducing the number of 
Doppler bins is to use coherent integration times that are below the maximum allow-
able value (i.e., multiple shorter coherent integrations are used instead of one long 

5.10  Discussion	
159
single coherent integration). The caveat of this method is a decreased sensitivity, usu-
ally named squaring loss. The squaring loss originates from the fact the correlation 
values are squared before they are added to remove the carrier-phase dependency. 
Squaring—as a nonlinear operation—reduces the overall performance compared to 
the (linear) coherent integration. The squaring loss is occasionally attributed to a 
reduced postdetection output signal-to-noise ratio value of the test statistics for the 
squaring detector (5.65) compared to the coherent detector (5.17). The postdetec-
tion signal-to-noise ratio value can be used to compare different acquisition strate-
gies. The higher the signal-to-noise, the more sensitive is the detection scheme. In the 
article by Borio, however, it has been shown that the output postdetection signal-to-
noise ratio (corresponding to the deflection coefficient) is unable to completely char-
acterize the acquisition performance; consequently, it should not be used to compare 
different acquisition methods in a strict sense [20]. Instead, it is recommended to 
work with the complete probability distribution and to define the squaring loss as 
the C/N0 difference to achieve a certain probability of detection.
If the maximum coherent integration time cannot be exploited for computa-
tional limitations, differential acquisition schemes can be used. Differential acquisi-
tion schemes use, typically, half the coherent integration time (and thus reduce the 
number of Doppler bins by two). They remove the carrier-phase dependency by a 
multiplication of two correlator values, which are obtained by correlating timely 
separated incoming signal sample batches; that is, an expression in the form
	
1
1
1
ˆ ˆ
ˆ ˆ
( , )
( , )
n
n
n
S
P
P
υ
τ ω
τ ω
γ
-
+
=
=
>
	
(5.108)
is used instead of (5.63) as test statistics. It requires that two adjacent correlator 
values depend similarly on the carrier phase to cancel the carrier-phase dependency 
via multiplication. The expected value of each product is of zero mean in contrast 
to a squared correlator value [used in (5.63)] which is of nonzero mean. Differential 
correlation was first published in Zarrabizadeh and Sousa’s article and has been 
introduced into satellite navigation in Park’s work [21, 22]. Theoretical investiga-
tions performed in articles by Ávila Rodríguez and Schmid demonstrate that the use 
of differential correlation brings a gain of less than 3 dB compared to the squaring 
scheme of Section 5.7.2.3 if the squaring scheme does not fully exploit the maximum 
coherent integration time and uses the same (i.e., half of the maximum) integration 
time as the differential scheme [23, 24]. The differential scheme can also be applied 
by multiplying the nonadjacent correlator values with each other, as described by 
Shanmugam [25]. The differential scheme is sensitive to data-bit transitions and, for 
best performance, it is required that neither of the multiplicands is affected by a data-
bit transition. Losses caused by data-bit transitions are investigated in the works by 
Schmid and Shanmugam [24, 25].
5.10  Discussion
This chapter presented several methods of how signal detection may occur in a nav-
igation receiver. It included “exotic” methods, such as the energy detector, which is 

160	
Signal Detection
easy to implement but does not yield approximate code-phase or Doppler values, 
and detection in the position domain, which has high implementation complexity. 
Established methods are based on signal detection in the pseudorange domain. 
All those methods are characterized by their need to evaluate the correlation values 
for a multitude of code-phase and Doppler values (called grid points). This evalua-
tion is computationally very demanding. However, especially for software receivers, 
there exist a number of sophisticated frequency-domain methods that partly relieve 
the computational demands. These will be discussed in Section 9.5. 
Two different detection principles have been contrasted in this section: Bayesian 
techniques and generalized likelihood-ratio detectors. Bayesian techniques generally 
outperform generalized likelihood-ratio detectors or give at least the same perfor-
mance. The sensitivity gain of using Bayesian methods is, however, small (less than 
1 dB for the data/pilot example) and depends on the characteristics of the available 
a priori information. The more the a priori distribution deviates from a uniform 
distribution, the higher the expected gain.
From a theoretical point of view, an optimum detection scheme does not exist; 
that is, there is no formula for the test statistics, which give an optimum perfor-
mance independent of the true signal-parameter values. Only the clairvoyant detec-
tor is optimal, but this detector needs to know the true code-phase, Doppler, and, 
eventually, amplitude values. 
Overall, generalized likelihood-ratio detectors seem to give a reasonable per-
formance and their implementation is typically simpler than that of a Bayesian 
detector. To design a good generalized likelihood-ratio detector the following points 
should be kept in mind: 
­Shrink the search space to a minimum number of grid points based on all 
information available to the navigation receiver.
­Filter the signal to avoid fine code-phase grid spacings (see Section 5.3).
­Look for an efficient implementation to evaluate the multitude of correlators 
(see Section 9.5).
­Find a good compromise among coherent integration time, number of non-
coherent integrations, and computational complexity (see Section 5.7.2.3).
­Find a suitable acquisition strategy that balances the computational load and 
simultaneously cycles optimally through the signals to be acquired.
­Allow the algorithm to do a self-calibration to determine the threshold for a 
given system false-detection probability. 
In the author’s opinion, the acquisition problem is solved satisfactorily by a 
generalized likelihood-ratio detector. The acquisition problem is mostly a problem 
of implementation that faces the difficulty of realizing a high number of correlators. 
Time-domain correlation, matched filters, and frequency-domain techniques are the 
most common solutions. 
The specific signal structure imposes important boundary conditions. The signal 
defines the required number of code search bins and Doppler search bins. For com-
putational purposes, short periodic signals are desirable. They allow the application 
of FFT-based circular correlation with Doppler preprocessing, the most effective 
software radio acquisition method presented in Section 9.5.6. On the contrary, 

5.10  Discussion	
161
those signals provide small cross-correlation protection, which could be resolved 
using interference cancellation methods as described in Section 5.7.3. In a software-
radio approach, interference cancellation techniques are easier to implement than 
a huge number of correlators (as would be required by a long coherent integration 
time), because subtraction of two signals is a computationally easy task. It should 
also be noted that the used-signal modulation scheme influences only via the code-
phase losses described in Section 5.8.5.
The use of Bayesian techniques, differential detectors, or other specific opti-
mized methods is encouraged if it is useful for a specific application and the imple-
mentation cost is reasonable. However, in the author’s experience, those techniques 
do not improve the performance by more than a few decibels compared to a gen-
eralized likelihood-ratio detector, provided they are based on the same number of 
correlators. For example, a high-sensitivity GPS receiver like the SiRF III copes 
with signal power variations of more than 20 dB and a sensitivity gain of 1–2 dB 
is perhaps not important [26]. More optimization potential lies in the correlator 
implementation. The already-mentioned Doppler preprocessing of Section 9.5.6 
improves the computational FFT performance by about a factor of 10 for a GPS 
C /A-code signal, resulting in 10 times more noncoherent integrations and, conse-
quently, a less than 10-dB sensitivity gain. The highest sensitivity can be achieved if 
long coherent integration times are achieved. This requires the use of pilot signals or 
data wipe-off techniques and imposes restrictions on the user dynamics and on the 
used oscillators. New techniques, like mobile-phone-network-assisted frequency 
and time stability, provision of navigation data bits via assistance data, and user 
dynamics compensation via an inertial sensor integrated into a mobile phone, may 
open new GNSS high-sensitivity applications.
References
  [1]	 Poor, H. V., An Introduction to Signal Detection and Estimation, New York: Springer, 
1988.
  [2]	 Kay, S. M., Fundamentals of Statistical Signal Processing: Detection Theory, Englewood 
Cliffs, NJ: Prentice Hall, 1998.
  [3]	 Scharf, L. L., Statistical Signal Processing: Detection, Estimation, and Time Series Analysis, 
Reading, MA: Addison-Wesley, 1991.
  [4]	 Lehmann, E. L., Testing Statistical Hypothesis, 2nd ed., New York: Wiley, 1986.
  [5]	 Betz, J. W., “Binary Offset Carrier Modulations for Radionavigation,” NAVIGATION, 
Journal of The Institute of Navigation, Vol. 48, No. 4, 2001, pp. 227–246.
  [6]	 Yang, C., J. Vasquez, and J. Chaffee, “Fast Direct P(Y)-Code Acquisition Using XFAST,” 
Proc. 12th Int. Technical Meeting of the Satellite Division of the Institute of Navigation 
(ION-GPS) 1999, Nashville, TN, September 14–17, 1999, pp. 317–321.
  [7]	 Yang, C., et al., “Extended Replica Folding for Direct Acquisition of GPS P-Code and Its 
Performance Analysis,” Proc. 13th Int. Technical Meeting of the Satellite Division of The 
Institute of Navigation (ION-GPS) 2000, Salt Lake City, UT, September 19–22, 2000, 
pp. 2070–2078.
  [8]	 Li, H., M. Lu, and Z. Feng, “Mathematical Modelling and Performance Analysis for 
Average-Based Rapid Search Method for Direct Global Position System Precision Code 
Acquisition,” IET Radar, Sonar & Navigation, Vol. 3, No. 1, 2009, pp. 81–92.
  [9]	 Lee, W. C. Y., Mobile Communications Engineering, New York: McGraw-Hill, 1982.

162	
Signal Detection
[10]	 van Dierendonck, A. J., “GPS Receivers,” in Global Positioning System: Theory and Ap­
plications, Vol. I, pp. 329–407, Parkinson, B. W., and J. J. Spilker, (eds.), Washington, D.C.: 
American Institute of Aeronautics and Astronautics, Inc., 1996.
[11]	 Heinrichs, G., et al., “HIGAPS: A Large-Scale Integrated Combined Galileo/GPS Chipset 
for the Consumer Market,” Proc. European Navigation Conference (ENC-GNNS) 2004, 
Rotterdam, May 16–19, 2004. 
[12]	 Verdú, S., Multiuser Detection, Cambridge, U.K.: Cambridge University Press, 1998.
[13]	 Glennon, E. P., et al., “Post Correlation CWI and Cross Correlation Mitigation Us-
ing Delayed PIC,” Proc. of the 20th Int. Technical Meeting of the Satellite Division 
of the Institute of Navigation (ION-GNNS) 2007, Fort Worth, TX, September 25–28, 
pp. 236–245.
[14]	 Wang, D., et al., “Optimum Tracking Loop Design for the New L2 Civil Signal Based 
on ML Estimation,” Proc. 17th Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation (ION-GNNS) 2004, Long Beach, CA, September 21–24, 2004, 
pp. 474 – 485.
[15]	 Borio, D., L. Camoriano, and L. Lo Presti, “Impact of Acquisition Searching Strategy on 
the Detection and False Alarm Probabilities in a CDMA Receiver,” PLANS 2006, IEEE/
ION Position, Location and Navigation Symposium, San Diego, April 25–28, 2006, 
pp. 1100–1107.
[16]	 Lozow, J. B., “Analysis of Direct P(Y)-Code Acquisition,” NAVIGATION, Journal of The 
Institute of Navigation, Vol. 44, 1997, pp. 89–97.
[17]	 Niedermeier, H., et al., “Reproduction of User Motion and GNSS Signal Phase Signatures 
Using MEMS INS and a Pedestrian Navigation System for HS-GNSS Applications,” Proc. 
4th ESA Workshop on Satellite Navigation User Equipment Technologies, NAVITEC, 
Noordwijk, the Netherlands, December 10–12, 2008.
[18]	 Sıçramaz Ayaz, A., T. Pany, and B. Eissfeller, “Performance of Assisted Acquisition of the 
L2CL Code in a Multi-Frequency Software Receiver,” Proc. 20th Int. Technical Meeting of 
the Satellite Division of the Institute of Navigation (ION-GNNS) 2007, Fort Worth, TX, 
September 25–28, 2007, pp. 1830–1838.
[19]	 López-Risuen´   o, G., et al., “User Clock Impact On High Sensitivity GNSS Receivers,” Proc. 
European Navigation Conference (ENC-GNNS) 2008, Toulouse, April 22–25, 2008. 
[20]	 Borio, D., et al., “The Output SNR and Its Role in Quantifying GNSS Signal Acquisition 
Performance,” Proc. European Navigation Conference (ENC-GNNS) 2008, Toulouse, 
April 22–25, 2008.
[21]	 Zarrabizadeh, M. H., and E. S. Sousa, “A Differentially Coherent PN Code Acquisition 
Receiver for CDMA Systems,” IEEE Trans. Commun., Vol. 45, 1997, pp. 1456–1465.
[22]	 Park, S. H., et al., “A Novel GPS Initial Synchronization Scheme Using Decomposed Dif-
ferential Matched Filter,” Proc. Institute of Navigation National Technical Meeting (ION-
NTM) 2002, San Diego, CA, January 28–30, 2002, pp. 246–253.
[23]	 Ávila Rodríguez, J. Á., T. Pany, and B. Eissfeller, “A Theoretical Analysis of Acquisition 
Algorithms for Indoor Positioning,” Proc. 2nd ESA Workshop on Satellite Navigation 
User Equipment Technologies, NAVITEC, Noordwijk, the Netherlands, December 8–10, 
2004. 
[24]	 Schmid, A., and A. Neubauer, “Performance Evaluation of Differential Correlation for 
Single Shot Measurement Positioning,” Proc. 17th Int. Technical Meeting of the Satellite 
Division of the Institute of Navigation (ION-GNNS) 2004, Long Beach, CA, September 
21–24, 2004, pp. 1998–2009.
[25]	 Shanmugam, S. K., J. Nielsen, and G. Lachapelle, “Enhanced Differential Detection Scheme 
for Weak GPS Signal Acquisition,” Proc. 20th Int. Technical Meeting of the Satellite Divi­
sion of the Institute of Navigation (ION-GNNS) 2007, Fort Worth, TX, September 25–28, 
2007, pp. 189–202.
[26]	 SiRF Technology, Inc., http://www.sirf.com, 2008.

163
c h a p t e r  6
Sample Preprocessing
Sample preprocessing summarizes a number of steps before an actual correlation 
takes places. Interfering pulses are eliminated, filters might be applied to ensure an 
optimum tracking performance, and the noise floor usually needs to be determined. 
Analog-to-digital conversion also requires properly chosen quantization thresholds 
to optimally represent the analog signal with a limited number of bits.
6.1  ADC Quantization
The signal processing algorithms of Chapters 4 and 5, as well as the correlators 
presented in Chapter 7, are derived under the assumption of the signal samples 
being floating-point numbers. In practice, however, only a limited number of bits 
are available to represent signal samples. The statement can be rephrased by using 
stochastic terms: For analytical derivations, the signal samples are assumed to be 
real- or complex-valued random variables, but in practice the signal samples are 
integer-valued random variables. This approximation is only possible because virtu-
ally all statistics derive from correlation values of the received-signal samples with 
some reference signals, as has been described in Section 4.4. The law of large num-
bers applies and the correlator outputs are sufficiently well modeled as Gaussian 
random variables [1]. Nevertheless, the ADC reduces the overall system perfor-
mance, which is described by an effective loss in signal power called conversion or 
quantization loss.
Quantization errors are introduced, for example, in the work by Proakis and 
Manolakis and in that by van Dierendonck [2, 3]. Whereas Proakis and Manolakis 
consider quantization of Gaussian noise only, van Dierendonck makes use of a 
reference that considers quantization noise together with filtering losses plus signal-
processing losses [4]. An extensive treatment of quantization errors in the presence 
of interference is given in Spilker and Natali’s chapter [5]. A numerical simulation 
of bandlimiting, sampling, and quantization errors for GNSS signals has been done 
by Betz and investigates also the influence of the sampling rate [6, 7].
Quantization errors shall be revised here for a low-resolution (1– 4 bits) ADC 
and a high-resolution (e.g., 16-bits) signal processing. This setting is adopted for 
the software-radio approach described above. Without loss of generality, only real-
valued signals are considered.
6.1.1  Quantization Rule
Quantization occurring during analog-to-digital conversion of an analog sample sm 
maps the sample sm on a finite number of values q(sm)

164	
Sample Preprocessing
	
0
0
1
1
1
2
1
1
( )
B
B
B
s
s
q s
s
α
β
β
α
β
β
α
β
β
-
-
<
=
<

	
(6.1)
The mapping is completely defined by the thresholds βb (b = 0 … B) and by the 
output values αb (b = 0 … B – 1). For an example of a linear symmetric 2-bit ADC, 
the threshold and output values are given as
	
-
-
{ 
}
3
3
1
1
,
,
,
2
2
2
2
{
,
,0, ,
}
b
b
α
δ
δ
δ
δ
β
δ
δ
-
-
	
(6.2)
For a symmetric n-bit ADC, the threshold and output values are given as
	
0
2
1
0
2
2
0
2
b
b
B
b
B
b
B
b
B
b
B
α
δ
β
β
δ
β
-
+
=
<
= -
-
=
<
<
=
	
(6.3)
Here, δ represents the ADC input step width, which can be adjusted to opti-
mally fit the analog signal. The range ± D of analog input signal levels, which are 
covered uniformly by the ADC, is given by half the number of output levels multi-
plied by the input step width:
	
2
B
δ
D =
	
(6.4)
The ADC output values are internally represented as integer numbers. Usually 
the signal processing has no direct access to δ. If the signal processing works with 
two-complement integers with a number of bits larger than log2(2B) (for example, 
Chapter 9 describes algorithms working with 16 bits), it is reasonable to represent 
the values using a scheme such as
	
16
,
2
1
0
bit b
b
B
b
B
α
=
-
+
<
	
(6.5)
Using these definitions, the expected value of a function of a signal sample sm 
and its quantized value q(sm) is given as
	
1
1
0
(
, (
))
(
,
) (
)
b
b
B
b
S
b
s
f s
q s
f s
p s
ds
µ
µ
β
µ
µ
µ
µ
µ
β
α
+
-
=
=
=
	
(6.6)
where the expected value is computed with respect to the probability density func-
tion p(sm) of the sample amplitude.

6.1  ADC Quantization	
165
6.1.2  Matched Filter
Quantization errors are evaluated with respect to a certain criterion. In the case of 
navigation signal processing, the output SNR of a matched filter is a reasonable 
criterion, because the matched filter represents a sufficient statistic (see Section 4.4). 
Furthermore, the (absolute) postcorrelation SNR (described below) relates to ac-
quisition sensitivity or tracking performance. In a direct-spreading communication 
system, the bit error rate would be an adequate criterion [1]. 
To analyze quantization errors for navigation signal processing, the received-
signal samples are considered to be a vector of random variables S. The vector is 
modeled as the sum of two independent wide-sense stationary stochastic processes 
R (navigation signal) and N (noise),
	
a
=
+
S
R
N	
(6.7)
Note that mathematical symbols with capital letters denote random variables, 
whereas lower-case letters denote the realization of random variables. All signals 
are assumed to be real-valued. The signal process is assumed to be a Gaussian 
process. A Gaussian signal process is a reasonable assumption if, for example, the 
superposition of all transmitted GNSS signals is considered. On the other hand, it 
should be noted that the subsequent computations can also be carried out using 
other probability density functions. For example, CW interference is modeled as a 
(1 – r 2)–1/2 probability density function. The statistics of the Gaussian signal process 
are given as
	
0
(
)
(0)
1,
(
)
(
)
rr
rr
rr
rr
R
R R
R
R
R
R
µ
µ
ν
µ
ν
µ
ν
ν
µ
=
=
-
=
-
=
-
R
R
	
(6.8)
and the probability density function as
	
2
1
1
( )
exp
2
2
1
1
( ,
)
exp
(
)
2
2
det
1
(
)
(
)
1
rr
rr
r
p r
r
p r
r
r
r Q
r
Q
R
Q
R
µ
µ
µ
µ
ν
µ
ν
ν
π
π
µ
ν
µ
ν
-
=
-
=
-
÷
-
=
÷
-
	
(6.9)
The statistics of the (white) noise process are given as
	
,
0
N
N N
µ
µ
ν
µ ν
δ
=
=
N
N
	
(6.10)

166	
Sample Preprocessing
and the probability density function as
	
2
2
2
1
(
)
exp
2
2
1
(
,
)
exp
2
2
2
n
p n
n
n
p n
n
µ
µ
µ
ν
µ
ν
π
π
=
-
=
-
-
	
(6.11)
The signal power is given by α 2 and the corresponding C/N0 value as (see Sec-
tion A.2.2)
	
2
0
/
2
sf a
C N =
	
(6.12)
The matched filter output operating on the quantized signal samples is given 
as
	
1
(
)
(
)
L
T
t
q
q s
r
µ
µ
µ=
=
×
=
s
r
	
(6.13)
If the matched filter is considered to be a random variable, it is analogously 
written as
	
1
(
)
(
)
L
T
T
q
q S
R
µ
µ
µ=
=
×
=
S
R
	
(6.14)
The relative SNR of the matched filter is defined as the ratio of the squared expected 
value divided by the variance of the matched filter as
	
(
)
2
2
2
2
(
)
var
(
)
(
)
T
rel
T
T
q
T
SNR
T
q
q
×
=
=
×
-
×
R,N
R,N
R,N
R,N
R,N
S
R
S
R
S
R
	
(6.15)
The relative SNR is related to the bit error rate and to the variability in time of 
signal power estimates. The relative SNR stands in analogy to the definition used 
in [7].
The absolute SNR of the matched filter is defined as the ratio of the squared ex-
pected value divided by the variance of the matched filter in the noise-only case as
	
2
2
2
(
)
( (
)
)
(
)
T
abs
T
T
q
SNR
q
q
×
=
×
-
×
R,N
R,N
R,N
S
R
N
R
N
R
	
(6.16)
The absolute SNR relates to the noncentrality parameters determining the ac-
quisition sensitivity described in Section 5.4.

6.1  ADC Quantization	
167
Both SNR values are defined at baseband and no carrier is considered. Includ-
ing the carrier is not straightforward and, eventually, Monte Carlo methods must 
be used [7]. As a consequence, the relationship between the SNR values and the 
high-rate pseudorange variances can only be given for special cases. For example, 
if a complex-valued baseband input signal is considered and the I-channel contains 
the signal plus the noise and the Q-channel contains only the noise, then the vari-
ance of the estimated carrier phase is related to the absolute SNR.
6.1.3  Evaluation of Expected Values
To evaluate the SNRs as a function of the number of output values B and an ADC 
range D, a number of expected values need to be calculated, which is illustrated in 
the following examples.
The expected value of the matched filter output with respect to the noise and 
the stochastic signal is given as
	
1
0
0
1
1
(
)
(
)
(
)
L
T
L
L
q
q S
R
q S
R
R
R R
L R R
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
=
=
=
×
=
=
=
=
R,N
R,N
R
R
N
R
S
R


	
(6.17)
where the conditional expected value with respect to the noise of a quantized sam-
ple under the assumption of a constant signal value is defined as
	
1
1
0
(
)
(
)
(
) (
)
(
)
b
b
n
ar
B
b
b
n
ar
r
q S
r
q ar
N
q ar
n p n
dn
p n
dn
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
β
µ
µ
β
α
+
=-
-
-
=
=
-
=
=
+
=
+
=
N
N

	
(6.18)
an expression that can be evaluated analytically for Gaussian noise. The result-
ing expressions are, however, lengthy and do not provide more insight; they are, 
consequently, not given here. For non-Gaussian noise, the expression can also be 
evaluated with numerical integration. 
The conditional expected value with respect to noise can also be considered 
as a random variable (actually a function of the random variable Rm) and is then 
mathematically written as
	
1
1
0
(
)
(
)
(
)
b
b
aR
B
b
b
n
aR
R
q S
R
q aR
N
p n
dn
µ
µ
µ
β
µ
µ
µ
µ
µ
µ
µ
β
α
+ -
-
=
=
-
=
=
+
=
N
N

	
(6.19)

168	
Sample Preprocessing
Further analogous relationships between functions of random variables and 
their realizations are not explicitly given here.
A second-order expected value is defined as
	

1
1
2
2
2
0
(
)
(
)
b
b
ar
B
b
b
n
ar
r
q ar
N
p n
dn
µ
µ
µ
β
µ
µ
µ
µ
µ
β
α
+ -
-
=
=
-
=
+
=
N
	
(6.20)
In cases where no signal is present, the first- and second-order moments of the 
quantized noise are defined as
	

1
1
1
0
1
2
2
2
0
(
)
(
)
(
)
(
)
b
b
b
b
B
b
b
n
B
b
b
n
n
q N
p n
dn
n
q N
p n
dn
µ
µ
β
µ
µ
µ
µ
β
β
µ
µ
µ
µ
β
α
α
+
+
-
=
=
-
=
=
=
=
=
=
N
N

	
(6.21)
The first- and second-order moments are deterministic quantities.
The expected value of the matched filter is obtained using numerical integration 
of
	
0
0 0
0
0
(
)
( )
T
r
q
L
r r p r dr
=-
×
=
R,N
S
R

	
(6.22)
For a Gaussian amplitude distribution, this expression can be evaluated ana-
lytically. It can be obtained straightforwardly by using an analytical mathematic 
software package.
The expected value of the squared matched filter output is given as
	
=
+
+

(
)

2
,
1
2
2
,
1
1
,
1
2
2
0
0
( (
)
)
(
)
(
)
L
T
L
L
L
q
q S
R q S R
R R R R
R R
R R
R R
R R
R R
R R
R R
L R R
µ
µ
ν
ν
µ ν
µ
µ
ν
ν
µ
µ
µ ν
µ
µ ν
µ
µ
ν
ν
µ
ν
µ
ν
µ
ν
µ
ν
µ ν
µ ν
=
=
=
=
×
=
=
+
+
R,N
R,N
R
R
R
R
R
R
R
R
R
S
R




 


	
(6.23)
The last line uses a relationship for the fourth moment of correlated Gaussian 
random variables. Assuming the signal samples Rm and Rν are uncorrelated if |m – ν| 
> L′, an auxiliary index λ = m – ν is introduced; and thus,

6.1  ADC Quantization	
169
+
+
=
-
+
+
+
R
R
R
R
R
R
R

 





2
2
2
2
2
0
0
0
0
1
,
0
2
2
2
2
0
0
0
0
0
0
0
0
,
0
2
2
2
2
2
0
0
0
0
0
0
0
1
( (
)
)
(
)
(
)
(
)
2
T
L
L
L
L
L
q
L
L R R
L R R
R
R
R
R
R
R
R
R
L
L R R
L R R
L
R R
R R
R R
R R
L
L R R
L R R
L
R R
R R
R R
ν λ
ν
ν λ
ν
ν λ
ν
ν λ
ν
ν
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
+
+
+
+
=
=-
=-
=
×
=
-
+
=
-
+
+
+
R,N
R
R
R
R
R
R
R
R
R
R
S
R






 

L
	
(6.24)
The relative SNR is given as


2
2
0
0
2
2
2
2
2
2
2
0
0
0
0
0
0
0
0
0
1
2
2
0
0
2
2
2
2
0
0
0
0
0
0
0
1
(
)
2
2
rel
L
L
SNR
L
R R
L
L R R
L R R
L
R R
R R
R R
L
R R
L
R R
L R R
L R R
L
R R
R R
R R
λ
λ
λ
λ
λ
λ
λ
λ
=
=
=
=
-
+
+
+
-
=
-
+
+
R
R
R
R
R
R
R
r
R
R
R
R
R


 




 

	
(6.25)
The absolute SNR is similarly evaluated as
	
-
+
+
R
R
R
R

 





2
2
0
0
2
2
2
2
0
0
0
0
0
0
0
1
2
2
2
2
2
0
0
0
0
0
0
2
2
2
2
2
0
0
0
0
0
2
abs
L
L
R R
SNR
L n R
L n R
L
R R
n n
n R
L
R R
L
R R
L R R
Ln
R
n
L n R
λ
λ
λ
λ=
=
=
=
=
R
R
R
R
R
R
R




	
(6.26)
because the expected value of a quantized sample vanishes if no signal is present 
and the noise process is of zero mean.
6.1.4  Infinite Number of Bits
In cases of loss-less quantization (i.e., the quantized sample equals the input sam-
ple), the following identities hold:

170	
Sample Preprocessing
	
2
2
2
2
2
2
0
0
0
0
1
1
3
R R
a R
R
a
=
+
=
+


(
)

2
2
2
2
0
0
0
2
2
0
0
0
2
0
1
( )
1
rr
R
aR
R
a R
R R
a R
a
a
R R
R R
a R R
a R
n
µ
µ
µ
µ
λ
λ
λ
λ
=
=
+
=
=
=
=
=
=
R
R
R
R
R
R
R
R


 

	
(6.27)
Under this assumption, idealized SNR values can be obtained, which serve as 
comparison values for the quantized SNR values. The difference between idealized 
SNR values and quantized SNR values expressed in decibels gives the quantization 
loss.
The idealized relative SNR is given as
	
2 2
2
,
2
2
2
2
2
2
2
1
1
(1
3
)
4
( )
1
2
4
( )
rel  ideal
L
L
rr
rr
L a
La
SNR
L
a
La
La
R
a
a
R
λ
λ
λ
λ
=
=
=
=
+
-
+
+
+
	
(6.28)
and the idealized absolute SNR is given as
	
2
,
abs ideal
SNR
La
=
	
(6.29)
6.1.5  Numerical Evaluation
Considering a scenario derived from the settings in Table 10.13, the quantization 
loss for the absolute and relative SNR shall be evaluated in addition to the squared 
expected value of the matched filter. The simulation parameters are summarized 
in Table 6.1. The signal correlation function approximates a GPS C/A correlation 
function, sampled at 4 MHz.
Table 6.1  Quantization Loss Parameters
Parameter
Value
C/N0
40 dBHz, 50 dBHz
Number of bits
1– 4
Number of output values B
2–16
Signal correlation function
Rrr(λ) = 1 – λ / 4, 0 ≤ λ  4
Sample rate
4 MHz
Sample type
Real




174	
Sample Preprocessing
cause the total power Ptot is the sum of the signal power C and the noise power N 
and is written as
	
0
0
/
/
1
tot
N
C N
P
C
N
C N
N
N
B
B
=
+
=
+
=
+
÷	
(6.32)
where B is the dual-sided noise-equivalent bandwidth. C/N0 is the cumulative signal-
to-noise ratio accounting for all transmitters. As long as C/N0 << B, the total quan-
tized noise power can also be measured in the presence of one or more signals.
6.2  Noise-Floor Determination
Throughout this work, it is usually assumed that the noise variance is one for real-
valued noise and two for complex-valued noise. However, Section 6.1 showed that, 
after ADC, the noise power is generally different from one for real-valued noise. 
From the example above, we could see that for a 2-bit ADC and D = 2, the quan-
tized noise power is 3.53 for an optimal quantization of a real-valued input signal. 
The difference between the true and the assumed noise variance has some (minor) 
consequences on the signal processing, which are discussed here. Signal processing 
relies on correlation values and the subsequent evaluation of them. Two cases shall 
be considered. 
In the first case, only ratios of correlators are processed. This is done to obtain 
the code-phase, Doppler, or the carrier-phase estimates, as described in Section 4.3. 
In this case, the formulas can also be directly applied if the true noise power differs 
from one (or, respectively, two). The nominator and denominator scale identically 
and the effect of the different noise power cancels.
The second case relates to signal power estimation and determination of thresh-
olds for signal detection. For example, a single coherent integration, as described 
in Section 5.7.1, compares the squared correlator value against a threshold γ. For 
convenience, the respective equation (5.13) shall be repeated here
	
2
( , )
P τ ω
γ
>
	
(6.33)
For nonunity noise power, this equation has to be modified as
	

2
2
( , )
P
nµ
τ ω
γ
>
	
(6.34)
Other equations can be modified accordingly. For typical GNSS applications, 
the value of 
µ
2
n  is quite stable in time if the signals are broadcast in protected radio 
bands. Important exceptions only occur if (pulsed) interference is present. Pulsed 
interference shall be discussed in Section 6.3.
6.3  ADC Requirements for Pulse Blanking
The standard operation mode of a GNSS receiver implies that the noise floor is 
constant in time. For certain GNSS frequency bands (e.g., Galileo E5 or E6), this 

6.3  ADC Requirements for Pulse Blanking	
175
assumption is not valid and pulsed interference occurs. Pulsed interference might 
also occur because of the presence of pseudolite signals, which are described in Sec-
tion 10.6.2.
As outlined in Section 10.6.2, pulse blanking is an effective countermeasure to 
mitigate the effect of the pulsed interference, as long as the pulses are received only 
for a small fraction of the time. In the following, some requirements for the ADC 
are formulated to ensure that pulse blanking works properly:
The front-end gain before the ADC must not react on the pulse (or least only 
very slowly).
ADC resolution and thresholds must be suitable to allow identification of 
pulses via an energy detector.
Noise-floor determination algorithms must exclude periods where pulses are 
present. 
If these conditions are fulfilled, the algorithm of Section 10.6.2 can be applied.
6.3.1  Front-End Gain and Recovery Time
To properly handle pulsed interference by pulse blanking, it is required that the ana-
log part of the front end not be affected by a received pulse after the pulse ended. 
In other words, it is expected that the received samples during the pulse are useless, 
but as soon as the pulse vanishes, the front end should return to normal operation. 
The time the front end needs is called recovery time. 
Sometimes GNSS front ends include an automatic gain control (AGC) to con-
trol the ADC thresholds to obtain minimum quantization losses. AGCs are required 
because front ends might be used with different antennas, each having integrated 
LNAs with different gains. Furthermore, temperature variations of antenna/front-
end internal amplifiers and mixers might require adjusting the AGC. If pulse inter-
ference is present, the AGC shall not react on this interference (i.e., the AGC time 
constant should be much larger than the pulse duration). An optimal solution could 
be to control the AGC via software, and the AGC parameters are set using noise-
variance estimates obtained after pulse blanking.
6.3.2  Pulse Blanking
Pulse blanking replaces periods of the received signal contaminated with pulses by 
a vanishing signal
	
0
pulse period
sµ
µ
=
	
(6.35)
Replacing the signal samples by “0” ensures that correlation values are mini-
mally distorted. On the other hand, noise-floor determination can be corrupted if 
an estimation of 2
nµ is carried out using blanked samples. If it is not possible for the 
noise-floor estimation to be aware of periods with blanked samples, the method of 
pulse clipping
1.
2.
3.

176	
Sample Preprocessing
	
max
max
max
pulse period
sgn(
)
s
s
s
s
s
s
s
s
µ
µ
µ
µ
µ
µ
<
=
	
(6.36)
with 
2
max
µ
s
n
=
 or sample randomization
	
2
(0,
)
pulse period
s
n
n
N
n
µ
µ
µ
µ
µ
=
∼
	
(6.37)
can be applied, where either the samples are clipped if their magnitude exceeds a 
certain value, or the samples are replaced by simulated noise samples. Both methods 
further degrade the parameter estimates but allow continuous noise-floor estima-
tion. Pulse clipping is automatically applied if a 1-bit ADC is used.
6.3.3  ADC Resolution
The ADC resolution needs to be sufficiently large to allow usage of the energy de-
tector as described in Section 10.6.2. The variance of the energy detector output 
should not be affected by ADC saturation effects. Otherwise, saturation effects 
hinder the energy detector from detecting the presence of an interfering signal. Ob-
viously, the number of bits needs to be larger than one (an energy detector working 
with 1-bit samples always gives the same output). 
To further investigate the influence of saturation effects on an energy detector, 
the following setting is considered. Thermal noise samples nm with unity variance 
plus an interference signal arm are received. The interference signal samples have 
a variance of α 2 and its amplitude distribution is assumed to be Gaussian. The 
spectral characteristics of the interfering signal (and, therefore, its autocorrelation 
function) are left unspecified. 
An unbiased estimate of the received interference power is obtained by subtract-
ing the noise-only energy-detector output from the noise-plus-interference energy- 
detector output:
	
2
2
2
1
1
1
1
ˆ
(
)
(
)
L
L
a
q s
q n
L
L
µ
µ
µ
µ
=
=
=
-
	
(6.38)
In the case of an infinite number of bits, the expected value corresponds to the 
interference power, which is written as
	


2
2
2
2
0
0
,
ˆ
B
a
r
n
a
=
-
R N
R
	
(6.39)
The ratio between interference-power and noise-power spectral density J/N0 is 
defined equivalently to the C/N0 value as
	
2
0
/
2
s
a f
J N =
	
(6.40)
and a J/N0 estimate is obtained via


178	
Sample Preprocessing
Considering the proposed navigation system of Chapter 10, it was stated in 
Section 10.6.2.2 that the 1-ms energy-detector limit for pseudolite pulses was 
J/N0 = 53 dBHz, a value which is clearly in the linear region for all ADC types. 
Therefore, pulse detection for the proposed navigation system of Chapter 10 can 
even be performed with a 2-bit ADC.
6.4  Handling Colored Noise
In many receiver implementations, it happens that the noise-power spectral density 
after ADC is nonflat. Colored noise appears. This case may happen because of 
front-end filter imperfections, which show magnitude variations in the passband. 
Additionally, it may happen that noise, such as interfering signals, are broadcast on 
the navigation signal band, effectively increasing the noise-power spectral density 
in certain frequency regions. 
If a colored-noise signal is treated like a white-noise signal, performance deg-
radations are the consequence. The estimation filters do not weight the spectral 
regions properly. Spectral regions with more noise need to be downweighted and 
spectral regions with less noise need to be upweighted. An estimator designed under 
the white-noise assumption, however, treats all spectral regions equally.
Three possibilities exist in a multibit navigation receiver to process colored-
noise signals optimally. The first method (spectral whitening) consists of filtering 
the incoming signal such that the filtered signal has white noise. This implies a 
change of the reference signals. The second method consists of applying a filter on 
the generated reference signals and leaving the incoming signal untouched. The 
third method leaves the reference signals untouched and filters the incoming signal. 
Note that from now on a complex-valued signal representation will be used.
All methods can be directly derived from the discussion of the sufficient statistic 
t of Section 4.4, which is written according to (4.164) as
	
1
( )
(
)
b
t
Q
*
-
=
s
r q
s	
(6.44)
Here r(qb) is a vector of reference-signal samples generated at various correla-
tion points qb. The vector of received-signal samples is denoted as s and Q is the 
Hermitian covariance matrix of the noise given as
	
,
0,
0,
2
N N
N N
N N
Q
µ
υ
µ
υ
µ
υ
µ υ
=
=
=
N
N
N
	
(6.45)
Assuming a wide-sense stationary noise, the covariance can be written as 
	
,
(
)
Q
Q
µ υ
µ
υ
=
-
	
(6.46)
6.4.1  Spectral Whitening
The method of spectral whitening filters the incoming signal s and the reference 
signal r(qb) identically such that the filtered incoming signal s′ is of white noise. 

6.4  Handling Colored Noise	
179
The magnitude of the filter’s frequency response is determined by the colored-noise 
power spectral density, whereas the phase of the frequency response can be chosen 
arbitrarily. 
Spectral whitening is written mathematically as
	
1 2
1 2
1 2
1 2
(
)
(
)
(
)
(
)
b
b
b
b
Q
Q
Q
Q
-
*
-
*
= F
F
=
= F
F
=
s
s
s
s
r q
r q
r q
r q
	
(6.47)
where F is an arbitrary unitary matrix F * F = 1, yielding
	
( )
(
)
b
t
*
=
s
r q
s 	
(6.48)
The filter FQ–1/2 affects the signal and the noise part of the received-signal 
samples in the same way. Because the received-signal part is changed, the reference 
samples have to be adapted properly. The noise part Nm′ of the filtered samples is 
white because
	
1 2
1 2
1 2
1 2
1 2
1 2
2
2
Q
Q
Q
Q
Q
Q Q
*
-
*
-
*
-
*
-
*
-
*
-
*
*
= F
F
= F
F
= F
F =
FF =
N
N
N
N N
NN
NN
1
	
(6.49)
The filter operation 
	
1 2
1 2
,
(
)
(
)
Q
s
Q
s
µ
ν
λ ν
µ
λ
λ
ν
-
-
= F
=
F
-
-
s
s
	
(6.50)
can actually be realized by any digital filter. The Q–1/2 term defines the magnitude 
response of the filter and F defines the phase response. Because F can be chosen 
arbitrarily and magnitude variations are usually small, a linear-phase finite impulse 
response (FIR) filter as described in the book by Diniz, da Silva, and Netto [8] could 
be an efficient way for implementation.
6.4.2  Modified Reference Signals
If colored noise is present, the reference signals can be modified to properly account 
for the noise correlations. This method was described in Section 4.4.4.
The modified reference signal is given by
	
1
(
)
(
)
b
b
Q-
=
r q
r q
	
(6.51)
and the sufficient statistic is obtained via simple correlation of the received-signal 
samples with the modified reference signal
	
( )
(
)
b
t
*
=
s
r q
s	
(6.52)

180	
Sample Preprocessing
The received signal itself remains unmodified and contains colored noise.
6.4.3  Overcompensation of the Incoming Signal
The method of overcompensation consists of applying a filter on the received-signal 
samples and leaving the reference signals unmodified. It is written as
	
1
Q-
=
s
s	
(6.53)
The sufficient statistic is given as
	
( )
(
)
b
t
*
=
s
r q
s 	
(6.54)
The noise of the modified signal has as covariance the inverse matrix of the 
unmodified signal; that is,
	
1
1
1
1
1
1
1
2
2
Q
Q
Q
Q
Q
QQ
Q
*
-
*
-
-
*
-
-
-
-
=
=
=
=
N
N
N
N N
NN
NN
	
(6.55)
Effectively, the noise-power spectral density of the modified signal is the inverse 
of the power spectral density of the unmodified signal. The filter compensates for 
the nonwhite noise-power spectral density plus for the incorrectly chosen reference 
signal. Both effects add up and the filtered signal can be thought of as “overcom-
pensated.”
6.4.4  Implementation Issues
The presented algorithms are typically implemented after ADC. If the signal sam-
ples are represented by 16-bit values (see Chapter 9), the algorithms are expected 
to have negligible finite precision effects. Implementing a digital filter operating on 
the incoming signals is of small computational costs; a digital filter operating on all 
generated reference signals would need more computational power. 
Two cases shall be considered: timely constant colored noise and timely vari-
able colored noise. In the first case, the method of spectral whitening seems to be 
most applicable because the phase of the filter frequency response can be chosen 
freely (thereby allowing a linear-phase FIR filter) and the resulting signal is of white 
noise. White noise is favorable for spectral monitoring issues or for visualization 
purposes. If the power spectral density varies with time, the method of overcom-
pensation could be used because this method requires only modification of the 
incoming signal. An important aspect of this method is, however, the requirement 
of determination of the timely variable spectrum.
6.5  Sub-Nyquist Sampling
The presented signal-processing algorithms have all been formulated in discrete time, 
based on a finite sample rate fs. The deterministic part of the signal, the reference sig-
nals, and the sin/cos signals were all based on continuous time signals sampled with 


182	
Sample Preprocessing
fs = 2B —Nyquist sampling: Signal and noise are sampled with the Nyquist 
rate. Ideal case, no losses, u = 1.
fs < 2B —Sub-Nyquist sampling: Aliasing of noise occurs, the signal autocor-
relation function is not affected by the sub-Nyquist sampling, u = 2B/fs.
When oversampling is used, the signal processing includes spectral regions, 
which are not covered by the navigation signal. These regions are ignored when 
correlating the received-signal samples with navigation signal replicas. However, 
oversampling can be quite useful because the high working sample rate allows small 
shifts of replica signals (e.g., early or late signals) with respect to a reference signal 
(e.g., the punctual signal). Typically it is much easier to shift a signal than to do a full 
regeneration of the signals (e.g., via resampling of Section 9.3). In fact, in hardware 
receivers, high oversampling rates are used to achieve small correlator spacings. 
Nyquist sampling represents a kind of ideal sampling; the signal is optimally 
captured, the noise after ADC is white, and no noise-aliasing losses occur. A high-
performance software receiver should work with Nyquist sample rates. Usually, fi-
nite analog-filter fall-off steepness effects can be ignored. The sample rate is (twice) 
the 3-dB bandwidth.
Sub-Nyquist sampling is the method of choice if the computational load is to 
be reduced, if the signal power is sufficiently high to cope with noise-aliasing losses, 
and if there is no need to shift reference signals. See the work by Pany and Eissfeller 
for further discussion [9]. Because of noise aliasing, the effective C/N0 value is re-
duced by the undersampling factor u:
	
0
0
1
/
/
C N
C N
u
	
(6.56)
An important restriction for choosing the sample rate occurs if real-valued 
signals are used. In this case, the replica signal correlates with negative frequency 
components of the received signal. Those correlation values are required to average 
to zero during the correlation process, that is, (7.12) shall hold. This implies that 
after ADC the aliased doubled center frequency should be larger than 0 (see also 
Chapter 7).
References
  [1]	 Amoroso, F., and Bricker, J. L., “Performance of the Adaptive A/D Converter in Com-
bined CW and Gaussian Interference,” IEEE Trans. Commun., Vol. 34, No. 3, 1986, 
pp. 209–213.
  [2] 	 Proakis, J. G. and D. G. Manolakis, Digital Signal Processing, Principles, Algorithms, and 
Applications, 4th ed., Upper Saddle River, NJ: Prentice-Hall, 2007.
  [3]	 van Dierendonck, A. J., “GPS Receivers,” in Global Positioning System: Theory and Ap-
plications, Vol. I, pp. 329–407, Parkinson, B. W., and J. J. Spilker, (eds.), Washington D.C.: 
American Institute of Aeronautics and Astronautics Inc., 1996.
  [4]	 Chang, H., “Presampling Filtering, Sampling and Quantization Effects on Digital Matched Fil-
ter Performance,” Proc. Int. Telemetering Conference, San Diego, CA, 1982, pp. 889–915.
  [5]	 Spilker, J. J. Jr. and Natali, F. D., “Interference Effects and Mitigation Techniques,” in 
Global Positioning System: Theory and Applications, Vol. I, pp. 717–771, Parkinson, B. W., 
and J. J. Spilker, (eds.), Washington, D.C.: American Institute of Aeronautics and Astro-
nautics Inc., 1996.
•
•

6.5  Sub-Nyquist Sampling	
183
  [6]	 Betz, J. W., “Bandlimiting, Sampling, and Quantization for Modernized Spreading Mod-
ulations in White Noise,” Proc. Institute of Navigation National Technical Meeting 
(ION-NTM) 2008, San Diego, CA, January 28–30, 2008.
  [7]	 Betz, J. W. and Shnidman, N. R., “Receiver Processing Losses with Bandlimiting and One-
Bit Sampling,” Proc. 20th Int. Technical Meeting of the Satellite Division of the Institute of 
Navigation (ION-GNSS) 2007, Fort Worth, TX, September 25–28, 2007, pp. 1244 –1256.
  [8]	 Diniz, P. S. R., E. A. B. da Silva, and S. L. Netto, Digital Signal Processing, System Analysis 
and Design, Cambridge, U.K.: Cambridge University Press, 2002.
  [9]	 Pany, T., and B. Eissfeller, “Code and Phase Tracking of Generic PRN Signals with Sub-
Nyquist Sample Rates,” NAVIGATION, Journal of The Institute of Navigation, Vol. 51, 
No. 2, 2004, pp. 143–159.

185
c h a p t e r  7
Correlators
In Chapter 4, optimum parameter-estimation techniques were discussed and al-
gorithms for MVUEs for the code phase, Doppler, signal power, and carrier 
phase were developed. The estimated parameters are derived from correlating the 
received-signal samples with different reference signals (waveforms), which are the 
received navigation signal at baseband c(t) and its first derivative. This is only one 
possibility to choose the waveforms and ways to optimize the reference signals for 
multipath mitigation, for example, are shown in Section 8.2. Overall, a software 
receiver is very flexible with regards to signal correlation and the resulting tracking 
scheme shall be called waveform-based tracking.
This chapter introduces the waveform-based tracking scheme and compares it 
to the (hardware receiver oriented) correlator-based tracking scheme. Four differ-
ent classes of waveforms are introduced that are used for carrier-phase, code-phase, 
and frequency estimation as well as for signal-quality monitoring. Difference cor-
relators are analyzed that are the basis for the highly stable carrier-phase tracking 
scheme of Chapter 10. Also, codeless tracking techniques [for the encrypted GPS L2 
P(Y) signal] are discussed, along with a description of how to adapt discriminator 
noise formulas for the case of colored noise.
7.1  Correlator and Waveform-Based Tracking
The correlator-based tracking scheme relies on the fact that a hardware receiver 
has only limited signal-generation capabilities but can work at a high sample rate 
and allows a high level of parallelization. Typically, a simple hardware GNSS re-
ceiver is only able to generate a carrier and binary PRN-code sequence. The product 
of both approximates the received signal r(t). The PRN-code sequence is shifted 
several times by an integer number of samples and the shifted PRN-code replicas 
are correlated with the received signal at baseband (see Figure 7.1). The result-
ing correlators C0, …, Cb have different sample (or code-phase) shift values and 
are termed “prompt,” “early,” “late” (or “very early/late”). For basic tracking, 
three correlators are required (prompt, early, and late), but depending on the used 
multipath-mitigation scheme and on the signal-modulation scheme, significantly 
more correlators might be required. 
For a software receiver that uses the multibit-correlation approach discussed in 
Section 9.4, it is reasonable to exploit this increased amplitude resolution to allow 
correlation with more complex reference signals instead of correlation only with 
the PRN-code sequence. The reference signals can then be optimized for certain 
criteria, as will be discussed in Section 8.2.
In the rest of this chapter, different correlators will be considered that corre-
late the received-signal samples with different classes (P, D, F, and W) of reference 


7.2  Generic Correlator 
187
7.2  Generic Correlator
The analysis of a generic correlator is based on the assumption of Section 1.8. The 
sequence of received-signal samples Sm is the sum of a deterministic signal rm plus 
noise Nm given by
	
1,
,
S
r
N
L
µ
µ
µ
µ
=
+
=
…
	
(7.1)
The deterministic part is assumed to be of the form
	
1
(
)exp
2 s
L
r
ac t
i
t
f
µ
µ
µ
τ
ω
ϕ
+
=
-
-
- ÷
÷
	
(7.2)
where a is the signal amplitude, w is the angular IF plus Doppler in radians per sec-
ond, j is the carrier-phase offset in radians, and t is the code delay in seconds. The 
signal is sampled at times tm
	
0
0
L
coh
s
t
t
t
T
f
µ
µ
=
=
=
	
(7.3)
where fs is the sample rate in samples per second. The function c(t) represents the 
received and filtered navigation signal at baseband and is allowed to be complex-
valued. The stochastic part Nm shall be left unspecified now, but it typically includes 
thermal and quantization noise. 
Furthermore, 
	
1
2 s
L
t
t
f
µ
µ
+
=
-
	
(7.4)
is defined for a more compact notation.
The received signal is characterized by four fundamental signal parameters: a, 
t, w, and j. Those parameters are assumed constant during the integration period 
Tcoh. If the broadcast GNSS signal contains a navigation data message, the message 
bit/symbol is assumed constant during the integration period and can be included 
in the carrier phase j.
The received samples are correlated with an internally generated sequence of 
samples given by
	
,
0
0
0
(
)exp{ (
)}
rec
rec
r
c
t
i
t
µ
µ
µ
τ
ω
ϕ
=
-
-
	
(7.5)
For the different classes of correlators (P, D, F, and W), the internal sequence is 
based on a different baseband signal crec. We will later substitute different signals, 
including the PRN code itself and early-late replicas, among others. Its fundamental 
parameters are denoted by a subscript “0.” Those parameters are typically near the 
true signal parameters. They define the correlation point and should not be con-
fused with the estimated signal parameters. Especially in the case of a multicorrela-
tor, the estimated parameters and the correlation point differ significantly.
The output of the correlator C is defined as
	
,
,
,
1
1
1
(
)
( )
(
)
L
L
L
rec
rec
rec
sig
noise
C S
r
S
r
r
r
N
C
r
C
N
µ
µ
µ
µ µ
µ
µ
µ
µ
µ
µ
µ
=
=
=
=
=
+
=
+
	
(7.6)

188 
Correlators
and is split into a deterministic signal part Csig and a stochastic noise part Cnoise. 
The integration (summation) involves a number of L samples corresponding to a 
coherent integration time of Tcoh = L/fs.
Within this section, all expected values are calculated with respect to noise; that 
is,
	
N
…
…
	
(7.7)
If the input signal has only a real component, we write the correlator output 
as 
	
1
(Re{
})
(
)
(
)
2
C
S
C S
C S
µ
µ
µ
=
+
	
(7.8)
Where Sµ are complex-conjugated-signal samples. Note that expressions in-
volving complex-conjugated-signal samples are not implemented in the receiver. 
They serve only to obtain a more compact notation. 
We start with the assumption of bandlimited white noise and that the Nyquist-
sampling criterion is fulfilled for the sample rate fs. It expresses itself for complex-
valued signals as
	
sf
B
=
	
(7.9)
and for real-valued signals as
	
2 sf
B
=
	
(7.10)
where B is the dual-sided white-noise bandwidth. In Section 7.6, the results will be 
extended for the case of colored noise. In both cases (real or complex input signal), 
the correlator output is a complex-valued random variable. Its expected value and its 
(co)variance are calculated in Section 7.2.1.
7.2.1  Expected Value
The expected value for the correlator output is the sum of the deterministic con-
tribution and the noise contribution. The latter contribution vanishes, as will be 
demonstrated. 
The deterministic part evaluates to (see Appendix A.4.4)
	
,
0
0
0
1
1
,
0
0
0
,
0
0
0
( )
(
)
(
)exp{ (
)
(
)}
(
)exp{
(
)} (
)
(
)exp{
(
)} (
)
rec
rec
L
L
sig
rec
rec
c c
coh s
c c
C
r
r
r
a
c t
c
t
i
t
i
t
aLR
i
aT
f R
i
µ
µ µ
µ
µ
µ
µ
µ
µ
τ
τ
ω
ϕ
ω
ϕ
τ
τ
ϕ
ϕ
κ ω
ω
τ
τ
ϕ
ϕ
κ ω
ω
=
=
=
=
-
-
-
+
-
=
-
-
+
+
=
-
-
+
+
	
(7.11)
When a real-valued input signal is considered, it is reasonable to assume that its 
center frequency is far from 0 MHz. The replica signal frequency is similar to the 
received-signal center frequency and |mod(w + w0, 2p fs)| >> 0 should be fulfilled, 
yielding
	
,
0
0
0
( )
(
)exp{
(
)} (
)
0
rec
sig
s
coh
c c
C
r
af T
R
i
µ
τ
τ
ϕ
ϕ
κ ω
ω
-
-
+
+
	
(7.12)

7.2  Generic Correlator 
189
For complex signals (whose center frequency might be around 0 MHz) the 
above equation does not hold.
Repeating the same derivation with the complex-conjugate received signal 
gives
	
,
0
0
0
1
1
,
0
0
0
(
)
(
)
(
)exp{
(
)
(
)}
(
)exp{ (
)} (
)
rec
sig
L
L
rec
rec
coh s
c c
C
r
r
r
a
c t
c
t
i
t
i
t
aT
f R
i
µ
µ µ
µ
µ
µ
µ
µ
µ
τ
τ
ω
ϕ
ω
ϕ
τ
τ
ϕ
ϕ
κ ω
ω
=
=
=
=
=
-
-
-
-
+
-
-
-
-
	
(7.13)
For a real-valued input signal, the correlation results for the normal and the 
complex-conjugate input signal must be summed. Because correlation is linear, we 
obtain under the assumption |mod(w + w0, 2p fs)| >> 0
	
,
0
0
0
1
(Re{
})
( )
( )
2
(
)exp{ (
)} (
)
2
rec
sig
sig
sig
coh s
c c
C
r
C
r
C
r
a T
f R
i
µ
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
=
+
=
-
-
-
	
(7.14)
We assume that the noise samples are unbiased. Consequently,
	
(
)
(
)
0
noise
noise
C
N
C
N
µ
µ
=
=
	
(7.15)
To summarize, the expected value for a complex input signal is
	
,
0
0
0
,
0
0
0
(
)
(
)exp{
(
)} (
)
(
)
(
)exp{ (
)} (
)
rec
rec
coh s
c c
coh s
c c
C S
aT
f R
i
C S
aT
f R
i
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
τ
τ
ϕ
ϕ
κ ω
ω
-
-
+
+
-
-
-
	
(7.16)
If a real-valued input signal is considered and |mod(w + w0, 2p fs)| >> 0 then the 
expected value is
	
,
0
0
0
(
)
(Re{
})
exp{ (
)} (
)
2
rec
coh s
c c
aT
f R
C
S
i
µ
τ
τ
ϕ
ϕ
κ ω
ω
-
-
-
	
(7.17)
because k(w) typically vanishes for large frequencies (see Appendix A.4.4).
7.2.2  Covariance
To evaluate the covariance, assume two different correlators that are distinguished 
by an index “a” and the index “b.” Both correlators are associated with different 
parameters and internal signals, specifically

190 
Correlators
	
0
0
0
0
0
0
(
)
,
,
,
(
)
,
,
,
a
a
a
a
a
rec
b
b
b
b
b
rec
C
S
c
C
S
c
µ
µ
τ
ω
ϕ
τ
ω
ϕ


	
(7.18)
Both work with the same received signal samples.
The covariance is defined as
	
cov
(
),
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
a
b
a
a
b
b
a
a
b
b
a
b
C
S
C
S
C
S
C
S
C
S
C
S
C
r
N
C
r
N
C
r
N
C
r
N
C
N C
N
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
=
-
-
=
+
-
+
+
-
+
=
	
(7.19)
because the signal contribution cancels and the expected value of the noise contri-
bution vanishes. Thus
	
{
}
0
0
0
0
0
0
,
1
0
0
0
0
0
0
1
0
0
0
0
0
,
cov
(
),
(
)
(
)exp{ (
)}
(
)exp (
)
2
(
)
(
)exp{
(
)
(
)}
2
(
)exp{ (
)} (
a
b
rec
rec
a
b
L
a
a
a
a
b
b
b
b
rec
rec
L
a
a
b
b
b
a
b
a
rec
rec
a
b
a
b
b
s
coh
c
c
C
S
C
S
N c
t
i
t
N c
t
i
t
c
t
c
t
it
i
f T
R
i
µ
µ
µ
µ
µ
υ
υ
υ
µ υ
µ
µ
µ
µ
τ
ω
ϕ
τ
ω
ϕ
τ
τ
ω
ω
ϕ
ϕ
τ
τ
ϕ
ϕ
κ ω
=
=
=
=
-
-
-
-
=
-
-
-
-
-
-
-
0)
a
ω
-
	
(7.20)
because, for the following, we assume that (1.16) and (1.28) hold. The covariance 
for the complex-conjugated input signal is given similarly as
	
( )
( )
(
)
( )
(
)
( )
( )
(
)
(
)
(
)
(
)
(
)
{
}
(
)
(
)
{
}
(
)
(
)
(
) (
)
{
}
( )
( )
0
0
0
0
0
0
,
1
0
0
0
0
0
0
1
cov
,
exp
exp
2
exp
cov
,
a
b
a
a
b
b
a
b
L
a
a
a
a
b
b
b
b
rec
rec
L
a
a
b
b
b
a
b
a
rec
rec
a
b
C
S
C
S
C
S
C
S
C
S
C
S
C
N
C
N
N c
t
i
t
N c
t
i
t
c
t
c
t
it
i
C
S
C
S
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
υ
υ
υ
µ υ
µ
µ
µ
µ
µ
µ
τ
ω
ϕ
τ
ω
ϕ
τ
τ
ω
ω
ϕ
ϕ
=
=
=
-
-
=
=
-
-
-
-
=
-
-
-
-
-
=
	
(7.21)

7.3  Correlator Types with Illustration 
191
For mixed terms, we obtain
	
(
)(
)
(
)
(
)
{
}
(
)
(
)
{
}
(
)
(
)
(
) (
)
{
}
0
0
0
0
0
0
,
1
0
0
0
0
0
0
1
cov
(
),
(
)
(
)
(
)
(
)
(
)
(
)
(
)
exp
exp
2
exp
0
a
b
a
a
b
b
a
b
L
a
a
a
a
b
b
b
b
rec
rec
L
a
a
b
b
b
a
b
a
rec
rec
C
S
C
S
C
S
C
S
C
S
C
S
C
N C
N
N c
t
i
t
N c
t
i
t
c
t
c
t
it
i
N N
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
υ
υ
υ
µ υ
µ
µ
µ
µ
υ
µ
τ
ω
ϕ
τ
ω
ϕ
τ
τ
ω
ω
ϕ
ϕ
=
=
=
-
-
=
=
-
-
-
-
=
-
-
-
-
-
=
	
(7.22)
as the expected value of these products of the complex-valued Gaussian noise is 
zero:
	
0
N N
N N
µ
υ
µ
υ
=
=
	
(7.23)
For real-valued input signals, we obtain
	
0
0
0
0
0
0
,
1
cov
(Re{
}),
(Re{
})
cov
(
),
(
)
4
1 cov
(
),
(
)
2
(
)exp{ (
)} (
)
a
b
rec
rec
a
b
a
b
a
b
a
b
a
b
b
a
s
coh
c
c
C
S
C
S
C
S
S
C
S
S
C
S
C
S
f T
R
i
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
=
+
+
=
-
-
-
     	
	
	
	
(7.24)
7.2.3  Variance
The variance of the correlator output is a special case of the covariance assuming 
identical parameters for the a’ and b’ case. 
For complex input signals, the equation
	
,
var
(
)
2
(0)
rec
rec
s
coh
c
c
C S
f T
R
µ
=
	
(7.25)
holds and for real-valued input signals
	
,
var
(Re{
})
(0)
rec
rec
s
coh
c
c
C
S
f T
R
µ
=
	
(7.26)
7.3  Correlator Types with Illustration
Depending on the choice of the internally generated reference signal, many differ-
ent types of correlators can be obtained. They are discussed in Section 7.3.1. For 
simplicity, the case of real-valued received signal samples is discussed.

192 
Correlators
7.3.1  P-Correlator
P-correlators are based on a transmitted-like reference signal and are used to deter-
mine carrier-phase tracking errors to extract navigation data symbols/bits; they are 
used in the acquisition process (perhaps using FFT techniques for correlation). A 
P-correlator reference signal cP(t) has to fulfill the requirement
	
,
(0)
0
P
c c
R
	
(7.27)
There exist different possibilities for the choice of the cP(t). If, for the P-correla-
tor CP, we use as internally generated signal the received signal at baseband itself, 
	
( )
( )
P
c
t
c t
=
	
(7.28)
then the CRLB (assuming no multipath is present) for the carrier-phase discrimina-
tor will be reached and optimal performance for navigation bit/symbol decoding 
and acquisition will be reached as well.
For this setting (7.28), the expected value and variance evaluate to
	
0
,
0
0
0
(Re{
})
2
/
(
)exp{ (
)} (
)
var
(Re{
})
2
P
coh
c c
P
coh
C
S
C N BT
R
i
C
S
BT
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
=
-
-
-
=
	
(7.29)
Here, (A.76) has been used to express the amplitude as a function of C/N0 and the 
dual-sided signal bandwidth B. The covariance of two P-correlators using different 
signal parameters can be easily calculated using (7.24). If both correlators work with 
the same signal, carrier phase, and angular frequency, this expression takes the form
	
(
)
(
)
(
)
,
0
0
0
0
cov
Re{
};
,
Re{
};
2
P
P
a
a
b
b
a
b
coh
c
c
P
P
C
S
C
S
BT
R
µ
µ
τ
τ
τ
τ
=
-
	
(7.30)
The P-correlator values are, in general, highly correlated for similar code-phase 
offsets. If both correlators are based on different angular frequencies w 0
a and w 0
b, 
they are uncorrelated if k (w 0
a – w 0
b) = 0.
In practice, for different reasons, it might be convenient to choose a slightly 
different form of cP(t) from c(t). For the case of GNSS signals, and if simplicity is 
required, the infinite-bandwidth representation of the PRN code is a good choice, 
because for most signals it can be represented by a 1-bit amplitude resolution. For 
carrier-phase multipath mitigation, a linear combination of the form “2P-E-L” of 
the infinite-bandwidth baseband representation of c(t) may prove advantageous [1]. 
Assuming, however, an arbitrary waveform cP(t) for the P-correlator, the stochastic 
properties are summarized as
	
0
0
0
0
0
0
0
0
(
)
(
)
(
)
(
)
{
} (
)
0
,
0
0
0
,
,
(Re{
})
2
/
(
)exp{ (
)} (
)
var
(Re{
})
2
(0)
cov
Re{
};
,
Re{
};
2
exp
P
P
P
P
P
P
coh
c c
P
coh
c
c
a
a
b
b
P
P
a
b
a
b
b
a
coh
c
c
C
S
C N BT
R
i
C
S
BT
R
C
S
C
S
BT
R
i
µ
µ
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
τ
τ
τ
τ
ϕ
ϕ
κ ω
ω
=
-
-
-
=
=
-
-
-
	
(7.31)

7.3  Correlator Types with Illustration 
193
7.3.2  F-Correlator
The F-correlator is used to determine Doppler-frequency tracking errors, a task usu-
ally performed in many GNSS receivers by differencing two carrier-phase estimates 
in time [2]. Using a dedicated correlator for this estimation can be advantageous be-
cause if Doppler frequency is estimated in a single step, the CRLB for the estimated 
frequency is achieved and the pull-in region is increased [3]. Furthermore, the com-
putation of the F-correlator does not require significant extra computational load 
in a software receiver because the linear function multiplying the reference signal in 
(7.32) can be approximated by a piecewise constant function. The correlation loop 
of Section 9.4 can be split into several smaller loops, thereby allowing computation 
of the P- and F-correlator in one turn.
The F-correlator derives from the LSQ Doppler estimation strategy of Section 4.3 
and the reference signal is given by a P-correlator reference signal multiplied with time:
	
( )
( )
2
coh
F
P
T
c t
t
c
t
=
-
÷
	
(7.32)
The resulting F-correlator reference signal must still allow the separation of 
code and carrier correlation, as described in Section 1.8.5.
The expected value of the F-correlator is
	
0
0
,
0
0
0
0
0
,
0
0
0
(Re{
})
(Re{
})
2
/
(
)exp{ (
)}
(
)
2
/
(
)exp{ (
)}
(
)
P
P
F
P
coh
c c
coh
c c
C
S
i
C
S
C N BT
R
i
i
C N BT
R
i
i
µ
µ
ω
τ
τ
ϕ
ϕ
κ ω
ω
ω
τ
τ
ϕ
ϕ
κ ω
ω
=
-
÷
=
-
-
-
-
÷
= -
-
-
-
	 (7.33)
and the covariance
	
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
{
}
(
)
0
0
0
0
0
0
0
0
0
0
,
0
0
0
0
0
0
0
0
cov
Re{
};
,
Re{
};
cov
Re{
};
,
Re{
};
cov
Re{
};
,
Re{
};
2
exp
P
P
a
b
F
F
a
b
P
P
a
b
a
b
P
P
a
b
a
b
a
b
b
a
coh
c
c
a
b
C
S
C
S
i
C
S
i
C
S
C
S
C
S
BT
R
i
µ
µ
µ
µ
µ
µ
ω
ω
ω
ω
ω
ω
ω
ω
ω
ω
τ
τ
ϕ
ϕ
κ ω
ω
ω
ω
=
=
-
-
÷
÷
= -
= -
-
-
-
÷
	
(7.34)
Because of the discussion of Section 1.8.5,
	
(
)
0
0
,
0
,
2
,
var
(Re{
};
)
2
(0)
( )
2
(0)
(0)
1
2
(0)
12
P
P
P
P
P
P
F
coh
c
c
coh
c
c
coh
c
c
coh
freq
C
S
BT
R
i
i
BT
R
BT
R
T
µ
ω
ω
κ ω
ω
ω
κ
χ
=
=
÷
÷
÷
=
-
=
	
(7.35)

194 
Correlators
7.3.3  D-Correlator
The D-correlator is used to determine the code-phase tracking error. In the most 
simple case, it is an early-minus-late replica of the infinite-bandwidth baseband 
representation of c(t). For code multipath mitigation, a double-delta linear combi-
nation or a shaping correlator is known to be useful [1]. 
Generally, we require for the D-correlator reference signal cD(t)
	
τ
τ
τ
=
<
,
,
,
,
(0)
0
( )
(0)
for
and
(0)
0
D
P
D
D
D
c
c
c c
c c
c c
R
R
R
l
R
	
(7.36)
Here, cP(t) denotes the P-correlator reference signal and the c(t) received 
signal. The symbol l is the required size of the code-phase linearity region.
If we choose for the D-correlator CD as an internally generated signal the first 
derivative of the received signal at baseband:
	
( )
( )
rec
c
t
c t
=
	
(7.37)
then the CRLB is obtained if no multipath signal is present and
	
(
)
(
)
(
)
(
)
{
} (
)
0
,
0
0
0
,
0
0
,
0
0
0
0
0
0
(Re{
})
2
/
(
)exp{ (
)} (
)
var
(Re{
})
2
(0)
cov
Re{
};
,
Re{
};
2
exp
D
coh
c c
D
coh
c c
a
a
b
b
D
D
a
b
a
b
b
a
coh
c c
C
S
C N BT
R
i
C
S
BT
R
C
S
C
S
BT
R
i
µ
µ
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
τ
τ
τ
τ
ϕ
ϕ
κ ω
ω
=
-
-
-
= -
= -
-
-
-
	
(7.38)
For an arbitrary choice of the D-correlator reference signal, (7.17) and (7.24) 
are used to obtain stochastic correlator properties.
7.3.4  W-Correlator
The main purpose of the W-correlator is its use in CDMA signal-quality monitoring 
or multipath mitigation. If it is used within a multicorrelator, it gives uncorrelated 
measurements of the received-signal chip form. It stands in analogy to the so-called 
Vision correlator [4].
The reference signal for the W-correlator is defined as the PRN-code sequence 
of the received signal convoluted with an approximation of Dirac’s delta function. 
Let us assume that the received-CDMA signal at baseband takes the form
	
1
( )
(
)
for
0
t<
PRN
N
k
c
PRN
c
k
c t
h m tf
k
N
f
=
=
-
	
(7.39)
where NPRN denotes the length of the PRN code and fc represents the code rate in 
chip per second. The function m defines the used-modulation scheme [e.g., BPSK or 

7.3  Correlator Types with Illustration 
195
(M)BOC for GNSS signals], including filtering, and hk is the PRN code spreading 
sequence. For example, if an infinite-bandwidth BPSK signal is considered, m takes 
the form
	
1
0
1
( )
0
otherwise
m
τ
τ
<
=


	
(7.40)
where τ is expressed in chips. The W-correlator reference signal is defined as
	
1
( )
(
)
for
0
PRN
N
W
k
c
PRN
c
k
c
t
h
tf
k
t
N
f
ε
δ
=
=
-
<
	
(7.41)
where 
	
1
0
( )
0
otherwise
ε
τ
ε
δ τ
<
=


	
(7.42)
approximates Dirac’s delta function. Note that, for numerical reasons, the am-
plitude is set to 1 instead of choosing 1/e. Furthermore, it should be noted that 
if the reference signal and the PRN code is periodically extended for t < 0 or 
t  NPRN / fc, then
	
( )
(
)
k
c
k
c t
h m tf
k
=-
=
-
	
(7.43)
holds, because m has limited support and the series converges. 
The correlation function evaluates to
	
(
)
(
)
(
)
,
,
/
,
/
1
( )
lim
(
)
( )
2
1
lim
(
)
(
)
2
1
lim
(
)
(
)
2
lim
(
)
(
)
2
W
c
c
T
c c
rec
T
T
T
k
c
l
c
T
k
l
T
T
k l
c
c
T
k l
T
N f
N
c
k l
c
c
N
k l
N
N f
R
c t
c
t dt
T
h m t
f
k
h
tf
l dt
T
h h
m t
f
k
tf
l dt
T
f
h h
m t
f
k
tf
l dt
N
ε
ε
ε
τ
τ
τ
δ
τ
δ
τ
δ
-
=-
=-
-
=-
-
=-
-
=
-
=
-
-
-
=
-
-
-
=
-
-
-
	
(7.44)
where in the last step a common integration and summation interval have been 
introduced. The last step is valid in the limit T 
  for a fixed value of t. For sim-
plicity, let us now assume that the approximate delta function behaves like Dirac’s 
delta function, namely
	
( )
(
)
if
T
T
b
y t
at
b dt
y
aT
b
aT
a
a
ε
ε
δ
-
-
-
	
(7.45)

196 
Correlators
Then
	
(
)
(
)
,
,
( )
lim
(
)
2
lim
(
)
2
lim
(
)
2
lim
(
)(2
1)
( )
2
( )
W
N
c c
k l
c
c
N
k l
N
N
k N
k k l
c
N
k
N l
k N
N
c
k k l
N
l
k
N
c
prn
N
l
c
prn
l
R
h h m l f
f
k
N
h h
m l
f
N
m l
f
h h
N
m l
f
N
R
l
N
m l
f R
l
ε
τ
τ
ε
τ
ε
τ
ε
τ
ε
τ
=-
- +
+
=-
=- -
+
=-
=-
=-
=-
-
-
=
-
=
-
=
-
+
=
-
	
(7.46)
where Rprn(l) is the normalized autocorrelation function of the PRN code with 
Rprn(0) = 1. Assuming an ideal PRN code with all other values vanishing, we 
obtain 
	
,
( )
(
)
W
c c
c
R
m
f
τ
ε
τ
-
	
(7.47)
Thus, the W-correlator allows measuring the chip waveform (including filter-
ing) of the used CDMA modulation scheme.
We obtain 
	
,
( )
(
)
W
W
c
c
c
R
f
ε
τ
εδ
τ
-
	
(7.48)
by simply substituting m with de in the above-listed derivation used to obtain 
(7.47). 
The expected value, variance, and covariance of the W-correlator evaluate to
	
(
)
(
)
(
)
(
)
(
)
{
} (
)
0
0
0
0
0
0
0
0
0
0
0
(Re{
})
2
/
exp{ (
)} (
) (
)
var
(Re{
})
2
cov
Re{
};
,
Re{
};
2
exp
W
coh
c
W
coh
a
a
b
b
W
W
b
a
a
b
b
a
coh
c
C
S
C N BT
i
m
f
C
S
BT
C
S
C
S
BT
f
i
µ
µ
µ
µ
ε
ε
ϕ ϕ
κ ω
ω
τ
ε
τ
τ
εδ
τ
τ
ϕ
ϕ
κ ω
ω
=
-
-
-
=
=
-
-
-
	
(7.49)
If the difference in the code phase expressed in chips exceeds e, then the two 
W-correlators are uncorrelated. For many signal-analysis purposes, this is a major 
advantage compared to the P-correlator. The value of e should be chosen care-
fully because the SNR (i.e., the ratio between the squared expected value divided by 
the variance) depends linearly on e. If the value of e is too small, it will make the W- 
correlator output noisy. For a multicorrelator, a good choice for e is the multicorrela-
tor spacing.

7.4  Difference Correlators 
197
7.4  Difference Correlators
P-correlators, as described in the Section 7.3.3, can act as sufficient statistics and 
are a possible basis upon which to estimate the fundamental signal parameter’s code 
phase, Doppler, carrier phase, and amplitude. On the contrary, difference correlat­
ors are a suitable basis when difference signal parameters (code phase and carrier 
phase) are of interest. Difference correlators are defined as the product of two cor-
relators taking one as a complex-conjugate value. 
Difference correlators are in two GNSS applications of importance: double- 
difference tracking and P-code-aided cross-correlation tracking of the encrypted GPS 
P(Y)-code. Double-difference tracking is described in Section 10.5.2. Cross-correlation 
techniques to track the encrypted P(Y)-code are summarized by Woo [5]. Using C/A-
code-based aiding, the Y-code is tracked on L1 and L2 using very short (2-ms) coher-
ent integration intervals aligned with an unknown W-code chip. Due to the C/A-code 
aiding, the Y-code correlation point is kept within the linear region (in the code phase 
and Doppler), but the correlator values contain the W-code chip and are too noisy 
to allow carrier-phase estimation and unwrapping. Instead, a W-code independent 
L1–L2 difference correlator is formed and the L1–L2 carrier phase difference is esti-
mated, filtered, and unwrapped (note: the effective L1–L2 wavelength is 86 cm, being 
3.5 times larger than the L2 wavelength). Adding the L1–L2 carrier-phase difference 
to the C/A-code-based L1 carrier phase gives an L2 carrier-phase estimate.
In Section 7.4.1, the thermal-noise performance of single-difference and in Sec-
tion 7.4.2 double-difference prompt correlators will be investigated.
7.4.1  Single-Difference P-Correlators
For the analysis of single-difference P-correlators, we start from an undifferenced 
P-correlator and assume that Doppler errors can be ignored and that the replica-
signal waveform cP(t) coincides sufficiently well with the received-signal waveform 
c(t). According to Section 7.3.1, the P-correlator statistic is given as
	
,
,
,
0
0
,
2
/
exp{ (
)}
var
2
P
P sig
P noise
P sig
coh
P noise
coh
C
C
C
C
d
C N BT
i
C
BT
ϕ
ϕ
=
+
-
=
	
(7.50)
For convenience, the data bit d is explicitly introduced (instead of merging it 
with j), assuming values ±1. The undifferenced-SNR value is defined as the ratio 
between the squared expected value and the variance:
	
2
,
0
,
/
var
P sig
coh
P noise
C
SNR
C N T
C
=
=
	
(7.51)
To form the difference correlators, in the first step, the P-correlator is compen-
sated for internal tracking effects to obtain a correlator value related only to the 
received-carrier phase [note: the expected P-correlator value of (7.50) is related to 
the difference of the received and internal carrier phase]; that is,

198 
Correlators
	
{
}
,
,
,
0
exp
k n
k n
k n
P
P
C
iϕ
=
	
(7.52)
and the (receiver) single-difference correlator is formed according to
	
,
,
k
k m
k n
P
P
P
D
=
	
(7.53)
Here, we use the same index notation as in Section 10.5.2 (superscripts k and l 
for transmitters and subscripts m and n for receivers).
Using (7.50), we obtain
	
{
}
(
)
{
}
(
)
,
,
,
0
,
,
,
,
0
,
2(
/
)
exp
2(
/
)
exp
k m
k
k
k m
k m
coh
P noise
k n
k
k n
k n
coh
P noise
P
d
C N
BT
i
C
d
C N
BT
i
C
ϕ
ϕ
D
=
+
+
	
(7.54)
and the deterministic part of the single-difference correlator evaluates to
	
(
)
{
}
{
}
2
,
,
,
,
0
0
2
,
,
0
0
2
(
/
)
(
/
)
exp
2
(
/
)
(
/
)
exp
k
k m
k n
k m
k n
coh
sig
k m
k n
k
coh
P
BT
C N
C N
i
BT
C N
C N
i
ϕ
ϕ
ϕ
D
=
-
=
D
	
(7.55)
which can be used to obtain an estimate of the single-difference carrier-phase esti-
mate Dj k=j k,m–j k,n. The data bit d has cancelled. 
The stochastic part evaluates to 
	
{
}
{
}
,
,
,
0
,
,
,
,
,
,
0
,
,
,
2(
/
)
exp
2(
/
)
exp
k m
k
k
k n
k n
coh
noise
P noise
k n
k m
k n
k
k m
k m
coh
P noise
P noise
P noise
P
C
d
C N
BT
i
C
d
C N
BT
i
C
C
ϕ
ϕ
D
=
+
+
	
(7.56)
and because correlator values from different receivers are uncorrelated
	
0
k
noise
P
D
=
	
(7.57)
The variance of the single-difference correlator evaluates to
	
(
)
D
= D
D
=
+
+
=
+
+
=
+
+
2
,
,
2
0
,
2
2
2
,
,
,
,
2
0
,
,
,
,
3
,
3
2
0
0
2
2
,
,
0
0
var
2(
/
)
2(
/
)
2(
/
)
2
2(
/
)
2
(2
)
4
(
/
)
(
/
)
1
k
k
k
noise
noise
noise
k m
k n
coh
P noise
k n
k m
k n
k m
coh
P noise
P noise
P noise
k n
k m
coh
coh
coh
k m
k n
coh
coh
coh
P
P
P
C N
BC
T
C N
BC
T
C
C
C N
B BT
C N
B BT
BT
B T
C N
T
C N
T
	
(7.58)
and is a function of the two C/N0 values. Furthermore, the variance depends non-
linearly on the coherent integration time, which reflects the fact that a nonlinear 
operation has been used.

7.4  Difference Correlators 
199
The SNR of the single-difference correlator evaluates to
	
2
2
4
,
,
0
0
2
2
,
,
0
0
2
,
,
,
,
0
0
,
,
,
,
0
0
4
( /
)
( /
)
4
(( /
)
( /
)
1)
var
( /
)
( /
)
(( /
)
( /
)
1)
(1
)
k
k m
k n
sig
coh
k m
k n
k
coh
coh
coh
noise
k m
k n
k m
k n
coh
k m
k n
k m
k n
coh
coh
P
B T
C N
C N
SNR
B T
C N
T
C N
T
P
T
C N
C N
SNR
SNR
C N
T
C N
T
SNR
SNR
D
D
=
=
+
+
D
=
=
+
+
+
+
N
	
(7.59)
and in case both SNR values are equal and much larger than one:
	
,
,
1
2
k m
k n
SNR
SNR
SNR
SNR
SNRD
=
=
=

	
(7.60)
In the latter case, single-differencing reduces the SNR value by 3 dB. An equiva-
lent 3-dB loss would also occur if single-differencing were done at the carrier-phase 
level.
7.4.2  Double-Difference P-Correlators
A double-difference P-correlator is used by forming the (transmitter) difference be-
tween two single-difference correlators
	
k
l
P
P
P
D
= D
D
	
(7.61)
and evaluates according to (7.55) as 
	
{
}
(
)
{
}
(
)
2
,
,
0
0
2
,
,
0
0
2
( /
)
( /
)
exp
2
( /
)
( /
)
exp
k m
k n
k
k
coh
noise
l m
l n
l
l
coh
noise
P
BT
C N
C N
i
P
BT
C N
C N
i
P
ϕ
ϕ
D
=
D
+ D
D
+ D
	
(7.62)
The deterministic part of the double-difference correlator
	
2
4
,
,
,
,
0
0
0
0
4
(
/
)
(
/
)
(
/
)
(
/
)
exp{
}
k m
k n
l m
l n
sig
coh
P
B T
C N
C N
C N
C N
i
ϕ
D
=
D
	
(7.63)
is used to estimate the double-difference carrier phase 
Dj = j k,m – j k,n – j l,m+ 
j l,n.
The stochastic part is
	
{
}
{
}
2
,
,
0
0
2
,
,
0
0
2
(
/
)
(
/
)
exp
2
(
/
)
(
/
)
exp
k m
k n
k
l
noise
coh
noise
l m
l n
l
k
k
l
coh
noise
noise
noise
P
BT
C N
C N
i
P
BT
C N
C N
i
P
P
P
ϕ
ϕ
D
=
D
D
+
D
D
+ D
D
	 (7.64)
and its expected value vanishes,
	
0
noise
P
D
=
	
(7.65)
because the single-difference correlator to two different transmitters is assumed to 
be uncorrelated. The variance of the double-difference correlator is given as



202 
Correlators
The output of the (cross-correlation) correlator X is defined as
	
(
)
,
,
,
1
1
1
(
)
( )
( ,
,
)
L
L
L
rec
rec
rec
sig
noise
X S
r
S
r
r
r
N
r M
N M
X
r
X
r
N
M
µ
µ µ
µ µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
=
=
=
=
=
+
+
+
=
+
	
(7.70)
and is split into a deterministic-signal part Xsig and a stochastic-noise part Xnoise. 
The integration (summation) involves a number of ncoh samples corresponding to a 
coherent integration time of Tcoh = L/fs.
In the following example, all expected values are understood with respect to the 
reference-signal noise and the received noise:
	
,
N M
…
…
	
(7.71)
7.5.1  Expected Value
The expected value for the correlator output is the sum of the deterministic contri-
bution 
	
{
}
µ
µ µ
µ
µ
µ
µ
µ
µ
τ
τ
ω
ϕ
ω
ϕ
τ
τ
ϕ
ϕ
κ ω
ω
=
=
=
=
-
-
-
-
+
-
-
-
-
,
0
0
0
1
1
,
0
0
0
(
)
(
)
(
)exp
(
)
(
)
(
)exp{ (
)} (
)
rec
L
L
sig
rec
rec
coh s
c c
X
r
r
r
a
c t
c
t
i
t
i
t
aT
f R
i
	
	
	
	
(7.72)
and the noise contribution. The expected value of the latter contribution vanishes 
because both noise processes are uncorrelated and unbiased,
	
(
)
(
)
,
1
,
,
0
L
noise
rec
X
r
N
M
r
N
r M
N M
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ=
=
+
+
=
	
(7.73)
The deterministic contribution relates to the parameter difference of the code phases 
t  – t0, Doppler difference w – w0, and carrier-phase difference j – j0.
Thus, for complex-valued input samples, the expected value is
	
,
0
0
0
(
)
(
)exp{ (
)} (
)
(
)
0
rec
coh s
c c
X S
aT
f R
i
X S
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
-
-
-
	
(7.74)
and for real-valued input samples,
	
,
0
0
0
(Re{
})
(
)exp{ (
)} (
)
2
rec
coh s
c c
a
X
S
T
f R
i
µ
τ
τ
ϕ
ϕ
κ ω
ω
-
-
-
	
(7.75)
7.5.2  Covariance
To evaluate the covariance, assume two different correlators, which are distin-
guished by an index “a” and an index “b.” Both correlators are associated with 
different parameters, namely

7.5  Noisy Reference Signal for Codeless Tracking 
203
	
0
0
0
0
0
0
(
)
,
,
,
,
(
)
,
,
,
,
a
a
a
a
rec
b
b
b
b
rec
X
S
c
M
X
S
c
M
µ
µ
µ
µ
τ
ω
ϕ
τ
ω
ϕ


	
(7.76)
Both work with the same received-signal samples. The underlying reference 
signal crec is identical, as is the noise process Mm.
Furthermore, we only consider code-phase shifts as a multiple of the sampling 
interval:
	
0
0
,
a
b
s
s
a
b
f
f
τ
τ
=
=
	
(7.77)
Similar to Section 7.2.2, the covariance is defined as
	
cov
(
),
(
)
(
0,
,
)
(
0,
,
)
a
b
a
b
X
S
X
S
X
r
N
M
X
r
N
M
µ
µ
µ
µ
µ
µ
µ
µ
=
=
=
	
(7.78)
because the signal contribution cancels and the expected value of the received-noise 
contribution vanishes. Thus,
	
(
)
(
)
{
}
(
)
(
)
(
)
{
}
(
)
(
)
(
)
(
) (
)
{
}
0
0
0
,
1
0
0
0
0
0
0
0
0
0
1
,
1
cov
(
),
(
)
cov
(
0,
,
),
(
0,
,
)
exp
exp
2
exp
2
a
b
a
b
L
a
a
a
rec
a
b
b
b
rec
b
L
a
b
b
a
b
a
rec
rec
L
a
b
rec
X
S
X
S
X r
N
M
X
r
N
M
N
c
t
i
t
M
N
c
t
i
t
M
c
t
c
t
it
i
N M
N M
c
t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ υ
υ
υ
υ
υ
µ
µ
µ
µ
µ
µ
υ
υ
µ υ
µ
τ
ω
ϕ
τ
ω
ϕ
τ
τ
ω
ω
ϕ
ϕ
τ
-
=
-
=
-
-
=
=
=
=
=
-
-
+
-
-
+
=
-
-
-
-
-
+
=
-
(
)
(
)
(
) (
)
{
}
(
)
(
)
{
} (
)
0
0
0
0
0
0
1
,
0
0
,
1
,
0
0
0
0
exp
2
exp
4
rec
rec
L
a
b
b
a
b
a
rec
L
a
b
a
b
s coh
c
c
a
b
b
a
a b s coh
c
t
it
i
N N
M
M
f T
R
i
f T
µ
µ
µ
µ
υ
µ
υ
µ υ
τ
ω
ω
ϕ
ϕ
τ
τ
ϕ
ϕ
κ ω
ω
δ
=
-
-
=
-
-
-
-
+
-
-
-
+
 
 
because (1.16) and (1.28) hold and we assume that the shifts a, b are much smaller 
than L. The covariance for the complex-conjugated input signal is given similarly 
as
	
( )
( )
cov
,
cov
(
),
(
)
a
b
a
b
X
S
X
S
X
S
X
S
µ
µ
µ
µ
=
	
(7.80)
(7.79)

204 
Correlators
For mixed terms, we obtain
(
)
(
)
{
}
(
)
(
)
(
)
{
}
(
)
(
)
(
)
(
) (
)
{
}
0
0
0
,
1
0
0
0
0
0
0
0
0
0
1
,
1
cov
(
),
(
)
exp
exp
2
exp
0
L
a
b
a
a
a
rec
a
b
b
b
rec
b
L
a
b
b
a
b
a
rec
rec
L
a
b
X
S
X
S
N
c
t
i
t
M
N
c
t
i
t
M
c
t
c
t
it
i
N N
N M
N M
µ
µ
µ
µ
µ
µ
µ υ
υ
υ
υ
υ
µ
µ
µ
µ
µ
υ
µ
µ
υ
υ
µ υ
τ
ω
ϕ
τ
ω
ϕ
τ
τ
ω
ω
ϕ
ϕ
-
=
-
=
-
-
=
=
-
-
+
-
-
+
=
-
-
-
-
-
+
=
	
	
	
	
(7.81)
Based on the derivation of (7.24), for real-valued input signals we obtain
	
(
)
(
)
(
)
(
)
{
} (
)
,
,
0
0
0
0
0
0
cov
Re{
} ,
Re{
}
exp
2
rec
rec
a
b
a
b
a
b
b
a
s coh
a b s coh
c
c
X
S
X
S
f T
R
i
f T
µ
µ
τ
τ
ϕ
ϕ
κ ω
ω
δ
=
-
-
-
+
	
(7.82)
7.5.3  Variance
The variance of the correlator output is a special case of the covariance assuming 
identical parameters for the “a” and “b” cases. 
For complex-valued input signals 
	
,
var
(
)
2
(0)
4
rec
rec
s coh
c
c
s
coh
X S
f T
R
f T
µ
=
+
	
(7.83)
holds, and for real-valued input signals
	
(
)
,
var
Re{
}
(0)
2
rec
rec
s coh
c
c
s coh
X
S
f T
R
f T
µ
=
+
	
(7.84)
7.5.4  L2P(Y)-Code Carrier-Phase Discriminator Noise
In the following section, the set of formulas for the cross-correlation correlator are 
applied to determine the GPS-P(Y) L2–L1 cross-correlation carrier-phase discrimi-
nator noise as depicted in Figure 7.4. The discriminator estimates the L2–L1 carrier 
phase difference, which is added to the L1 carrier phase to obtain an L2 carrier-
phase estimate. The L1 carrier-phase estimate is based on the C/A-code, whereas 
the L2–L1 carrier-phase estimate is based on the P(Y)-code. Consequently, both 
estimates are uncorrelated.
In Figure 7.4, the reference signal is obtained by multiplying the signal samples 
on L1 by a complex carrier. The frequency of the carrier needs to be selected in a 
way that the resulting carrier frequency w0 (including Doppler) matches approxi-
mately the L2 carrier frequency (including Doppler) for the satellite of interest. 
The necessary Doppler computations are based on GPS C/A-code measurements. 
Doppler frequency errors are tolerable if they are much smaller than the inverse 
of the coherent integration time. The reference signal is delayed by t0 to maximize 
the correlator output. The delay needs to be a multiple of the sampling period. The 
delay can be used to compute the L2–P(Y) code pseudorange, which is not discussed 
here. The parameter j0 of (7.68) is the carrier phase of the reference signal and is 
directly related to the received L1-carrier phase.

7.5  Noisy Reference Signal for Codeless Tracking 
205
We assume that the deterministic part of the reference signal equals the trans-
mitted signal [being the same P(Y)-code signal on L1 and L2] multiplied by an 
amplitude factor b:
	
( )
( )
rec
c
t
bc t
=
	
(7.85)
The reference signal is complex-valued and b relates to the C/N0 value on L1. 
According to Appendix A.2.1, the relationship is
	
2
0,
/
2
s
ref
f b
C N
=
	
(7.86)
The autocorrelation function of the reference signal becomes
	
2
,
,
( )
( )
rec
rec
c
c
c c
R
b R
τ
τ
=
	
(7.87)
The amplitude of the received signal relates to the C/N0 value on L2
	
2
0
/
4
sf a
C N
=
	
(7.88)
because a real-valued received signal is considered (see Appendix A.2.2). 
The formula for the variance of a carrier-phase discriminator will be derived in 
Section 8.1.3 and is given by (8.31). For cross-correlation, it reads as
	
2
2
2
2
,
,
2
2
2
2
0
,
0
0
,
0
0,
var
(Re{
})
var
(Re{
})
var
(Re{
})
1
2
(Re{
})
2
(Re{
})
4
(0)
8
4
(0)
8
1
2(
)
(
)
(
)
2(
)
(
)
(
)
(4
2
/
P
P
P
P
s
coh
c c
s coh
s
coh
c c
s
coh
c c
s
coh
c c
coh
X
S
X
S
S
X
S
X
S
f T
b R
f T
f T
b R
L
af T
bR
af T
bR
T
C N
µ
µ
µ
µ
µ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
÷
F
+
÷
+
+
÷
=
+
÷
-
-
-
-
=
(
)
2
2
2
0
0,
0
,
0
2
0,
2
2
0
0,
0
,
0
0,
2
2
0
0,
0
,
0
8
)
2
4
/
2
/
(
)
(
)
(4
2
/
8 )
1
2(
) 4
/
2
/
(
)
(
)
2
/
2
4
/
/
(
)
(
)
2
/
1
ref
s coh
s
s
coh
ref
c c
coh
ref
s
s
coh
ref
c c
coh
ref
coh s
coh
ref
c c
coh
f T
f
f T
C N
C N
R
T
C N
L f
f T
C N
C N
R
T
C N
T
f
T
C N C N
R
T
C N
κ ω
ω
τ
τ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
+
-
-
+
÷
+
÷
-
-
+
=
-
-
+
0,
2
2
0
0,
0
,
0
0,
2
0
0,
0
,
0
0,
2
0
0,
0
,
0
2
4
/
/
(
)
(
)
/
2
/
/
(
)
(
)
/
1
2
/
/
(
)
(
)
ref
coh s
coh
ref
c c
ref
s
coh
ref
c c
ref
s
coh
ref
c c
T
f
T
C N C N
R
C N
f
T
C N C N
R
C N
f
T
C N C N
R
κ ω
ω
τ
τ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
+
÷
÷
-
-
+
=
-
-
+
÷
+
÷
-
-
	
(7.89)
where Xp denotes the prompt cross-correlation correlator. 

206 
Correlators
If the C/N0 value of the reference signal (e.g., on L1) is much larger than the 
sample rate, the phase-discriminator variance equals the case of a noiseless refer-
ence signal:
	
0,
2
/
0
0
,
0
2
0
0
,
0
1
var
(Re{
})
2
/
(
)
(
)
1
1
2
/
(
)
(
)
ref
s
C N
f
coh
c c
coh
c c
S
T
C N
R
T
C N
R
µ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
F
=
-
-
÷
+
÷
-
-

	
(7.90)
In the general case of an arbitrary C/N0 value of the reference signal, the phase-
discriminator noise is identical to the noiseless reference-signal case if the received 
signal C/N0 value is replaced by an effective value C/N0,eff:
	
0,
0,
0
0,
/
/
/
/
ref
eff
ref
s
C N
C N
C N C N
f
=
+
	
(7.91)
Thus, the cross-correlation loss is given by
	
0,
0,
/
/
ref
xcorr
ref
s
C N
L
C N
f
=
+
	
(7.92)
and is a function of the reference-signal power and the sample rate fs.
7.6  Incorporating Colored Noise
Within this section, we will extend the obtained mean and variance formulas for the 
case of colored noise. The approach is based on a signal transformation to reduce 
the colored-noise case to the white-noise case. Within this approach, artificial sig-
nals are introduced and the reader should keep in mind that those signals are just 
used for the theoretical analysis. They do not appear in the receiver. 
7.6.1  White-Noise Transformation
The colored-noise analysis starts from a similar signal model as for the white-noise 
case. The signal samples Sµ are the sum of a deterministic part rµ and a stochastic 
part Nµ, 
	
S
r
N
µ
µ
µ
=
+
	
(7.93)
The complex-valued noise samples are from a wide-sense stationary process 
and the covariance is
	
0,
0,
2 (
)
N N
N N
N N
Q
µ
υ
µ
υ
µ
υ
µ
υ
=
=
=
-
N
N
N
	
(7.94)
The noise-power spectral density is related to the covariance function via the 
Fourier-series equation
	
2
( )
( )exp
2
2
s
s
s
if
f
f
Q f
Q
f
f
µ
π
µ
µ
=-
=
-
<

	
(7.95)

7.6  Incorporating Colored Noise 
207
and its inverse
	
2
2
1
2
( )
( )exp
s
s
f
s
s
f
f
if
Q
Q f
df
f
f
π
µ
µ
=-
=

	
(7.96)
Note that
	
2
2
1
1
(0)
( )
s
s
f
s
f
f
Q
Q f df
f
=-
=
=

	
(7.97)
must be fulfilled so that the C/N0 definition can be maintained. For the C/N0 defini-
tion in the case of colored noise, the noise-power density is interpreted as a mean-
noise power density. 
The complex-valued signal model from Section 1.8 is used:
	
(
)exp{ (
)}
r
ac t
i
t
µ
µ
µ
τ
ω
ϕ
=
-
-
 	
(7.98)
In the following examples, we analyze in detail the expression of a correlator 
operating on the complex-conjugated samples. The discussion is analogous for a 
correlator operating on the nonconjugated samples. According to Section 7.2, the 
correlator is defined as
	
( )
,
1
L
rec
rec
C S
r
S
µ
µ µ
µ
*
=
=
=
×
S
r
	
(7.99)
The expression is now rewritten, introducing artificial signals S¢, r¢rec, and N¢ 
	
( )
(
)
1 2
1 2
1 2
1 2
rec
rec
rec
rec
C S
Q
Q
Q
Q
µ
*
*
*
-
-
*
=
×
=
×
=
×
=
×
S
r
S
r
S
r
S
r
	
(7.100)
which are defined as
	
1 2
1 2
1 2
1 2
,
,
rec
rec
Q
Q
Q
Q
-
-
-
=
+
=
=
=
=
S
r
N
S
S
r
r
N
N
r
r
	
(7.101)
by using the Hermitian colored-noise covariance matrix Q. Similar to the discus-
sion of spectral whitening in Section 6.4.1, the artificially introduced noise is white; 
that is,
	
,
0,
0,
2
N
N
N
N
N
N
µ
υ
µ
υ
µ
υ
µ υ
δ
=
=
=
N
N
N
	
(7.102)
So far, the discussion has been carried out using finite-length sample vectors. It 
is, however, more convenient to confine the discussion to the level of continuous-
time signals, thereby allowing simpler expressions when working in the frequency 
domain.
Let Wx{…} be a filter operating on the continuous time signals defined in fre-
quency domain as
	
( )
{ ( )}
( )
( )
( )
( )
x
x
x
c t
W
c t
c f
W f
f
c f
F




	
(7.103)

208 
Correlators
with x being a real number (acting as an exponent) and an arbitrary phase function 
defined in the frequency domain with
	
( )
1
f
F
=

	
(7.104)
The filter’s magnitude response is related to the colored-noise power spectral 
density via
	
2( )
( )
W
f
Q f
-
= 

	
(7.105)
The filter Wx{…} is called  a (continuous-time) whitening filter.
Applying the whitening filter to the received signal and the inverse whitening 
filter to the internally generated reference signal before sampling
	
1
( )
{ ( )}
( )
{
( )}
ref
ref
S t
W S t
c
t
W
c
t
-
=
=
	
(7.106)
leaves the correlation value invariant and allows the application of the white-noise 
theory. Only the correlation functions appearing in formulas on the stochastic cor-
relator properties need to be adjusted.
The correlation function between an internal reference signal and the received 
signal remains unchanged because
	
1
,
,
{ },
{
}
( )
( )
( )
rec
rec
rec
c c
c c
W c W
c
R
R
R
τ
τ
τ
-
=
	
(7.107)
and the correlation function between two reference signals changes to
	
1
1
2
,
{
},
{
}
,
{
}
( )
( )
a
b
a
b
a
b
rec
rec
rec
rec
rec
rec
c
c
W
c
W
c
c
W
c
R
R
R
τ
τ
-
-
-
=
	
(7.108)
In Section 7.6.2, the technique will be illustrated for the example of the code-
discriminator noise for an early–late tracker of a signal of finite bandwidth.
7.6.2  Early–Late Code Discriminator with Infinite Sample Rate
In the following example, the white-noise transformation will be used to determine 
the discriminator noise for an early–late tracker of a signal of finite bandwidth us-
ing an infinite sample rate (i.e., we work now with continuous time signals).
We assume that an infinite-bandwidth signal with the waveform at baseband 
cp(t) is transmitted and the same signal is also generated inside a receiver as a rep-
lica signal. The signal plus colored noise is received by the front end, which limits 
the bandwidth of both. First, the results for real-valued signal samples are analyzed 
and the latter results are also presented for a complex-valued signal. The spectra 
of the continuous-time signals are shown in Figure 7.5. The noise is, in both cases, 
bandlimited and eventually colored. 
We now start with the analysis of the real-valued signal.
The signal is transmitted at a nominal frequency f0 and a brick-wall filter is 
used within the front end. No signal or noise energy passes outside the passband 
that ranges from –B to B. The spectrum of the real-valued signal and the noise is 


210 
Correlators
The cross-correlation function between the received signal and an internally 
generated signal is given by (see Section A.2.5)
	
2
2
2
,
,
2
( )
( )
(
)
( )
rec
rec
B
if
if
c c
c c
rec
B
f
f
R
R
f e
df
c
f c
f e
df
π τ
π τ
τ
=-
=-
=
=
-



	
(7.112)
because outside the passband, the received signal has only vanishing frequency 
components. The frequency-domain representation of the correlation function is 
the product of the frequency transform of both signals.
The correlation function between two internally generated signals changes ac-
cording to (7.108) into
	
2
2
2
,
{
}
,
3 2
2
2
0
3 2
( )
( )
2
(
)
(
)
( )
a
b
a
b
rec
rec
rec
rec
B
if
c
W
c
c
c
B
f
B
a
b
if
rec
rec
B
f
B
R
Q f
R
f e
df
Q f
f c
f c
f e
df
π
τ
π
τ
τ
-
=-
=-
=
+
=
+
-





	
(7.113)
The whitening filter is shifted by f0, the center frequency, where the correlation 
takes place.
Ignoring for the moment the squaring loss (which is sufficient to demonstrate 
the white-noise transformation), the variance of the code discriminator, working on 
real-values samples with white noise, obtained from (8.14), is
	
(
)
2
,
0
,
(0)
1
var
Re{
}
2
/
(0)
D
D
D
c
c
coh
c c
R
D
S
C N T
R
µ
=
	
(7.114)
Applying the white-noise transformation, the code-discriminator variance 
changes to
	
2
,
{
}
0
,
(0)
1
var
(Re{
})
2
/
(0)
D
D
D
c
Q c
coh
c c
R
D
S
C N T
R
µ
=
	
(7.115)
Note that Q{…} = W–2{…}.
The early–late reference signal is
	
( )
2
2
D
P
P
d
d
c
t
c
t
c
t
=
-
-
+
	
(7.116)
where d is the discriminator spacing in seconds.
The correlation function of the complex-conjugated received signal with the 
early–late reference signal is
	
(
)
(
)
,
,
,
,
2
2
2
2
2
,
2
( )
( )
2
2
( )
D
P
D
P
P
P
P
P
P
c c
c
c
c
c
c
c
B
d
d
if
if
c
c
B
f
d
d
R
R
R
R
R
f
e
e
df
π
τ
π
τ
τ
τ
τ
τ
-
+
=-
=
=
-
-
+
=
-
÷

	
(7.117)

7.6  Incorporating Colored Noise 
211
The first derivative at the origin is
	
(
)
2
,
,
2
2
,
2
(0)
2
( )
4
( )sin(
)
D
P
P
P
P
B
d if
d if
c c
c
c
B
f
B
c
c
B
f
R
i
fR
f
e
e
df
fR
f
d f df
π
π
π
π
π
-
=-
=-
=
-
=


	
(7.118)
The modified autocorrelation function of the early–late reference signal 
becomes
	
(
)
,
{
}
,
{
}
,
{
}
,
{
}
2
2
2
0
,
3 2
2
2
0
,
3 2
(0)
2
(0)
(
)
( )
(
)
( ) 2
4
(
)
( )sin (
)
D
D
P
P
P
P
P
P
P
P
P
P
c
Q c
c
Q c
c
Q c
c
Q c
B
ifd
ifd
c
c
B
f
B
c
c
B
f
R
R
R
d
R
d
Q f
f R
f
e
e
df
Q f
f R
f
fd df
π
π
π
-
=-
=-
=
-
-
-
=
+
-
-
=
+




	
(7.119)
Overall, the code-discriminator variance working on real-valued samples with 
colored noise becomes
	
2
2
0
,
3 2
2
0
2
,
2
(
)
( )sin (
)
1
var
(Re{
})
2
/
2
( )sin(
)
P
P
P
P
B
c
c
B
f
B
coh
c
c
B
f
Q f
f R
f
fd df
D
S
C N T
fR
f
fd df
µ
π
π
π
=-
=-
+
=



 	
(7.120)
Note that,
	
2
,
( )
(
)
( )
( )
P
P
c
c
P
P
P
R
f
c
f c
f
c
f
=
-
=




	
(7.121)
If a complex-valued input signal is processed, the integration boundaries would 
be symmetric, yielding
	
2
2
,
2
2
0
2
,
2
( )
( )sin (
)
1
var
(
)
2
/
2
( )sin(
)
P
P
P
P
B
c
c
B
f
B
coh
c
c
B
f
Q f R
f
fd df
D S
C N T
fR
f
fd df
µ
π
π
π
=-
=-
=



 	
(7.122)
Equations of type (7.122) have also been derived in the work by Betz and 
Kolodziejski using a different methodology [8]. 


7.7  Comparison of Finite and Infinite Sample Rates 
213
sampled without aliasing, but the spectra of the internally generated infinite band-
width replica shows aliasing effects.
After sampling, the noise-power spectral density is flat and the white-noise the-
ory can be applied. Ignoring the squaring loss, the code-discriminator variance from 
(8.14) is expressed in the frequency domain as
	
2
,
0
,
2
,
2
0
2
,
2
(0)
1
var
(
)
2
/
(0)
( )sin (
)
1
2
/
2
( )sin(
)
D
D
D
P
P
P
P
c
c
coh
c c
c
c
f
B
coh
c
c
B
f
R
D S
C N T
R
R
f
fd df
C N T
fR
f
fd df
µ
π
π
π
=-
=-
=
=


	
(7.124)
This expression compares to (7.122) and differs only in the integration bound-
aries of the nominator. In fact, in (7.124), the aliased early-minus-late reference- 
signal frequency components correlate with each other, whereas they do not 
correlate in the infinite sample-rate case (7.122). 
To visualize the difference between the infinite and finite sample-rate case a 
BPSK power spectral density is assumed
	
2
,
2
sin (
)
( )
(
)
P
P
c
c
c
c
c
fT
R
f
T
fT
π
π
=

	
(7.125)
where Tc is the chip period in seconds. Table 7.1 summarizes the parameter used for 
the evaluation of the formulas. It should be noted that (7.123) and (7.124) give the 
code variance in seconds-squared and the discriminator spacing is in seconds. For 
better visualization in Figure 7.7, the variance (actually the standard deviation) is 
plotted in meters and the discriminator spacing is in chips.
The integrals occurring in (7.123) and (7.124) can be solved analytically using 
a symbolic mathematics software package. The resulting expressions are not given 
here. From Figure 7.7, one clearly sees the divergence of the code-noise variance, if 
d 
 0 and if a finite sample rate is used. 
Thus, an early–late tracker does not approach the CRLB if d 
 0 in a real-
receiver implementation, which necessarily works with a finite sample rate. The 
Table 7.1  Parameters for Nyquist/Infinite 
Sample-Rate Code-Variance Evaluation
Name
Value
Modulation
BPSK
Chip rate
1.023 Mchip/s
Bandwidth
20.46 MHz
C/N0
45 dBHz
Tcoh 
20 ms


7.7  Comparison of Finite and Infinite Sample Rates 
215
  [7]	 Sleewagen, J.-M., “Surge Anomaly in Cross-Correlation GPS Measurements: Description 
and Analysis,” NAVIGATION, Journal of The Institute of Navigation, Vol. 46, No. 2, 
1999, pp. 119–125.
  [8]	 Betz, J. W., and K. R. Kolodziejski,  “Extended Theory of Early-Late Code Tracking for 
a Bandlimited GPS Receiver,” NAVIGATION, Journal of The Institute of Navigation, 
Vol. 47, No. 3, 2000, pp. 211–226.
  [9]	 Holmes, J. K., “Noncoherent Late Minus Early Power Code Tracking Loop Performance 
with Front End Filtering,” Proc. 20th Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation (ION-GPS) 1997, Kansas City, MO, September 16–19, 1997, pp. 
583–591.
[10]	 Pany, T., et al., “Code and Carrier Phase Tracking Performance of a Future Galileo RTK 
Receiver,” Proc. European Navigation Conference (ENC-GNSS) 2002, Graz, May 27–30, 
2002.

217
C h a p t e r  8
Discriminators
The different correlator types of Chapter 7 are the basis for estimating signal- 
parameter values. The correlator values are combined to form the code-phase, Dopp­
ler, and carrier-phase discriminator values. Nonlinear operations are required to 
remove the carrier-phase dependency of the correlators and to obtain noncoherent 
discriminators. The reference functions can be optimized to achieve a desired track-
ing performance in terms of multipath mitigation and thermal noise. This process 
is called S-curve shaping. Multiple correlator values can be used to simultaneously 
estimate direct and reflected signal parameters. Finally, this chapter outlines how to 
compute positioning accuracy from discriminator noise.
8.1  Noncoherent Discriminators
The D- (and F-correlator) values depend approximately linearly on the code-phase 
(and respectively on the Doppler) difference of the received and replica signal. How-
ever, the D- and F-correlator are also proportional to the complex-signal amplitude. 
As pointed out in Section 4.3, the complex-amplitude dependency can be removed 
by dividing the D- or F-correlator by the P-correlator. Care must be taken if the 
P-correlator value is near zero and eventually the discriminator values need to be 
clipped. The carrier-phase estimate is obtained via an atan operation without any 
clipping operation.
In the following, all expected values are with respect to noise; that is,
	
=
N
…
…
	
(8.1)
8.1.1  Code Discriminator
The code-phase discriminator is obtained by dividing one D-correlator by one P-
correlator. The reference signals associated with the different correlators are
	
( )
( )
D
D
P
P
C
c
t
C
c
t
¬
¬
	
(8.2)
The reference signals fulfill the following requirements within the code phase lin-
earity limit l in order to allow the construction of a linear code-phase discriminator, 

218 
Discriminators
	
,
,
,
,
,
(0)
0
( )
(0)
(0)
0
(0)
0
D
P
D
D
D
P
c
c
c c
c c
c c
c c
R
R
R
R
R
τ
τ
τ  l
	
(8.3)
Because of the first condition, both correlators are uncorrelated if they are 
based on the same code-phase delay. Because the correlators use a large number 
of signal samples, the central-limit theorem applies and the correlator values are 
Gaussian random variables. Uncorrelated Gaussian random variables are indepen-
dent of each other.
The code-phase discriminator is constructed for a real-valued incoming signal as
	
(
)
(
)
(
)
(
)
(
)
2
Re{
}
Re{
}
Re{
}
Re
Re
Re{
}
Re{
}
D
D
P
P
P
C
S
C
S
C
S
D
C
S
C
S
µ
µ
µ
µ
µ
α
α
=
=
	
(8.4)
where a is a normalization constant that will be determined later.
In a first-order approximation, the expected value of the code discriminator is
	
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
Re{
}
Re{
}
Re
Re
Re{
}
Re{
}
Re{
}
Re{
}
Re{
}
Re{
}
Re{
}
Re
1
Re{
}
Re{
}
Re{
Re{
}
Re{
}
Re{
}
Re
1
Re{
}
Re{
}
D
D
P
P
P
P
D
P
P
P
P
P
D
P
P
P
P
C
S
C
S
D
C
S
C
S
C
S
C
S
C
S
C
S
C
S
C
S
C
S
C
C
S
C
S
C
S
C
S
C
S
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
α
α
α
α
-
=
=
-
+
-
=
-
÷÷
-
+
-
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
2
2
2
2
2
,
0
2
,
0
}
Re{
}
2
Re{
}
Re{
}
Re{
}
Re{
}
Re
1
Re{
}
2
Re{
}
Re{
}
Re{
}
(
)
Re
1
(
)
2
Re{
}
D
P
P
P
P
P
D
P
P
P
P
c c
c c
P
S
C
S
C
S
C
S
C
S
C
S
C
S
C
S
C
S
C
S
R
R
C
S
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
α
τ
τ
α
τ
τ
-
-
÷
=
-
÷
÷
-
-
÷
=
-
÷
-
÷
	
	
	
(8.5)
because the D- and P-correlators are independent random variables. For high P-cor-
relator SNR,

8.1  Noncoherent Discriminators 
219
	
,
0
,
0
(
)
Re
(
)
D
P
c c
c c
R
D
R
τ
τ
α
τ
τ
-
-
	
(8.6)
The expected discriminator value should be equal to the code-tracking error, 
therefore
	
0
0
!
,
0
,
,
0
,
,
(0)(
)
1
Re
(0)
(0)(
)
(0)
Re
(0)
D
P
P
D
P
c c
c c
c c
c c
c c
R
D
R
R
R
R
τ τ
τ τ
τ
τ
α
τ
τ
τ
τ
α
=
=
-
÷
=
÷
+
-
=
	
(8.7)
A normalization constant of
	
,
,
,
,
(0)
(0)
(0)
(0)
P
P
D
D
c c
c c
c c
c c
R
R
i
R
R
α
ε
ε
=
+
R
	
(8.8)
achieves, in the case of high signal power,
	
τ τ
τ
τ
-
=
-

0
0
l
D
	
(8.9)
Typically, e = 0.
For low P-correlator SNR values, the normalization constant needs to be ad-
justed to maintain a unity slope of the discriminator at the origin. This is ignored in 
many GNSS-receiver implementations. 
For t = t0, the variance of the complex-valued code-phase discriminator is 
obtained as
	
2
(Re{
})
var
var
(Re{
})
(Re{
})
(Re{
})
D
D
P
P
C
S
C
S
C
S
C
S
µ
µ
µ
µ
-
=
	
(8.10)
because both correlators are independent and because the expected value of CD 
vanishes. The inverse of the squared absolute value of the complex Gaussian ran-
dom variable is approximated based on the assumption that its variations are much 
smaller than the mean value:
	
2
2
2
2
2
2
1
1
2
2
1
1
1
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
-
-
-
-
-
-
-
-
-
=
-
+
=
+
-
-
÷
÷
=
+
=
+
÷
÷
÷
	

220 
Discriminators
	
2
2
2
4
4
2
2
2
4
1
2
Re
var
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
-
-
-
-
-
-
-
=
-
+
=
-
-
+
-
÷
=
+
	
(8.11)
Thus, the code-discriminator variance is obtained by using (7.17) and (7.26) with 
fs = 2B and a = (2C / N0 / B)1/2 as
	
2
4
,
2
0
,
2
0
,
,
,
,
2
0
,
(Re{
})
var
(Re{
})
var
(Re{
})
(Re{
})
(Re{
})
var
(Re{
})
2
(0)
2
/
(0)
1
2
/
(0)
2
(0)
(0)
(0)
1
/
(0)
D
D
P
P
P
P
D
D
P
P
P
D
P
D
P
P
P
coh
c
c
coh
c c
coh
c c
coh
c
c
c
c
c
c
coh
c c
C
S
C
S
C
S
C
S
C
S
C
S
BT
R
C N BT
R
C N BT
R
BT
R
R
R
C N T
R
C
µ
µ
µ
µ
µ
µ
κ
κ
κ
-
-
-
+
=
+
÷
=
+
2
0
,
/
(0)
P
coh
c c
N T
R
κ
÷
÷
	
(8.12)
with 
	
0
(
)
κ
κ ω
ω
=
-
	
(8.13)
accounting for Doppler correlation losses. 
The variance of the real-valued code-phase discriminator is half the variance of 
the complex-valued discriminator and is for e = 0
	
2
2
,
,
,
2
2
,
0
,
0
,
(Re{
})
var
(Re{
})
var
2
(Re{
})
(0)
(0)
(0)
1
(0)
2
/
(0)
/
(0)
P
D
D
P
P
D
P
P
D
P
c c
c
c
c
c
c c
coh
c c
coh
c c
C
S
D
S
C
S
R
R
R
R
C N T
R
C N T
R
µ
µ
µ
α
κ
κ
=
÷
=
+
÷
	
(8.14)
The variance of the code discriminator is mainly given by the ratio of the au-
tocorrelation function at the origin of the code-tracking reference function cD(t) 

8.1  Noncoherent Discriminators 
221
divided by the squared first derivative of the cross-correlation function of the 
complex-conjugated received signal c(t) with the code-tracking reference function. 
The variance is minimal if cD(t) = c (t) and e = 0.
8.1.2  Doppler Discriminator
The Doppler discriminator is obtained by dividing the F-correlator by the P-correla-
tor. The reference signals associated with the different correlators are
	
( )
2
( )
coh
F
P
P
P
T
C
t
c
t
C
c
t
¬
-
÷
¬
	
(8.15)
The F-correlator reference function is directly derived from the P-correlator 
reference function. The P-correlator reference function fulfills
	
,
,
(0)
0
(0)
0
F
P
P
c
c
c c
R
R
=
	
(8.16)
Similar to the code-phase discriminator, the F- and P-correlator are independent 
Gaussian random variables. 
The F-correlator is given by
	
2
(Re{
})
(Re{
})
(Re{
})
Re
Re
(Re{
})
(Re{
})
F
F
P
P
P
C
S
C
S
C
S
F
C
S
C
S
µ
µ
µ
µ
µ
β
β
=
=
	
(8.17)
where b is a normalization constant to be determined later.
Similar to (8.5) the expected value of the F-correlator is 
	
(
)
2
2
(Re{
})
Re
(Re{
})
(Re{
})
(Re{
})
(Re{
})
Re
1
(Re{
})
2
(Re{
})
F
P
P
P
F
P
P
C
S
F
C
S
C
S
C
S
C
S
C
S
C
S
µ
µ
µ
µ
µ
µ
µ
β
β
=
-
÷
-
÷
÷
	
(8.18)
Assuming a high P-correlator SNR and using (7.17), (7.33), and (A.76) yields
	
0
,
0
0
,
0
0
0
0
0
0
0
0
(Re{
})
Re
(Re{
})
2
/
(
)(
(
))
Re
(
) (
)
2
/
(
(
))
Re
2
/
(
)
(
)
Re
(
)
P
P
F
P
coh
c c
coh
c c
C
S
F
C
S
C N BT
R
i
aT
BR
C N B i
C N B
i
µ
µ
β
τ
τ
κ ω
ω
β
τ
τ κ ω
ω
κ ω
ω
β
κ ω
ω
κ ω
ω
β κ ω
ω
-
-
=
-
-
-
-
=
-
-
-
=
-
-
	
(8.19)

222 
Discriminators
As a result of the discussion in Section 1.8.5, on separation of code and carrier 
correlation,
	
0
0
0
0
0
0
2
0
(
)
(0)
(0)(
)
Re
Re
(
)
(0)
(0)(
)
(0)(
)
1
Re
Re
(
)
(0)
12
coh
freq
F
i
i
i
i T
ω
ω
κ ω
ω
κ
κ
ω
ω
β
β
κ ω
ω
κ
κ
ω
ω
κ
ω
ω
β
β
χ
ω
ω
κ
-
-
+
-
-
-
-
+
-
-
=
-
-

	
(8.20)
Consequently, the normalization constant is
	
2
12
freq
coh
i
T
β
ε
ε
χ
=
+
R
	
(8.21)
Typically, e = 0. 
The normalization constant should be increased for low P-correlator SNR to 
compensate for the second-order expected value decrease in (8.18). For high P-
correlator SNR, the expected value is
	
0
0
F
ω ω
ω
ω
-
=
-

	
(8.22)
For w = w0, the F-correlator variance is derived from 
	
2
(Re{
})
var
var
(Re{
})
(Re{
})
(Re{
})
F
F
P
P
C
S
C
S
C
S
C
S
µ
µ
µ
µ
-
=
	
(8.23)
which evaluates using (8.11) and (8.13) to
	
2
4
2
,
2
0
,
0
2
0
,
0
,
2
,
(Re{
})
var
(Re{
})
var
(Re{
})
(Re{
})
(Re{
})
var
(Re{
})
2
(0)
12
2
/
(
)
1
2
/
(
)
2
(0)
(0)
P
P
P
P
P
P
P
P
F
P
F
P
P
P
coh
c
c
freq
coh
coh
c c
coh
c c
coh
c
c
c
c
freq
coh
C
S
C
S
C
S
C
S
C
S
C
S
BT
R
T
C N BT
R
C N BT
R
BT
R
R
T
µ
µ
µ
µ
µ
µ
χ
κ
τ
τ
κ
τ
τ
χ
-
-
-
=
+
=
-
+
-
÷
=
,
2
2
0
,
0
0
,
0
(0)
1
12
/
(
)
/
(
)
P
P
P
P
c
c
coh
c c
coh
c c
R
C N T
R
C N T
R
κ
τ
τ
κ
τ
τ
÷
+
÷
-
-
	
(8.24)

8.1  Noncoherent Discriminators 
223
The Doppler-discriminator variance is finally given as
	
2
2
2
,
,
4
2
2
2
0
,
0
0
,
0
,
,
2
3
0
,
0
0
,
(Re{
})
var
(Re{
})
var
2
(Re{
})
(0)
(0)
12
1
2
12
/
(
)
/
(
)
6
(0)
(0)
1
/
(
)
/
P
P
P
P
P
P
P
P
P
P
P
F
P
c
c
freq
c
c
coh
freq
coh
c c
coh
c c
coh
c
c
c
c
freq
c c
coh
c c
coh
C
S
F
S
C
S
R
T
R
T
C N T
R
C N T
R
R
R
C N
T
R
C N T
R
µ
µ
µ
β
χ
χ
κ
τ
τ
κ
τ
τ
χ
κ
τ
τ
κ
=
÷
=
+
÷
-
-
=
+
-
2
0
(
)
P τ
τ
÷
÷
-
	
(8.25)
This formula compares to the Doppler CRLB (4.84). The variance is larger than 
the CRLB if the replica waveform does not match the received waveform or if Dop-
pler or code-phase mismatch occurs.
8.1.3  Phase Discriminator
The carrier-phase discriminator is directly derived from the P-correlator. The P- 
correlator uses as reference function
	
( )
P
P
C
c
t
∼
	
(8.26)
which is required to fulfill
	
,
(0)
0
P
c c
R
	
(8.27)
The carrier phase discriminator shall either be based on the argument of the 
complex-valued P-correlator (four-quadrant arctan) or on the two-quadrant arctan 
function
	
angle{
}
Im{
}
atan Re{
}
P
P
P
C
C
C
F =
F =
	
(8.28)
The first equation is used if the signal is not modulated with data-bit informa-
tion and the second one is used if the signal is modulated with a binary data-bit 
stream using a BPSK modulation. Both discriminators are treated identically in the 
following example.
Following the same derivation as in Section 4.3.2.8, the expected value of the 
carrier-phase discriminator is
	
0
0
ϕ ϕ
ϕ
ϕ
-
F
=
-

	
(8.29)
for high P-correlator SNR. The magnitude of the expected value reduces at lower 
SNR values. A Monte Carlo simulation of the expected value of the carrier phase 


8.2  S-Curve Shaping 
225
8.1.4  Clipping
The formulas for the proposed code-phase and Doppler discriminators involve di-
vision by the P-correlator value. Division is a mathematically unsafe operation be-
cause a division by zero may occur. On the contrary, the correlation point should 
lie within the linear region of both discriminators. 
The discriminator values can therefore be bounded by the extension of the 
linear code-phase or Doppler region (or more generally, by the maximum possible 
code-phase and Doppler difference). The discriminator values are clipped to stay 
within the mentioned thresholds. Clipping is not required for the carrier-phase dis-
criminator.
Clipping is a nontrivial assumption on the tracking-loop performance, which 
is required to keep the correlation point in the linear region. If this requirement is 
fulfilled, clipping is a useful constraint on the admissible code-phase and Doppler 
range. 
8.2  S-Curve Shaping
The formulas of the previous Section 8.1 allow computation of the code-phase, 
carrier-phase, and frequency tracking performance for a given set of reference sig-
nals. The reference signals need to fulfill the conditions (8.3), (8.16), and (8.27), 
but can otherwise be chosen arbitrarily. Most important, the waveform of the 
signals can be chosen flexibly and, by optimizing the waveform, the tracking per-
formance can be improved.
Figure 8.2  Slope of the four-quadrant carrier-phase discriminator for different SNR values.

226 
Discriminators
The method of using a flexible reference signal is tailored for the software-re-
ceiver approach. First, the software-receiver algorithms of Chapter 9 work with a 
16-bit sample resolution, allowing for the represention of sophisticated waveforms. 
By contrast, a simple hardware receiver may work with 1- or 2-bit resolution to 
represent the reference signals. Second, the generation of one P-correlator reference 
signal and of one D-correlator reference signal is sufficient for tracking in most 
applications. This corresponds to two complex-valued correlators per channel. By 
contrast, some other receiver structures need three (early, prompt, late) or five (very 
early, early, prompt, late, very late) complex-valued correlators per channel.
In the context of code tracking, the presented tracking scheme is also called a 
code-continuous reference waveform (CCRW) tracking scheme and was first in-
troduced in an article by Weill [2]. The CCRW scheme falls into the class of non-
parametric estimators because no multipath signal parameters are estimated, just 
line-of-sight signal parameters [3]. The scheme allows realization of most linear 
code discriminators, including the early–late and double-delta discriminator, being 
well known for optimum code performance with the GPS C/A-signal. Those corre-
lator types can also be applied for modernized GNSS signals using the BOC, CBOC, 
or AltBOC modulation scheme as has been pointed out in Irsigler and Eissfeller’s 
work [4]. In Section 7.6.2, the early–late discriminator was investigated for arbi-
trary signal waveforms and colored noise. As another example, the double-delta 
code-tracking reference waveform is given by
	
(
)
(
)
1
( )
(
(
)
(
))
2
2
2
D
p
p
p
p
d
d
c
t
c
t
c
t
c t
d
c t
d
=
-
-
+
-
-
-
+
	
(8.32)
assuming that cp(t) is the (infinite-bandwidth) signal waveform at baseband. Two 
prominent discriminators cannot be realized in the CCRW scheme: the early-power-
minus-late-power discriminator [1] or the BOC(n,n) side-peak cancellation technique 
[5]. Those two techniques require, however, more correlators than the CCRW.
In the following section, the code discriminator will be discussed and several 
performance criteria will be presented. A method will be outlined to choose the 
reference function for a given code-discriminator function (S-curve). The same dis-
cussion can also be carried out for phase and frequency discriminators, which will, 
however, not be discussed in this text.
8.2.1  Code-Discriminator Performance Characteristics
A code discriminator can be optimized for one or more of the following perfor-
mance criteria:
Minimum variance caused by thermal noise;
Low multipath errors;
High stability;
Linearity in the tracking region.
Furthermore, it is typically required that the code discriminator shows only one 
stable tracking point (i.e., a zero crossing with positive slope) within the range of 
admissible code-tracking errors. 


228 
Discriminators
Within the linear region, multipath errors are independent on the used correla-
tion scheme and no multipath mitigation is possible. The size of the linear region 
needs therefore to be limited to achieve lower multipath errors. On the other hand, 
a large linear region results in a high tracking stability. A trade-off between the two 
performance figures has to be done depending on the specific target application.
8.2.3  Frequency-Domain S-Curve Shaping
The definition of the code discriminator (8.4) relies on the correlation function of 
the incoming signal c(t) with a code-tracking reference signal cD(t). The correlation 
in frequency domain is written as
	
,
( )
(
)
( )
D
c c
D
R
f
c
f c
f
=
-

	
(8.35)
In the following discussion, a method will be presented that shows how the 
reference signal can be computed to achieve a desired correlation function 
, D
c c
R
. 
The desired correlation function must be known beforehand. The method will 
be illustrated for the D-correlator, but can identically be applied also for the P-
correlator, which is used to remove the carrier-phase dependency from the code 
discriminator.
The presented method relies on inverting (8.35) by dividing the cross-correla-
tion Fourier transform by the Fourier transform of the incoming signal. The division 
can only be performed for nonvanishing signal frequency components. Frequency 
components with a vanishing (or very small) signal magnitude must not be present 
in the S-curve. In other words, the S-curve and received signal need to be spectrally 
compatible in the sense that the spectral content of the signal must be sufficient to 
represent the S-curve.
The D-correlator reference signal to obtain the S-curve 
, D
c c
R
 is given by
	
,
( )
(
)
(
)
( )
0
(
)
D
c c
D
R
f
c
f
c
f
c
f
c
f
γ
γ
-
>
-
=
-

	
(8.36)
where g  is a suitable constant. 
The computation of the reference signal is straightforward and is illustrated 
here with two examples that work with discrete- and finite-length Fourier trans-
forms. The computation’s settings are summarized in Table 8.1. The method is ap-
Table 8.1  Frequency-Domain S-Curve Shaping Settings
Parameter
Value
Sample rate
16.384 MSamples/s
Fourier size
16,384
Signal time
1 ms
Spectral threshold g
10% of max. spectral magnitude
Number of bits to represent reference 
signal
4



8.3  Multipath Estimating Techniques 
231
8.2.4  Discussion
Spectral S-curve shaping is a convenient method to calculate a reference signal to achieve 
a given correlation function. It gives a stable tracking scheme (e.g., no BOC ambiguity) 
with defined multipath characteristics. One disadvantage of spectral S-curve shaping is 
that the S-curve needs to be specified for all code-phase values (not only for the region 
of interest), which eventually increases the thermal-noise variance. 
In another work, a different S-curve shaping method is described that illustrates 
how to compute the code-tracking reference function to obtain a given S-curve [7]. 
The method relies on fitting a set of shifted autocorrelation functions to the target 
S-curve. The fitting is applied only in the region of interest. This fitting problem can 
be well-solved for high-bandwidth signals. For low-bandwidth signals, the solution 
becomes unstable and the desired S-curve cannot be reproduced. For high-band-
width signals, near-optimum multipath mitigation can be achieved. For BOC sig-
nals, the pull-in range can be increased to avoid unstable tracking points. For BPSK 
signals, this method reproduces the double-delta correlator, which is known to have 
optimum multipath performance. This method has also been applied in a work by 
Paonni for the MBOC-modulation family [8]. 
Neither spectral shaping methods (spectral and fitting) take into account the 
thermal-noise performance. For example, the reference function plotted in Fig­
ure 8.5 shows almost no relationship to the PRN-code sequence and worse thermal- 
noise performance is expected. Generally, the parameters of the target S-curve (e.g., 
the size of the linear region) need to be chosen empirically to achieve good ther-
mal-noise performance. Development of a modified S-curve shaping scheme that 
also includes thermal-noise performance is currently ongoing. The resulting code 
discriminator depends on the weights put on the thermal-noise errors and the multi­
path errors to assess the total  performance.
8.3  Multipath Estimating Techniques
This section introduces a class of parametric discriminators simultaneously esti-
mating line-of-sight and multipath signal parameters [3]. The method is based on 
the complex least-square adjustment described in Appendix A.1 together with the 
correlator models of Section 7.2. The presented discriminator tries first to detect 
the presence of multipath signals in addition to the line-of-sight signal and then 
eventually adapts the number of parameters to be estimated.
The multipath-estimating discriminator is advantageous over the non parametric 
approach because of the following facts:
Multipath mitigation is applied only when needed, thereby avoiding an un-
necessary signal power loss.
Strong multipath signals (causing potentially large errors) are better detected 
and better mitigated than weak signals. A multipath power-independent per-
formance can be achieved.
Under certain assumptions, the method is theoretically optimal and naturally 
exploits the benefits of signals with a large Gabor bandwidth (e.g., modern-
ized GNSS signals). This has been demonstrated in [9].

232 
Discriminators
The method intrinsically provides multipath mitigation for the code phase, 
Doppler, and carrier phase simultaneously.
The LSQ procedure provides accuracy estimates for the discriminator values, 
which are based on the actual signal amplitude.
The major disadvantage of the presented scheme is the increased complexity. 
First, additional correlators are needed. Second, the LSQ scheme requires matrix 
operations. Within a software radio, however, both disadvantages are tolerable. 
The required additional correlators are obtained by using already-generated ref-
erence signals shifted in Doppler and code-phase direction. Thereby, the time-
consuming signal-generation process is circumvented and correlation itself can be 
performed efficiently, as will be shown in Section 9.8. The required matrix opera-
tions are performed fast because the considered processors support floating-point 
operations by hardware. The most time-consuming operation is the inversion of 
the normal matrix, which is, for one multipath signal and one line-of-sight sig-
nal, a complex 6  6 matrix. The algorithm involves a fixed number of iterations 
(maximum 1–2).
A multipath-estimating delay-lock loop was introduced in the article by van 
Nee as an unweighted correlation-function fitting procedure [10]. Here, we gener-
alize those results by using arbitrary reference waveforms, by using a full com-
plex weighted least-squares scheme, and also by allowing for Doppler estimates. 
Furthermore, practical implementation aspects are given. The presented scheme 
tries to minimize the involved computational resources (just one or two propaga-
tion paths are considered) compared to a more rigorous technique that estimates 
for many multipath parameters [11]. The presented scheme minimizes the influence 
of one strong multipath signal caused by a specular reflection. This multipath type 
may introduce high and constant biases in the pseudorange measurements, which 
are hard to reduce and have a strong impact on the navigation solution if the specu-
lar reflection is constant in time. By contrast, diffuse reflections or diffractions typi-
cally have less power and have generally a more random character. Filtering (e.g., 
a carrier- or Doppler-aided DLL) reduces the influence of diffuse or timely variable 
reflections and no multipath-estimating discriminator is needed. 
8.3.1  The LSQ Equations
To set up the LSQ equations, a parameter vector q is considered. It is used to set up 
a model of the received signal and q contains the high-rate pseudorange parameters 
of the line-of-sight signal and of the multipath signals. The parameter vector q is 
given as
	
1
1
1
(
)T
M
M
M
a
a
τ
ω
τ
ω
=
q

	
(8.38)
where m is the signal index (ranging from 1 … M), am is the complex-signal 
amplitude 
	
exp{
}
m
m
m
a
a
iϕ
=
-
	
(8.39)
tm is the code phase in seconds, wm is the angular Doppler frequency in radians 
per second, and jm is the carrier phase in radians. The code phase is defined at the 

8.3  Multipath Estimating Techniques 
233
beginning of the interval, the Doppler is constant throughout the interval, and the 
carrier-phase value jm is defined in the middle of the integration interval, corre-
sponding to a signal model 
	
1
1
(
)exp{
}
(
)exp
2
M
M
coh
m
m
m
m
m
m
m
m
T
r
a c t
i
t
a c t
i
t
µ
µ
µ
µ
µ
τ
ω
τ
ω
=
=
=
-
=
-
-
÷ 	
(8.40)
The number of multipath signals is M – 1. If no multipath signal is present, 
M = 1.
The received signal is correlated with different reference signals shifted by a 
code-phase and Doppler offset. Overall, B correlators are involved and the complex- 
correlation values are summarized in a vector C:
	
1
(
)
B T
C
C
=
C

	
(8.41)
The correlator b uses as reference signal crec
b, and the code phase at the begin-
ning of the correlation interval is t0
b. The angular Doppler frequency w0
b is constant 
during the integration interval and the carrier phase j0
b vanishes at the midpoint of 
the integration interval (note that the carrier-phase estimate is derived from am):
	
C
S
c
0
0
0
( )
,
,
,(
0)
b
b
b
b
b
rec
µ
τ
ω
ϕ
=

	
(8.42)
Using the results of Section 7.2, a functional and stochastic model of the cor-
relator values is defined that serves as the basis for the following discussion. 
The LSQ discriminator is given by a weighted fit of this model to the correlator 
values, thereby minimizing 
	
1
ˆ
argmin(
)
(
)
Q
*
-
=
-
-
q
v
q
q
q
C
C
C
C
	
(8.43)
The correlator model Cq is calculated by (7.17) and the covariance between two 
correlator values Qv is calculated by (7.24).
The LSQ equation (8.43) is linearized around the linearization point q0,
	
0
1,0
1,0
1,0
,0
,0
,0
(
)T
M
M
M
a
a
τ
ω
τ
ω
=
q

	
(8.44)
and the correlator values are modeled for the linearization point as
	
(
)
0
1
0
0
(Re{
};
)
(Re{
};
)
T
B
C
S
C
S
µ
µ
=
q
C
q
q

	
(8.45)
The differences of the true signal parameters with respect to the linearization 
point are 
	
0
D
=
-
q
q
q 	
(8.46)
and the correlator differences are
	
0
D
=
-
q
C
C
C 	
(8.47)

234 
Discriminators
For clarification, it should be noted that the LSQ discriminator involves two 
parameter sets called “points”: the correlation point and the linearization point. 
The correlation point is given by (8.42) and represents the NCO values used to 
compute the correlation values. The correlation point is kept constant throughout 
the LSQ procedure and the time-consuming correlation process needs not to be 
repeated. This is in contrast to the discussion of Section 4.3 or the MLE approach 
of Won [12]. On the other hand, the linearization point is used to linearize the cor-
relator model (7.17). The linearization point may vary during the iterations of the 
LSQ procedure. The length of the vectors representing the correlation point (equal 
to 2B) and the linearization point (equal to 3M) are different. The linearization 
point should be near the true values to ensure that the linearization is a reasonable 
approximation. Furthermore, at least one correlation point (t0
b, w0
b) should lie near 
the true parameter values.
The linearized LSQ equation is given as
	
1
(
)
(
)
min
2
A
Q
A
χ
*
-
= D
-
D
D
-
D
v
C
q
C
q
	
(8.48)
and the value of c is used to verify that the assumed model (i.e., the number of 
multipath parameters) is correct. 
Using the amplitude definition (8.39) the bth correlator value is modeled from 
(7.17) as
	
0
,0
,0
,0
0
,
,0
0
1
,0
,0
0
,
,0
0
1
(Re{
};
)
exp{
}
(
)
(
)
2
(
)
(
)
2
brec
brec
b
b
M
m
m
coh s
m
c c
b
m
m
b
M
m
coh s
m
c c
b
m
m
C
S
a
i
T
f R
a
T
f R
µ
ϕ
τ
τ
κ ω
ω
τ
τ
κ ω
ω
=
=
=
-
=
-
-
=
-
q
	
(8.49)
The design matrix takes the form
	
1
(
...
)
M
A
A
A
=
	
(8.50)
with Am as submatrices given by
	
1
1
1
0
0
0
1
0
0
0
(Re{
};
)
(Re{
};
)
(Re{
};
)
(
)
(
)
(
)
(Re{
};
)
(Re{
};
)
(Re{
};
)
(
)
(
)
(
)
m
m
m
m
B
B
m
m
m
C
S
C
S
C
S
a
A
C
S
C
S
C
S
a
µ
µ
µ
µ
µ
µ
τ
ω
τ
ω
÷
D
D
D
÷
÷
=
÷
÷
÷÷
D
D
D
q
q
q
q
q
q



	
(8.51)

8.3  Multipath Estimating Techniques 
235
The derivatives are computed with respect to the parameter improvements Dq 
and are evaluated at the linearization point. 
The derivatives are explicitly given as
	
,0
0
,
,0
0
,0
0
,
,0
0
,0
0
,
,0
0
(
)
(Re{
})
(
)
(
)
2
(
)
(Re{
})
(
)
(
)
2
(
)
(Re{
})
(
)
(
)
2
brec
brec
brec
b
coh s
m
c c
b
b
m
m
b
m
coh s
m
c c
b
b
m
m
b
m
coh s
m
c c
b
b
m
m
T
f R
C
S
a
a T
f R
C
S
a T
f R
C
S
µ
µ
µ
τ
τ
κ ω
ω
τ
τ
κ ω
ω
τ
τ
τ
κ ω
ω
ω
-
=
-
D
-
=
-
D
-
= -
-
D
	
(8.52)
The covariance between two correlator values is derived from (7.24) as
	
; ,
0
0
0
0
,
cov
(Re{
}),
(Re{
})
(
) (
)
b
c
rec
rec
b
c
b
c
c
b
b c
s
coh
c
c
Q
C
S
C
S
f T
R
µ
µ
τ
τ κ ω
ω
=
=
-
-
v
	
(8.53)
The covariance matrix is independent of the linearization point and remains 
constant throughout the LSQ iteration process. 
8.3.2  Calibration
A LSQ discriminator relies on an accurate model of the correlation values. In a real 
receiver implementation, this model has to be derived from real measurements in 
order to correctly account for the front-end filter characteristics. For example in van 
Nee’s work, correlation values of a GPS receiver are averaged to get a mean correla-
tion function [10]. Errors in the correlation model will degrade the LSQ-discriminator 
performance in terms of introduced biases and a less accurate fit. Furthermore, the 
correlator residuals might be mistaken as multipath signals. Calibrated correlator 
models are also necessary for signal-quality monitoring and correlator calibration 
can be found in Irsigler’s thesis [13].
8.3.3  General Procedure
The LSQ discriminator estimates the code phase, the Doppler, the carrier phase, and 
the amplitude from a number of correlator values. The basic equations of the com-
plex LSQ scheme are described in Appendix A.1. Unfortunately, the LSQ adjust-
ment has several caveats. The most important problem arises from the fact that the 
normal matrix becomes singular if line-of-sight and multipath delays are identical, 
as has been discussed in Section 4.3.6.
The LSQ procedure starts from given correlator values. At first, the algorithm 
assumes the presence of no multipath signal (M = 1). Using appropriate initial 
values, the LSQ adjustment is iterated for a predefined maximum number of itera-
tions or until the parameter vector converges. Then a c2-test is used to check if the 
no-multipath assumption is valid or not. If it is not, the same procedure is repeated, 
assuming this time the line-of-sight signal and one multipath signal (M = 2). 

236 
Discriminators
Especially for the case M = 2, the LSQ algorithm may diverge. This is the case 
if no multipath signal is present and the c2-test incorrectly decides for the M = 2 
hypothesis. Then, as a fallback, the M = 1 parameters are used as an estimation 
result. The correlation point must be chosen such that, for M = 1, the LSQ algo-
rithm always converges. A fallback to the M = 1 case also occurs if the estimated 
parameter variances for the M = 2 case exceed fixed-threshold values. This is done 
to avoid cases of a nearly singular normal matrix that occurs for (nearly) identical 
line-of-sight and multipath code-phase values.
It is proposed to use a complex LSQ algorithm to reduce the dimensions of 
the involved matrices by a factor of two. The complex LSQ algorithm implies that 
complex-valued code-phase and Doppler improvements are also estimated. The 
imaginary parts of these improvements are discarded when the linearization point 
is updated. 
The proposed algorithm stops at M = 2 because, for higher M values, the al-
gorithm tends to be unstable and the occurrence of more than one specular reflec-
tion is unlikely. For the M = 2 case, the algorithm identifies the line-of-sight signal 
parameters as the set of parameters having the smaller code-phase delay. Formally, 
the scheme can be extended straightforwardly for M > 2.
8.3.4  Correlator Placement
The initial code-phase and Doppler values of at least one reference signal used to 
compute the correlation values need to be near the true values for each signal. The 
tracking loop ensures that one set of correlators (the prompt correlator set) follows 
the line-of-sight signal. Other correlators that are necessary to detect and mitigate 
the multipath signal are placed around the prompt set with fixed code-phase and 
Doppler offsets. The precise placing depends on the expected multipath environ-
ment. Typically, the other correlators are delayed with respect to the line-of-sight 
correlators. 
Ideally, all correlators together form a sufficient statistic for all possible code-
phase and Doppler values, as discussed in Section 4.4. There, the multicorrelator 
approach and the first-derivative approach are described. The first-derivative ap-
proach works with triples of colocated P-, D-, and F-correlators, and each triple 
allows proper linearization of the correlator-value model within the linearity region 
around the nominal code-phase and Doppler values of the correlator triple. The 
union of all linearity regions should cover the true code phase and Doppler values 
of the line-of-sight and multipath values.
8.3.5  Initial Values
Choosing a proper LSQ initialization is important to avoid divergence problems 
in the first LSQ step. The initialization values are the first guess of the difference 
between true values and the correlation-point values. 
For the line-of-sight signal parameters, the initial code-phase and Doppler er-
rors are assumed to vanish because the tracking loop tries to follow the line-of-sight 
signal. The code-phase and Doppler values of the multipath signal are chosen ac-
cording to the position of the correlator with the maximum power (after compen-

8.3  Multipath Estimating Techniques 
237
sating for the line-of-sight signal effect). The position is chosen during the M = 1 
step after the observed-minus-computed correlator values are computed.
Initial values for the complex-signal amplitude are obtained by performing one 
LSQ step. After this step, only the complex amplitude is updated and the code-
phase and Doppler values are fixed to their initial values. After the first step, the 
code-phase and Doppler values also are updated. This initialization step ensures 
that the division by the complex amplitude to remove the carrier-phase dependency 
is done with a good signal-amplitude estimate.
8.3.6  Number of Required Iterations
From a theoretical point of view, the LSQ scheme is only optimal for high signal-
power values. This fact has some consequences on the number of LSQ iterations 
when working with nonhigh signal power. We argue that a single LSQ iteration pro-
vides generally better results than iteration of the LSQ equations until convergence.
In Section 4.7, it was shown that iterating the LSQ procedure until convergence 
does not necessarily provide improved results compared to a single iteration. The 
reason is that, for weak signals, the noise produces many minima in the cost function. 
The subsequent iteration tends to converge to one of those minima, but the further 
the linearization point drifts away from the correlation point, the more inaccurate the 
correlation model will be. Furthermore, the normal matrix diverges if the code phase 
of the line-of-sight and of the multipath signal converge with each other. 
On the other hand, a single iteration provides a numerically stable estimation 
procedure. A single iteration is also optimal if one correlation point is near the true 
values. A single iteration is also a good engineering solution. The only exception oc-
curs for the case of high signal power, where a second iteration is required to make 
the estimates unbiased. 
8.3.7  Multipath Detection
After performing the no-multipath step (M = 1), a c2-test (described in Appendix 
A.1.5) is done to verify that the no-multipath hypothesis is correct. The reader may 
ask why a test is necessary to verify the presence of a multipath because, theoreti-
cally, the M = 2 LSQ procedure should result in the no-multipath case in a vanishing 
multipath amplitude. Again, the reason lies in the fact that, for the no-multipath-
case, the M = 2 LSQ procedure tends to yield identical line-of-sight and multipath 
code-phase values, making the normal matrix diverge. 
Choosing a high significance level for the M = 1 c2-test ensures that the LSQ 
procedure also converges well for M = 2. On the other hand, a lower significance 
level can be used (to avoid cases of undetected multipath) and the nonconvergence 
of the M = 2 LSQ procedure can be used as an indicator that no multipath is pres-
ent. Then a fallback to the M = 1 parameters is used. 
It should be pointed out that the number of multipath signals (and eventually 
coarse estimates of the code phase and Doppler of the multipath signals) can also be 
obtained by other methods, like RAIM, C /N0 monitoring, and dedicated metrics. 
An excellent overview of those techniques is given in the work by Irsigler [13]. 

238 
Discriminators
8.3.8  Discussion
The presented multipath-estimating discriminator is an adaptive method to mitigate 
multipath errors and has an optimal thermal-noise performance if no multipath 
signal is present or if the multipath signal is easily detectable. If the multipath sig-
nal remains undetected, the performance is still comparable to a narrow early–late 
discriminator. The method seems not to have any disadvantage in terms of perfor-
mance compared to a nonparametric discriminator. The major drawbacks are the 
increased computational demands and the calibration efforts.
The method demonstrates also that the nonrandom parameter approach dis-
cussed in Chapter 4 does not provide an optimal estimator for arbitrary signal 
power levels if the linearity conditions are not fulfilled. The MLE or LSQ scheme 
is optimal only in the limit of infinite signal power. A typical LSQ problem is that 
the low-power multipath remains undetected. The nonoptimality also manifests 
itself as unstable LSQ iterations, especially if multipath-signal parameters are 
estimated. Many local minima of the cost function (8.43) exist. Although there 
exist methods to minimize this multidimensional function that reliably converge 
to one of these local minima [11], the estimation principle itself remains subop-
timal.
As discussed in Section 4.8, Bayesian techniques are, by definition, also optimal 
for low-signal-power values, but rely on correct stochastic-parameter (especially 
multipath) models. In the author’s opinion, this information is difficult to provide 
in practical situations, especially for multipath-signal parameters. The receiver 
must be aware of its surroundings (e.g., rural, indoor, urban). A universal mul-
tipath model would be highly desirable. The Bayesian approach also needs more 
computational resources when, for example, a particle filter is used. However, re-
sults presented by others demonstrate that the Bayesian approach may outperform 
an epoch-per-epoch LSQ estimation because it exploits the relationship between 
multipath-signal-parameter probability density functions at different epochs [14].
The LSQ discriminator and Baysian techniques rely on an accurate correlator 
model that might be difficult to obtain in a real implementation because it needs the 
receiver to be calibrated for given filters, amplifiers, and antennas.
8.4  From Discriminator Noise to Position Accuracy
This chapter provides formulas to compute variances of high-rate pseudorange es-
timates. For example, (8.14) is the code-discriminator variance and (8.25) is the 
F-correlator Doppler variance. As already mentioned, the high-rate pseudorange 
estimates are smoothed to obtain low-rate pseudorange estimates, which are then 
processed to obtain position estimates. Both steps are complex and many different 
tracking-loop algorithms exist, along with many positioning methods. They are not 
covered in this work, but there exists a canonical way to obtain the variance of the 
position solution from the high-rate pseudorange variance. This method shall be 
outlined to provide the reader with a method to evaluate the influence of various 
signal-processing techniques of the positioning solution. Furthermore, the method 
allows a simplified performance evaluation of vector-tracking stability described in 
Section 4.3.3.3.

8.3  Multipath Estimating Techniques 
239
The canonical method accounts only for thermal noise and ignores other rel-
evant error sources (e.g., unmodeled multipath, transmitter-position errors, atmo-
spheric delays, and so forth). Loop filters are characterized by their bandwidth BL 
(see Section 4.3.3.1). 
The canonical tracking-loop concept was introduced in the work by Betz and 
Kolodziejski [15]. The method was introduced to convert unsmoothed TOA esti-
mates (i.e., high-rate pseudorange estimates) into smoothed TOA estimates (i.e., 
low-rate pseudorange estimates). The conversion from low-rate pseudorange esti-
mates to positions depends on the transmitter geometry and the geometric place-
ment of the transmitters is modeled by a dilution-of-precision factor (DOP). All 
estimates are considered to be unbiased.
Following Section 4.3.3.1, let q denote a high-rate pseudorange parameter that 
is available with a rate in seconds given by Tcoh. The variance of the corresponding 
low-rate pseudorange parameter p is given by
	
var
2
var
L coh
p
B T
q
=
N
N	
(8.54)
where BL denotes the noise-equivalent loop bandwidth in hertz. This relation holds if 
0 < BLTcoh < 1; refer to the work by Kazemi for a recent discussion on tracking-loop 
stability [16]. Furthermore, the tracking loop is required to model the dynamics suf-
ficiently well so that transient errors can be ignored. 
We assume now that, for one-epoch multiple identical-variance, indepen­
dent and unbiased low-rate pseudorange estimates of the same type for different 
transmitters are available. An LSQ estimator is used to calculate a (generalized) 
position-parameter estimate (e.g., Doppler estimates might be used to obtain one 
velocity-component estimate or code-phase estimates to obtain a coordinate esti-
mate). The variance of the (generalized) position estimate is given by
	
var
DOPvar
x
p
=
N
N	
(8.55)
where the DOP factor accounts for the geometric placement of the transmitters. 
DOP factors are described in many text books of satellite navigation [17]. The DOP 
factor is the diagonal element of the parameters’ covariance matrix obtained under 
the assumption of unity low-rate pseudorange variance. 
References
  [1]	 van Dierendonck, A. J., “GPS Receivers,” in Global Positioning System: Theory and Ap-
plications, Vol. I, pp. 329–407, Parkinson, B. W., and J. J. Spilker, (eds.), Washington, D.C.: 
American Institute of Aeronautics and Astronautics Inc., 1996.
  [2]	 Weill, L. R., “GPS Multipath Mitigation by Means of Correlator Reference Waveform De-
sign,” Proc. Institute of Navigation National Technical Meeting (ION-NTM) 1997, Santa 
Monica, CA, September 14–16, 1997, pp. 197–206.
  [3]	 Kaplan, E. D., and C. J. Hegarty, (eds.), Understanding GPS: Principles and Applications, 
2nd ed., Norwood, MA: Artech House, 2006.

240 
Discriminators
  [4]	 Irsigler, M., and B. Eissfeller, “Comparison of Multipath Mitigation Techniques with Con-
sideration of Future Signal Structures,” Proc. 16th Int. Technical Meeting of the Satellite 
Division of the Institute of Navigation (ION-GPS/GNSS) 2003, Portland, OR, September 
9–12, 2003, pp. 2585–2592.
  [5]	 Julien, O., et al., “A New Unambiguous BOC(n,n) Signal Tracking Technique,” Proc. Eu-
ropean Navigation Conference (ENC-GNSS) 2004, Rotterdam, May 16–19, 2004.
  [6]	 Pany, T., and B. Eissfeller, “Code and Phase Tracking of Generic PRN Signals with Sub- 
Nyquist Sample Rates,” NAVIGATION, Journal of The Institute of Navigation, Vol. 51, 
No. 2, 2004, pp. 143–159.
  [7]	 Pany, T., M. Irsigler, and B. Eissfeller, “S-Curve Shaping: A New Method for Optimum 
Discriminator Based Code Multipath Mitigation,” Proc. 18th Int. Technical Meeting of 
the Satellite Division of the Institute of Navigation (ION-GNSS) 2005, Long Beach, CA, 
September 13–16, 2005, pp. 2139–2154.
  [8]	 Paonni, M., et al., “Looking for an Optimum S-Curve Shaping of the Different MBOC 
Implementations,” NAVIGATION, Journal of The Institute of Navigation, Vol. 55, No. 4, 
2008, pp. 255–266.
  [9]	 Ávila Rodríguez, J. Á., T. Pany, and G. Hein, “Bounds on Signal Performance Regarding 
Multipath-Estimating Discriminators,” Proc. 19th Int. Technical Meeting of the Satellite 
Division of the Institute of Navigation (ION-GNSS) 2006, Fort Worth, TX, September 
26–29, 2006, pp. 1710–1722.
[10]	 van Nee, R. D. J., et al., “The Multipath Estimating Delay Lock Loop: Approaching Theo-
retical Accuracy Limits,” Proc. IEEE Position Location and Navigation Symposium, Las 
Vegas, NV, April 11–15, 1994, pp. 246–251.
[11]	 Nunes, F. D., F. M. G. Sousa, and J. M. N. Leitao, “BOC/MBOC Multicorrelator Receiver 
with Least-Squares Multipath Mitigation Technique,” Proc. 21st Int. Technical Meeting 
of the Satellite Division of the Institute of Navigation (ION-GNSS) 2008, Savannah, GA, 
September 16–19, 2008, pp. 652–662.
[12]	 Won, J. H., T. Pany, and B. Eissfeller, “Implementation, Verification and Test Results of a 
MLE-Based F-Correlator Method for Multi-Frequency GNSS Signal Tracking,” Proc. 20th 
Int. Technical Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 
2007, Fort Worth, TX, September 25–28, 2007, pp. 2237–2249.
[13]	 Irsigler, M., Multipath Propagation, Mitigation and Monitoring in the Light of Galileo and 
Modernized GPS. University of Federal Armed Forces Munich, Werner-Heisenberg-Weg 
39, D-85577 Neubiberg, http://www.unibw.de/unibib/digibib/ediss/bauv, 2008.
[14]	 Lentmaier, M., et al., “Dynamic Multipath Estimation by Sequential Monte Carlo Meth-
ods,” Proc. 20th Int. Technical Meeting of the Satellite Division of the Institute of Naviga-
tion (ION-GNSS) 2007, Fort Worth, TX, September 25–28, 2007, pp. 1712–1721.
[15]	 Betz, J. W., and K. R. Kolodziejski, “Extended Theory of Early-Late Code Tracking for a 
Bandlimited GPS Receiver,” NAVIGATION, Journal of The Institute of Navigation, Vol. 
47, No. 3, 2000, pp. 211-226.
[16]	 Kazemi, P. L., “Optimum Digital Filters for GNSS Tracking Loops,” Proc. 21st Int. Tech-
nical Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 2008, 
Savannah, GA, September 16–19, 2008, pp. 2304–2313.
[17]	 Hofmann-Wellenhof, B., H. Lichtenegger, and E. Wasle, GNSS: Global Navigation Satellite 
Systems: GPS, GLONASS, Galileo & More, Vienna: Springer, 2008.

241
C H A P T E R  9
Receiver Core Operations
Within a GNSS SDR, there are a few operations that consume most of the process-
ing power. They shall be described and analyzed in the following chapter. A specific 
characteristic of the core operations is that their implementation needs fixed-point 
arithmetic to run efficiently. By contrast, calculation of the navigation solution or 
tracking-loop update (just to name two examples) can be done with the full floating- 
point power available to the processor. Furthermore, the core operations run within 
a one-dimensional loop and are, from the algorithmic point of view, rather simple. 
In some sense they represent a heritage from GNSS hardware receivers. An im-
portant exception in this context is the use of Fourier techniques in a GNSS SDR. 
Fourier techniques are more complex from the algorithmic point of view and may 
also be implemented with floating-point arithmetic.
It should also be mentioned that the choice of the algorithms is, in some sense, 
specific to the SDR implementation developed at the University of Federal Armed 
Forces (Munich/Germany), but approaches used by other research institutes are 
also discussed.
9.1  Test-System Configuration
Implementation of core algorithms is always, to a certain extent, platform-specific. 
The platform determines the optimal implementation strategy and determines how 
much performance can be expected. The performance measurements shown in the 
next sections are based on a system shown in Table 9.1.
The system is a laptop that was purchased at the beginning of 2006. It is a 
single-core CPU system based on Intel’s Netburst architecture. This architecture has 
already been replaced by the Core 2 Duo architecture at the time of this writing.
The benchmark results and power consumption of the test system have been 
partly obtained by a tool from SiSoftware [1]. At the time of this writing, single-
CPU systems with multiple cores (e.g., quad-core processors) were already available 
whose main memory bandwidth outperformed the presented system by a factor 
of four and whose integer-processing performance was 24 times faster but whose 
power consumption was also five times higher. 
A detailed performance analysis of the core algorithms was obtained by using 
the run-time analysis tool by Intel that provides the number of clock ticks a single 
CPU instruction needs during execution [2]. It should be noted that those numbers 
are estimated based on CPU internal timer readings and are reproducible only on 
the test-system configuration. Even in this case, a slight variation of the estimated 
number of clock ticks is common.

242	
Receiver Core Operations
9.2  Signal-Sample Bit Conversion
Spread-spectrum navigation signals within a SDR are usually represented by integer 
samples of a given bit size. The term “signals” refers to both the received naviga-
tion signal(s) and the internally generated signals. Usually a low number of bits is 
sufficient to represent those signals. For example, in Section 6.1 it is stated that 
received GNSS signals can be represented with a loss of 0.2 dB by using 3 bits in the 
absence of interference. Internally generated sine/cosine carriers can be represented 
by a 1-bit amplitude (i.e., essentially as a square wave) causing a loss of 0.9 dB.
There are, however, two hardware-related factors that determine more rigor-
ously how many bits shall be used to represent the signals. They are:
Bits provided by the ADC or maximum bandwidth of the ADC to CPU data 
link;
Integer formats supported by the CPU’s vector instructions.
The first factor usually limits the number of bits to less than four (see Table 
2.1). Only in special cases (e.g., if a commercial ADC board is used) may the SDR 
be forced to work with a larger number of input bits (e.g., 8, 14, or 16 bits are 
common COTS ADC board formats that would allow it to cope with high-power 
interference). The bit format provided by the ADC card may not use a two’s- 
complement format, which is the CPU internal format. For example, sign/magni-
tude formats are commonly used ADC output formats. 
The second factor is specific for the CPU and the algorithms used for correla-
tion. For example, CPUs supporting the SSE-SSE4 instructions allow efficient mul-
tiplication of two 16-bit numbers 8-wise in parallel. Another method for signal 
multiplication works most efficiently if both signals are represented as 1-bit values. 
Then a simple XOR operation can be used to multiply two 1-bit numbers 128-wise 
in parallel with SSE/MMX instructions.
Table 9.1  Test-System Configuration 
Parameter
Test System (Laptop)
Highest Values from [1]
Computer model
Dell Inspirion 9300
—
CPU
Intel Pentium M (780)
—
Number of cores
1
4
CPU architecture
IA-32
—
CPU clock speed
2.26 GHz
—
Main memory
1 GB
—
L1/L2 cache bandwidth
23 GB/s resp. 11 GB/s
330 GB/s resp. 85 GB/s
L1/L2 (data) cache size
32 kB, resp. 2 MB
128 kB, resp. 4 MB
Main memory bandwidth
2.5 GB/s
10.2 GB/s
CPU power consumption
5–27W
140W
CPU chip technology
90 nm
—
Battery capacity
80 Wh
—
Battery weight 
461g
—
External electrical power  
consumption in idle mode
34W
—


244	
Receiver Core Operations
9.2.2  Numerical Performance
The following reference-assembler implementation on the chosen test system is 
shown in Table 9.2 and is based on Figure 9.1. It demonstrates the conversion of 
2-bit values into 16-bit values. Within the input stream, each byte contains, on the 
four LSB positions, two 2-bit values. The upper four bits are ignored as they belong 
to a different input stream (e.g. to a different GNSS-frequency band). The two 2-bit 
values are converted into two 16-bit values in one step. The 16-bit values are rep-
resented as one 32-bit value. The algorithm runs in a one-dimensional loop and in 
each step one input byte is read and the corresponding 32-bit output value is stored 
in the output signal. 
The assembly code of Table 9.2 shows only the core part and must be initial-
ized. The CPU register eax is initialized in a way that eax points to the beginning 
of the input stream. The register ebx is set to “-length,” where length is the number 
of bytes of the input stream. The register edx points to the beginning of the output 
stream, and ecx points to the lookup table. The lookup table consists of 256 values 
and each value is represented by 32 bits (i.e., by the two 16-bit output values). The 
indices of this table are the 8-bit input values and it should be noted that only the 
four lower bits count. Consequently, the 256 32-bit output values take only 16 pos-
sible values. 
Table 9.2 shows that one loop cycle takes 10.96 clock ticks on the test system. 
Within one cycle, two values are converted; assuming a CPU clock frequency as 
shown in Table 9.1, 412 Msamples can be converted per second. This value is com-
parably low, especially if a triple-frequency GNSS SDR with 40.96 MHz sample 
rate is considered. In this case, 122.88 Msamples per second have to be converted 
and the conversion itself (which is a more or less trivial operation) consumes 28% 
of the maximum CPU processing load of the test system. Table 9.1 also demon-
strates that the most time-consuming (or clock-tick consuming) instruction is the 
lookup operation, which needs 7.81 clock ticks on average. Overall, the CPU is not 
able to pipeline the loop sequence well, nor is the compiler able to generate vector-
ized code. The lookup table itself can be kept in the CPU’s L1 cache, but the input 
and output streams have to be read/written from/to the main memory. 
Table 9.2  Assembly Language Code Snippet for Bit Size Conversion 
Instruction
Description
Clock Ticks
loop_begin:
movzx esi, BYTE PTR 
[ebx+eax+length]
Load next input 8-bit value into esi
0.98
mov esi, DWORD PTR [ecx+esi*4]
Perform lookup table operation.  
The register esi is the index of the  
table and it also receives the lookup  
table values
7.81
mov DWORD PTR [edx], esi
Store resulting 32-bit value  
contained in esi in the  
output stream
1.03
add edx, 4
Advance output stream by 32 bit
1.14
add ebx, 1
Advance input stream by 8 bit
—
jne loop_begin
go to beginning of loop, if ebx != 0
—
Total of clock ticks
10.96
Number of instructions
6

9.3  Resampling	
245
9.2.3  Discussion and Other Algorithms
The bit conversion is trivial from the mathematical point of view and therefore 
no further analysis is needed. Also, no precision is lost when the number of bits is 
increased. 
The case of bit reduction occurs when, for example, 8-bit values from a com-
mercial ADC card are packed and stored as 1-bit values. In this case, the sign-bit 
from the 8-bit values is taken and eight sign-bits are combined into one byte. The 
lookup-table approach is not applicable in this case because of the fact that it would 
need a huge (i.e., 64-bit-long) table index and eventually explicit programming 
would need to be used. The more general case of m-bit to n-bit bit reduction is also 
trivially realised by taking the upper n-bits of the m-bit value if both values use the 
sign/magnitude representation and the sign bit is the MSB. 
9.3  Resampling
An efficient way of generating reference signals in a navigation SDR is to store 
precomputed signals in memory and to resample them to the sample rate actually 
needed. Typically, sine/cosine signals need to be generated, along with the PRN-
code sequence and more general reference signals (see Section 8.2).
Because of time constraints, typically nearest-neighbor resampling is used be-
cause the amplitude accuracy of the reference signals is not very high. Remem-
ber that sine/cosine signals can be represented as 1-bit signals, which are square 
waves.
9.3.1  Algorithm
The algorithm investigated in the following section mimics a hardware-receiver-
like NCO structure. The NCO is represented as a 64-bit-long variable whose up-
per 32-bits act as an index to the precomputed signal table and whose lower 32-bit 
values define the NCO phase and NCO-rate resolution. The algorithm (which is 
depicted in Figure 9.2) is initialized with the start-NCO value and the NCO incre-
ment. The algorithm runs in a loop for the required number of samples and, for 
each loop iteration, the lookup-table entry corresponding to the index given by 
the upper 32 bits of the NCO value is stored in the output stream. Afterwards, the 
NCO value is incremented by the NCO increment value and the next loop itera-
tion starts. 
The algorithm generates a signal with a constant rate (e.g., constant Dop-
pler). If time-variable rate signals are needed, it is recommended to approximate 
those signals by piecewise constant rate signals simply for numerical performance 
reasons. 
9.3.2  Numerical Performance
In Table 9.3 an optimized-assembler implementation of the algorithm depicted in 
Figure 9.2 is given for the test system of Table 9.1. The routine is initialized with 


9.3  Resampling	
247
denote the sample rate of the signal to be generated in 1/sec. The values of the pre-
computed lookup table shall be denoted as “value” and this term may represent a 
PRN-code sample or a sine/cosine value. It is common practice to store the refer-
ence signals “over sampled” [i.e., a single chip of a PRN code or a complete sine 
period is usually represented by a fixed number of (multiple) values]. This shall be 
denoted by the equation
	
#values
#samples
o
=
	
(9.1)
where o denotes the oversampling factor. Here, “samples” stands either for “chip” 
or for “cycles.” 
The NCO-phase resolution is determined by o and by the number of bits in 
the lower part of the NCO (in the above example, 32) but which will now be 
denoted as m for the sake of generality. The NCO resolution in [samples] is given 
by
	
1
(2
)
mo
φ
D
=
	
(9.2)
Because the NCO increment is an integer multiple of the NCO resolution, the 
NCO rate resolution in samples per second is given by
	
2
s
m
f
o
φ
D
=
	
(9.3)
For example, if a precomputed sine/cosine table is stored as a table of o = 256 
values (containing exactly one period), then the presented algorithm allows a phase 
Table 9.3  Assembly Language Code Snippet for Nearest-Neighbor Resampling 
Instruction
Description
Clock Ticks
loop_begin:
mov ebp, DWORD  
PTR [edx+ebx*4]
Retrieve value from lookup table. 
The register [edx] points to beginning 
of lookup table, ebx is the index
0.98
add esi, eax
Increment the lower 32 bits of NCO 
value stored in esi (eax contains the 
lower 32 bits of the increment)
1.33
mov WORD PTR [ecx], 
bp
Store 16-bit value in output stream
0.54
mov ebp,  
DWORD PTR  
[no_samples]
Load frame length (multiplied with 2) 
into ebp
1.04
adc ebx, edi
Increment upper 32 bits of NCO 
value stored in ebx (edi contains the 
upper 32 bits of the increment)
0.64
add ecx, 0x2h
Increment output sample index 
0.83
cmp ecx, ebp
Check if end of frame is reached
0.19
jb loop_begin
If not, go to beginning of loop
0.09
Total of clock ticks
5.64
Number of instructions
8

248	
Receiver Core Operations
resolution of 9.1  10–13 cycles, which is, for most applications, sufficiently high. 
For an exemplary sample rate of 40.96 MHz, the NCO-rate resolution evaluates to 
37 mHz. If a 16-bit NCO fine resolution had been used, then the NCO-rate resolu-
tion would evaluate in this case to 2.44 Hz, which could cause significant distor-
tions in GNSS frequency tracking.
For PRN-code generation, a typical example might be to store the PRN-code 
sequence (or derived reference signals) with an oversampling factor of o = 20. 
This is, for example, required to achieve a d = 0.1 early–late narrow correlator. 
The corresponding 32-bit NCO code-phase resolution is then 1.2  10–11 chip. If a 
sample rate of 40.96 MHz is again considered, the NCO-rate resolution evaluates 
to 0.00048 chip/s. Assuming a C/A-code chip length of 293m, this corresponds to 
a range-rate resolution of 14 cm/s. 
9.3.4  Discussion and Other Algorithms
Resampling of signals is a potential bottleneck in a GNSS radio, as has been dem-
onstrated above. Again, this results from the inability of the CPU to support ef-
ficient lookup-table operations. Other methods to generate the reference signals 
(e.g., either by direct trigonometric floating-point functions for sine/cosine signals, 
or realization of linear-shift registers for PRN-code generation in assembler) are, 
however, much more inefficient. 
In the presented algorithm, the output values are 16-bit values and storing them 
in memory is quite efficient. By contrast, if reference signals are represented by 1-bit 
values packed into bytes, then the single bits (looked up from the lookup table) need 
to be shifted via bit operations into a CPU register. If the register is filled with the 
required number of bits (e.g., 8), it is then written into the main memory.
The most efficient way to solve the resampling problem is to store the signals 
already with the required sample rate. Then the required parts of the resampled 
signal can be simply copied. In the case of the packed 1-bit signal representation, 
there exists, however, another problem. Because direct bit access is not possible, the 
minimal access unit is one byte. Consequently, the signal to be generated needs to 
be aligned to eight values with the precomputed signal. The precomputed signal is 
stored eight-wise, each copy shifted by one 1-bit (i.e., one value) with respect to its 
predecessor. 
9.4  Correlators
Correlators are fundamental for a GNSS SDR because they define a sufficient statis-
tic and all parameter estimates derive from them (see Section 4.4). Computationally, 
they represent a dot-product operation written as
	
1
0
N
i i
i
C
s r
-
=
=
	
(9.4)
The two vectors si and ri may, for example, represent the incoming-IF signal and 
the internally generated reference signal.

9.4  Correlators	
249
9.4.1  SDR Implementation
Fortunately, the dot-product operation is essential to multimedia applications and 
modern CPUs do support specific commands to vectorize this operation. For ex-
ample, in the SSE2 command set of the Pentium M, the command pmaddwd can 
be found, which combines the multiplication and addition into one command. It 
multiplies eight 16-bit values element-wise with another eight 16-bit values. Two 
of the resulting 32-bit products are added and, finally, four 32-bit products are 
stored in a CPU register (which is a special XMM vector register being 128 bits 
wide). 
The implementation shown in Table 9.4 of the correlation is a direct applica-
tion of the command pmaddwd. Before running the routine, the register edi points 
to the beginning of the first signal and esi points to the beginning of the second 
signal. The register eax is initialized to zero and ebx contains the length of the cor-
relation (i.e., N). The vector register xmm0 (which contains four 32-bit values) is 
set to zero at the beginning and contains the four partial sums of the correlation 
result C after the routine ends. Those four partial sums have then to be added to 
obtain C.
Table 9.4 shows that one loop iteration takes 15.07 CPU cycles on the test 
system. Eight values of the first signal are correlated with eight values of the sec-
ond signal within one iteration. Assuming a CPU clock frequency as shown in 
Table 9.1, 2  1,200 Msamples can be correlated per second. Here, we assume that 
the first signal is kept within the L1 CPU cache, whereas the second signal is read 
from the main memory. If both signals can be read from the L1 CPU cache, one 
loop iteration takes 4.69 clock ticks, resulting in a correlation capacity of 3,855 
Msamples/s. For this case, the clock ticks of the single instructions are written 
within parentheses in the last column of Table 9.4.
The reciprocal throughput (i.e., the minimum number of clock cycles per in-
struction) for the Intel Netburst architecture is reported to be 1 for the paddd, 2 
for the pmaddwd, and 1 for the movdqa command [3]. For the Intel Core 2 Duo 
architecture, these values reduce to 0.5, 1, and 1, respectively. 
Table 9.4  Assembly-Language Code Snippet for Correlation 
Instruction
Description
Clock Ticks
loop_begin:
movdqa xmm1, XMMWORD PTR 
[edi+eax*2]
Load next eight 16-bit values of signal 1 
into register xmm1
0.96 (1.06)
pmaddwd xmm1, XMMWORD PTR 
[esi+eax*2]
Multiply (and partly add) xmm1 with 
next eight 16-bit values of signal 2. The 
result are four part sums, each 32-bit, 
stored in xmm1
0.01 (0.08)
paddd xmm0, xmm1
Add part sums of xmm1 to xmm0
12.19 (2.19)
add eax, 0x8h
Increment signal index by eight values
1.19 (0.47)
cmp eax, ebx
Check if end of signal is reached
0.59 (0.80)
jb loop_begin
If not, jump to loop begin
0.13 (0.09)
Total of clock ticks
15.07 (4.69)
Number of instructions
6

250	
Receiver Core Operations
In cases where the second signal is read from main memory, the bottleneck is 
again the memory-bus bandwidth. Table 9.1 reports a value of 2.5 GB/s, which ex-
plains the fact that the correlation is limited by 1,200 Msamples/s. For a correlation 
speed of 1,200 Msamples/s, a number of 2.4 GB has to be transferred from the main 
memory to the CPU as each sample of the second signal is 2 bytes long.
9.4.2  Discussion and Other Algorithms
From Table 9.4, it is evident that the performance of the presented correlation algo-
rithm heavily depends on whether the signals are read from main memory or if they 
are already within the CPU caches. A factor of nearly three is gained. Therefore, 
one of the key issues in a GNSS SDR is to organize the data flow such that the CPU 
caches are exploited efficiently. 
Another algorithm published for PC-based GNSS SDR in an article by Ledvina 
proposes the already-mentioned approach to work with a 1-bit sample representa-
tion [4]. This bit effectively corresponds to the sign of the signal sample (e.g., a 0 
corresponds to a negative sign, a 1 to a positive sign). The advantage of doing so is 
that the multiplication of two 1-bit values boils down to a xor operation, as can 
be seen from Table 9.5. 
The Intel Netburst Archicture supports the command pxor, which allows per-
forming an xor operation with two 128-bit registers with a throughput of two 
cycles, the Intel Core 2 Duo should give a throughput of 0.33 [3]. For the case of 
the Intel Core 2 Duo, on average for each CPU clock tick 2  384 1-bit values can 
be multiplied with each other. Those values have to be loaded from memory, but 
for the packed 1-bit representation the load on the memory bus is considerable 
lower than for the 16-bit representation. A little trickier is the addition of the 1-bit 
product values. Here, two efficient approaches are possible. The first approach uses 
explicit CPU commands that count the number of “1” bits in a register. Such com-
mands have become available recently with the introduction of the SSE4 command 
set in Intel and AMD CPUs. The second approach subdivides the 128-bit register 
into eight 16-bit values. Each 16-bit value acts as an index of a lookup table, whose 
entries correspond to the number of “1”-bits of the 16-bit index values. By doing so, 
the sum of sixteen 1-bit values can be performed with one lookup-table operation. 
Comparing the 16-bit approach with the 1-bit approach a few important differ-
ences are noted. The 1-bit approach shows its biggest advantage in the high mem-
ory bus efficiency and fully exploits the efficient correlation by a xor command. 
The biggest disadvantage of the 1-bit approach is the cumbersome data handling. 
The 16-bit approach allows a convenient realization of high-end signal-processing 
algorithms with minimum implementation losses; the correlation can be performed 
well, but the memory bandwidth demands are high. 
Table 9.5  Definition of the xor Operation
A
B
xor(A,B)
0
0
1
0
1
0
1
0
0
1
1
1

9.5  Fast Fourier Transform	
251
9.5  Fast Fourier Transform
Fast Fourier transform techniques are mostly used in a GNSS SDR for signal ac-
quisition and exploit the convolution theorem. In fact, they are essential in a SDR 
for acquisition, allowing the realization of a large number of effective correlators 
needed for fast and sensitive acquisition. However, signal-preprocessing or postcor-
relation FFT tracking algorithms also benefit from an efficient FFT implementa-
tion. In contrast to the other core algorithms above, FFT implementations can be 
complex, but because they are used for myriads of other applications, very efficient 
libraries exist [2, 5]. Therefore, in this chapter no assembler language snippet is 
presented and performance benchmarks are based on the library [2]. On the other 
hand, the use of Fourier techniques for correlation can be quite tricky and optimiza-
tion at the algorithmic level will be shown in the following section.
9.5.1  Algorithm
The FFT is a widely known algorithm for efficiently evaluating a DFT. For the fol-
lowing example, we assume that the DFT is defined as
	
1
0
exp
2
FFT{
}
N
k
n
k
n
n
nk
s
s
i
s
s
N
π
-
=
=
-
=


	
(9.5)
where sn is the time domain representation of a signal of length N and ks  is the 
frequency-domain representation. The idea of the FFT became popular with the 
publication by Cooley and Tukey, but had already been discovered by C.F. Gauß in 
1805 [6]. It is based on the following identity
	
/ 2 1
/ 2 1
2
2
1
0
0
/ 2 1
/ 2 1
2
2
1
0
0
2
(2
1)
exp
2
exp
2
2
2
exp
2
exp
2
exp
2
N
N
k
m
m
m
m
N
N
m
m
m
m
mk
m
k
s
s
i
s
i
N
N
mk
k
mk
s
i
i
s
i
N
N
N
π
π
π
π
π
-
-
+
=
=
-
-
+
=
=
+
=
-
+
-
=
-
+
-
-

	
(9.6)
The DFT of (9.5) is written as two DFTs whose individual length is half of the 
original length. The first DFT is called even DFT (as it operates on elements with 
even indices), the second one is called odd DFT. Both vectors are scaled and added 
together to get the initially required DFT result (this is usually called a butterfly 
operation). The process of splitting the large DFT into two smaller DFTs can be 
recursively repeated, ending in an efficient FFT algorithm. The use of FFT tech-
niques is widespread and explained in many textbooks (e.g., [7]). A more detailed 
explanation shall not be given here. It should be noted that although mixed-radix 
DFT algorithms exist, the use of a radix-2 algorithm as presented above is still the 
most common implementation. Consequently, the vector length N needs to be an 
integer power of two.
It is a common practice to assume that the calculation of an FFT of size N needs 
	
2
#
5
log
FFT
Ops
N
N
=
	
(9.7)

252	
Receiver Core Operations
operations, which could either be multiplications or additions [5]. Modern desktop-
PC CPUs can perform multiplications with the same speed as additions. 
9.5.2  Convolution Theorem
Although very basic, the convolution theorem for a finite size DFT shall be repeated 
here as it is of utmost importance for the following sections. Referring to (9.5), the 
inverse DFT is defined as
	
1
0
1
1
exp 2
IFFT{
}
N
n
k
n
k
k
nk
s
s
i
s
s
N
N
N
π
-
=
=
=

 	
(9.8)
It is well known that the following identify holds
	
1
,0
0
exp 2
N
k
n
nk
i
N
N
π
δ
-
=
=
	
(9.9)
where dk,l is the Kronecker delta, which evaluates to one if k = l or otherwise to 
zero. If we assume periodic signals s and r; that is,
	
n aN
n
s
s
a
+
=
Z	
(9.10)
and similarly for r, then we can write a circular correlation function as
	
1
1
1
2
0
0
,
0
1
1
2
,
0
0
1
,
2
,
0
1
0
1
2
exp
(
(
))
1
2
2
exp
exp
(
)
1
2
exp
1
2
exp
N
N
N
m
n n m
k l
n
n
k l
N
N
k l
k l
n
N
k l
k
l
k l
N
k
k
k
i
h
s r
s r
nk
l n
m
N
N
i
i
s r
ml
n k
l
N
N
N
i
s r
ml N
N
N
i
s r
mk
N
N
π
π
π
π
δ
π
-
-
-
+
=
=
=
-
-
=
=
-
-
=
-
-
=
=
=
+
+
=
+
=
=
-
=
 
 
 
 
1
0
1
2
exp
N
k k
k
i
s
r
mk
N
N
π
-
-
=


	
(9.11)
The Fourier transform of the correlation values hm is thus given by
	
k
k k
h
s
r
-
=

  	
(9.12)
The DFTs of the signals s and r are also periodic in the sense of 
	
k aN
k
s
s
a
+
=


Z	
(9.13)




256	
Receiver Core Operations
be applied it allows reduction of the FFT size by a factor of two compared to zero 
padding.
9.5.4  Spectral Shifting
If one of the frequency-domain signal representations (here, e.g., kr ) is circularly 
shifted prior to the multiplication, the correlation function, including a defined 
frequency offset, is obtained. 
Referring to (9.12), the shifted spectra kr  is defined as
	
( )
SHIFT { }
k
p
k
k p
r
p
r
r +
=
=



	
(9.19)
and the inverse FFT evaluates to
	
1
1
0
0
1
1
0
0
1
1
( )
( )exp 2
exp 2
1
(
)
1
exp 2
exp
2
exp 2
exp
2
n
k
k p
k
k
k
k
k
k
n
nk
nk
r
p
r
p
i
r
i N
n k
p
np
nk
r
i
i
r
i
np
i
r
π
π
π
π
π
π
L-
L-
+
=
=
L-
L-
=
=
=
=
L
L
L
-
=
=
-
L
L
L
L
L
=
-
L




	
(9.20)
where L is the used IFFT size. The value of L depends on whether zero padding 
or circular correlation is used. Thus, the spectrally shifted signal (9.19) in the fre-
quency domain corresponds to the signal multiplied with a complex sine/cosine 
carrier in the time domain. 
The method of spectral shifting can be applied to a zero-padding or a circular-
correlation correlator. Spectral shifting modifies both techniques, as shown by the 
block diagram in Figure 9.6.
The obtained correlation function finally evaluates to
	
1
1
0
0
1
( )
IFFT{FLIP{FFT{
}}SHIFT {FFT{
}}}
(
)
( )
exp
2
m
n
p
n
N
N
n n m
n n m
n
n
h
p
s
r
n
m p
s r
p
s r
i
π
-
-
+
+
=
=
= L
+
=
=
-
L
	
(9.21)
Figure 9.6  Frequency-domain correlator with spectral shifting.


258	
Receiver Core Operations
The inverse-Fourier transform of the block-averaged spectrum dκ  evaluates to
	
1
2
1
2
2
1
2
1
1
1
0
(
1)
1
1
1
2
1
0
(
1)
1
1
1
0
1
1
0
1
exp 2
1
1
exp 2
1
( )
exp 2
1
( )
exp 2
m
k
k
k
k
k
k
m
d
d
i
m
h
i
m
k
h
i
m
k
h
i
κ
κ
κ
κ
κ
κ
κ
κ
κ
π
κ
π
κ
π
κ
π
L -
=
+
L -
L -
=
= L
+
L -
L -
=
= L
L-
=
= L
L
= L
L
L
= L
L
= L
L




	
(9.24)
where the relationship of κ to k is given by 
	
2
( )
k
k
κ
=
L
	
(9.25)
The symbol   denotes the largest integer smaller than the containing number 
(i.e., the floor operation). The inverse FFT can be further written as
	
1
1
0
1
,
0
1
( )
exp 2
1
exp 2
m
k
k
block m
k
k
k
k
k
d
h
im
mk
h
i
κ
π
π
L-
=
L-
=
=
-
+
÷
L
L
L
L
= L
L


	
(9.26)
with 
	
,
1
2
1
2
2
exp
( )
2
exp
fract
block m
k
k
k
im
k
h
h
k
im
k
h
π
κ
π
=
-
-
÷
L
L
=
-
÷
L
L



	
(9.27)
The function fract gives the fractional part (between zero and one) of a real 
number. In the above equations, the factors m/L1 and fract(. . .) are both between 
zero and one. The difference of the block-averaged spectrum to the original spec-
trum depends on m and is a slowly varying complex sinusoidal given as
	
1
2
2
exp
fract
m
k
im
k
b
π
=
-
÷
L
L

	
(9.28)


260	
Receiver Core Operations
“spectrum” has a sharp peak (the peak of the correlation function) that indicates 
a band-limited “waveform” and it is possible to filter the waveform and reduce its 
sample rate without significant information loss.
The advantage of this method is that the computational burden is reduced at 
least by a factor of L2 and it may find its applications for assisted acquisition (if the 
code phase search range can be limited) and for frequency-domain tracking (where 
only correlation values around zero Doppler are needed).
9.5.6  Circular Correlation with Doppler Preprocessing
In case the signal r is periodic (as defined in Section 9.5.3.2) and if M is an integer 
multiple of the signal period, the circular correlation approach of Section 9.5.3.2 
can be substantially simplified. This was first observed for the GPS C/A-code signal 
by Akopian [9] and processing load reductions of the order of the periodicity (i.e., 
maximum 20 in the case of the GPS C/A-code) can be obtained [10].
To apply this method, it is assumed that the value M can be written as
	
1
2
1
2
,
M
M M
M M
=
N	
(9.30)
where M1 is the period in samples of the signal r and M2 is the number of periods 
contained in r. In the case of the GPS C/A-code signal, a period contains 1,023 PRN 
code chips; this period is represented (using resampling) by M1 samples. An efficient 
choice for M1 is 211 or 212 to allow FFT techniques. A typical GPS C/A-code value 
for M2 is 8 to reduce the number of cases with a correlation over a data bit bound-
ary. Time-domain index values are split up in the following way
	
2
1
1
2
1
1
1
{0, . . . ,
/
1},
{0, . . . ,
1}
n
n M
n
n
M M
n
M
=
+
-
-
	
(9.31)
and frequency-domain index values as
	
2
1
2
1
1
1
1
{0, . . . ,
/
1},
{0, . . . ,
1}
M
k
k
k
k
M M
k
M
M
=
+
-
-
	
(9.32)
An index of type k1 is called coarse frequency index, an index of type k2 is 
called fine frequency index. 
With these settings, the periodicity of r is expressed as
	
2
1
1
1
n M
n
n
r
r
+
=
	
(9.33)
The Fourier transform of r simplifies to 
	
1
1
1
1
2
2
1
1
1
2
1
1
1
1
2
1
2
1
1
1
1
2
1
1
1
2
1
0
0
1
1
2 2
1
1 1
1 2
1
0
0
1
1 1
1 2
,0
1
1
0
2
exp
(
)
2
exp
exp
2
M M
M
k
k M M
k
n M
n
n
n
M M
M
n
n
n
M
k
n
n
i
M
r
r
r
n M
n
k
k
M
M
i
M
r
n k M
n k
n k
M
M
M
n k
n k
r
i
M
M
M
M
M
π
π
δ
π
-
-
+
+
=
=
-
-
=
=
-
=
=
=
-
+
+
÷
=
-
+
+
÷
=
-
+
÷
=


1
2
1
1
1
1 1
,0
1
1
0
exp
2
M
k
n
n
n k
r
i
M
δ
π
-
=
-
÷
	
(9.34)

9.5  Fast Fourier Transform	
261
where (9.9) has been used to obtain the third line. As the whole expression of the 
third line is multiplied with a Kronecker delta, the value of k2 can also be set to zero 
inside the exponential function. Overall, the equation states that the Fourier trans-
form of a periodic signal has nonvanishing components only for a fine frequency 
index k2 = 0. The spectral-shifted signal obtained by applying (9.19) to the periodic 
signal r is written as
	
1
1
1
1
2
2
2
2
1
1
1
1
1
1
(
)
,0
1
1
0
(
)
exp
2
M
k p
k
p M M
k
p
k
p
n
n
M
n k
p
r
r
r
i
M
M
δ
π
-
+
+
+
+
+
=
+
=
=
-
÷


	
(9.35)
The spectral-shifted circular FFT of (9.21) evaluates for a periodic signal r to
2
1
1
1
1
1
1
2
1
1
1
2
2
1
2
1
1
2
1
1
(
)
2
1
1
1
2
1
0
0
( )
(
)
1
2
exp
(
)
m
m M
m
M M
M
k M M
k
k
p M M
k
p
k
k
h
p
h
p M M
p
i
M
s
r
m M
m
k
k
M
M
M
π
+
-
-
-
-
+
+
+
=
=
=
+
=
+
+
÷


	
(9.36)
where only the first line of (9.21) has been rewritten using the index convention for 
periodic signals. Inserting (9.34) yields
2
1
1
1
1
1
1
1
2
2
2
1
1
2
1
1
1
2
1
1
1
2
1
1
1
,0
1
0
0
0
1
1
1
2
1
1
1
2
1
1
1
1
1
2
1
1
1
2
1
1
1
( )
(
)
1
(
)
(
)
exp
2
1
(
)
(
)
exp
2
m
m M
m
M M
M
M
k M M
k
k
p
n
k
k
n
k M M
p
n
h
p
h
p M M
p
M
s
r
M
M
n k
p
m M
m
M
i
k
k
M
M
M
n k
p
m M
m
M
s
r
i
k
p
M
M
M
M
δ
π
π
+
-
-
-
-
-
+
=
=
=
-
+
=
+
=
+
+
-
-
+
÷÷
+
+
=
-
-
-


1
1
1
1
1
1
1
1
2
1
1
1
1
1
0
0
1
1
1
1
1
1 1
2
2
1
1
1
1
1
0
0
1
(
)
(
)
exp
2
M
M
k
n
M
M
k M M
p
n
k
n
n k
p
m k
p m M
m
s
r
i
M
M
M
M
π
-
-
=
=
-
-
-
+
=
=
÷÷
+
+
=
-
-
+
÷

	
(9.37)
The Fourier transform of the signal s (which is, in general, not periodic with a 
periodicity of M1) obtained with the index convention of periodic signals is given 
as
	
1
1
1
1
2
2
1
1
1
2
1
1
2
1
1
1
2
1
1
2
1
1
1
2
1
0
0
1
1
1 1
2
1
1
2
1
0
0
2
exp
(
)
(
)
exp
2
M M
M
k M M
p
a M
a
a
a
M M
M
a M
a
a
a
i
M
s
s
a M
a
k
p
M
M
a k
a M
a p
s
i
M
M
π
π
-
-
-
+
+
=
=
-
-
+
=
=
=
-
+
-
+
÷
+
=
-
-
+
÷

	
(9.38)

262	
Receiver Core Operations
 which is inserted into (9.37), yielding
2
1
1
1
1
1
1
2
1
1
1
1
1
2
1
1
1
2
1
1
1
1
1
0
0
0
0
1
1
1
1 1
2
2
1
1
1 1
2
1
1
2
1
1
1
( )
(
)
1
(
)
(
)
(
)
exp
2
m
m M
m
M M
M
M
M
a M
a
n
k
a
a
n
h
p
h
p M M
p
s
r
M
n k
p
m k
p m M
m
a k
a M
a p
i
M
M
M
M
M
π
+
-
-
-
-
+
=
=
=
=
=
+
=
+
+
+
-
-
+
-
+
÷
	
(9.39)
Based on this formula, it is possible to rearrange the signal s in the form of a 
matrix with M2 rows and M1 columns. This matrix shall be denoted as t(p2)a1; its 
row index p2 corresponds to a fine frequency and its column index a1 corresponds 
to the sample index. The matrix t(p2)a1 is defined as
	
1
1
2
1
1
2
1
2
1
1
2
2
0
(
)
(
)
exp
2
M M
a
a M
a
a
a M
a p
t p
s
i
M
π
-
+
=
+
=
-
÷
	
(9.40)
The matrix t(p2)a1 averages the (in general, nonperiodic) signal s over all peri-
ods. Samples corresponding to the same index a1 (but to different periods) are aver-
aged. The averaging is repeated for all possible values of the fine-frequency index 
and the result is stored in a different row; for every row, different fine-frequency 
compensation factors are applied before averaging. The expression (9.39) can be 
further simplified as
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
2
1
1
1
2
1
0
0
0
1
1
1
1 1
2
2
1
1
1 1
1
1
1
1
1
1
1
1 1
2
2
1
1
2
1
1
1
0
( )
(
)
1
(
)
(
)
(
)
exp
2
1
(
)
(
)
(
)
exp
2
m
m M
m
M
M
M
a
n
k
a
n
M
k
n
k
n
h
p
h
p M M
p
t p
r
M
n k
p
m k
p m M
m
a k
i
M
M
M
M
n k
p
m k
p m M
m
t p
r
i
M
M
M
M
π
π
+
-
-
-
=
=
=
-
-
=
=
+
=
+
+
-
-
+
-
÷
+
+
=
-
-
+
÷

1
1
1
1
1
1
1
1
1
0
1
1 1
2
2
1
1
2
1
1
0
2
2
1
1
2
1
1
(
)
(
)
exp
2
1
(
)
IFFT{FLIP{FFT{ (
)}}SHIFT {FFT{
}}}exp
2
M
M
k
k
p
k
p
n
m k
p m M
m
t p
r
i
M
M
M
p m M
m
t p
r
i
M
M
π
π
-
=
-
-
+
=
+
=
-
-
+
÷
+
=
-


	
(9.41)
resulting in a frequency-domain correlation scheme depicted in Figure 9.9. The 
important point in this equation is that all FFTs are of the order M1 instead of M. 

9.5  Fast Fourier Transform	
263
The matrix t(p2)a1 is independent of p1. After the FFTs of the matrix t(p2)a1 and of 
one period of the signal r are computed, it suffices to calculate one IFFT of size M1 
to search one Doppler bin. Recall that, within the circular-correlation approach of 
Section 9.5.3.2, an IFFT of size M is required to search one Doppler bin.
A particular simple case occurs if a Doppler bin with a fine frequency of p2 = 
0 is searched. In this case, the computation of the p2 = 0 row of the matrix t(p2)a1 
simplifies to an averaging of samples.
9.5.7  Handling Secondary Codes
The algorithm presented in Section 9.5.6 proves to be a very efficient realization 
of the circular-correlation method. However, its prerequisite (a periodic signal r) is 
fulfilled only for a few GNSS signals. One example is the GPS C/A-code where the 
PRN code repeats itself 20 times within one data bit. Other examples are pilot signal 
components. However, most of the modernized GNSS signals (e.g., GPS L5 and most 
of the Galileo signals) use tiered codes, which are given by a convolution of a long 
primary and a short secondary code. This structure is being used for data as well as 
for pilot components. The combined tiered code can be considered as a very long 
code sequence, but it would be more convenient if the primary code alone could be 
used for acquisition. The combined tiered code is eventually too long to be acquired 
directly. In other words, although it is possible to consider a tiered-code pilot signal as 
a (long) periodic signal, it is more practical to consider it as a “nearly periodic” signal 
with the shorter period of the primary code.
This section shows how the method of Section 9.5.6 can be adapted to cope 
with tiered codes and to apply the techniques for a nearly periodic signal. The 
presented solution is not as efficient as that in Section 9.5.6 but can be consider-
ably more efficient than a full-length code acquisition, especially in a case when the 
secondary code-phase search space can be limited (e.g., if aiding time information 
is available to the GNSS receiver).
To proceed we assume that r is a tiered code signal; that is, it can be written as
	
=
n
n n
r
u v 	
(9.42)
where the primary code signal u fulfills the identity 
	
+
=
2
1
1
1
n M
n
n
u
u 	
(9.43)
Figure 9.9  Circular correlation with Doppler preprocessing.

264	
Receiver Core Operations
and for the secondary code signal v 
	
2
1
1
2
1
n M
n
n M
v
v
+
=
	
(9.44)
holds. The same index notation as in Section 9.5.6 has been assumed. The signal u 
in this section corresponds to the periodic signal r of Section 9.5.6. 
Equation (9.42) can be rewritten as
	
π
-
=
=

1
0
1
exp 2
M
n
n
k
k
nk
r
u
v
i
M
M 	
(9.45)
where k
v  is the Fourier transform of the secondary code signal v. 
Inserting this equation into the formula for circular correlation with spectral 
shifting (9.21) yields
	
1
0
1
1
0
0
1
1
0
0
1
0
0
(
)
( )
exp
2
1
(
)
(
)
exp 2
exp
2
1
(
)(
)
exp 2
1
(
)(
)
exp 2
M
m
n n m
n
M
M
n
n m
k
n
k
M
M
n
n m
k
n
k
M
M
k
n
n m
k
n
n
m p
h
p
s r
i
M
n
m k
n
m p
s u
v
i
i
M
M
M
n
m k
p
s u
v
i
M
M
n
m k
p
v
s u
i
M
M
π
π
π
π
π
-
+
=
-
-
+
=
=
-
-
+
=
=
-
-
+
=
=
+
=
-
+
+
=
-
+
-
=
+
-
=



1
1
0
1
(
)
M
u
k m
k
v h
p
k
M
-
=
=
-

	
(9.46)
with 
	
1
0
(
)
( )
exp
2
M
u
m
n
n m
n
n
m p
h
p
s u
i
M
π
-
+
=
+
=
-
	
(9.47)
being the correlation function of the signal s with the strictly periodic signal u. To 
obtain hm
u(p), the method of Section 9.5.6 can be used. The correlation function 
including the secondary code hm(p) is the properly weighted sum of the correlation 
functions obtained for the periodic signal hm
u(p) at different frequency offsets. The 
evaluation of (9.46) is numerically not efficient because it contains a sum over the 
full spectral width (i.e., k ranges from 0 to M – 1). Further simplifications can be ob-
tained if we analyze k
v . Using the index notation of Section 9.5.6, it evaluates to
1
1
1
1
2
2
1
1
2
1
1
2
1
2
1
1
1
2
1
1
1
2
1
0
0
1
1
2 2
1
1
1
2
1
0
0
2
exp
(
)
2
2
exp
exp
M M
M
k
k M M
k
a M
a
a
M M
M
a M
a
a
i
M
v
v
v
a M
a
k
k
M
M
ia k M
ia
M
v
k
k
M
M
M
π
π
π
-
-
+
=
=
-
-
=
=
=
=
-
+
+
÷
=
-
-
+
÷


	
(9.48)

9.5  Fast Fourier Transform	
265
Defining the factor b(k) as
	
1
1
1
1
1
1
1
0
1
1
1
1
2
1
2
1
1
0
1
2
( )
exp
1
2
(
)
exp
M
a
M
a
ia k
k
M
M
ia
M
k M M
k
k
k
M
M
M
π
β
π
β
-
=
-
=
=
-
+
=
-
+
÷
	
(9.49)
and simplifying it to
	
1
1
1
1
1
1
1
0
2
1
exp
1
2
1
( )
exp
2
1
exp
M
a
iM k
ia k
M
k
ik
M
M
M
M
π
π
β
π
-
=
-
-
=
-
=
-
-
	
(9.50)
yields
	
1
1
2
2
1
1
1
2
(
)
k M M
k
k
v
v M
k M M
k
β
+
=
+


	
(9.51)
Here, 
2
k
v  denotes the Fourier transform of the secondary code just accounting 
for the index k2 (actually a short Fourier transform). Overall, the correlation func-
tion is then given as 
	
2
2
2
2
1
1
1
1
( )
( )
0
( )
( )
(
)
( )
(
)
BM
M
u
u
m
k k
m
k k
m
k
k
BM
M
M
h
p
v
k h
p
k
v
k h
p
k
M
M
β
β
-
-
=
=-
=
-
-


	
(9.52)
where the summation can be limited by choosing, for example, B = 1 . . . 3. This 
limitation is motivated beause the function β(k) exhibits a narrow peak, as shown 
in Figure 9.10.
The extent to which the frequency bins can be further limited has to be deter-
mined on a case-by-case basis. A particular simple case occurs if the Fourier trans-
form 
2
k
v  exhibits a dominant peak. Then a narrow limitation of the summation 
range could be performed. Defining
	
1
1
1
1
1
1
1
1
1 1
1
1
2
2
1
1
0
1
2
( )
(
)
(
)
exp
M
m
m
l
l
p
l
im l
w
p
w
p M M
p
t p
r
M
M
π
-
-
+
=
=
+
=


	
(9.53)
yields
	
2
2
1
2
1
1
1
*
1
1
2
0
2
2
1
1
1
1
2
1
( )
(
)
(
)
(
)exp
2
B
M
m
k
k
B k
m
h
p
v
k M M
k
M
p m M
m
w
p
k M M
k
i
M
β
π
-
-
=-
=
+
+
-
-
-

	
(9.54)
and a block diagram of the resulting acquisition scheme is shown in Figure 9.11. It 
generalizes the scheme of Figure 9.9 for arbitrary secondary codes.


9.5  Fast Fourier Transform	
267
tion of full-length (i.e., M) FFTs. For a tiered code with a single period, a summa-
tion of the order of M2 terms is required, thus the processing gain is partly lost. 
Nevertheless, the method allows for working with shorter FFTs, which is of special 
importance if only a limited portion of the correlation function needs to be com-
puted (i.e., if the code-phase search range can be limited). 
9.5.8  Asymptotic Computational Performance
The asymptotic performance of an acquisition algorithm is given as the number of 
required operations in the limit of an infinite long coherent integration time. We 
assume that a fixed Doppler range shall be tested; thus, the number of Doppler bins 
increases linearely with Tcoh. Time-domain correlation shows a third-order perfor-
mance, the application of the convolution theorem a second-order performance 
and the secondary code scheme a first-order performance. The asymptotic compu-
tational performance is summarized in Table 9.6.
It should be noted that the secondary code scheme of Figure 9.11 is the most 
efficient and realizes a coherent correlation over multiple periods of the secondary 
code. It requires a pilot signal.
9.5.9  Reported FFT Performance Values
For a successful implementation of a frequency-domain correlator, an efficient FFT 
implementation is required. The computational complexity (i.e., the number of 
mathematical operations, either multiplication or addition) of a complex FFT of 
size N is approximately given as [5]
	
2
#
5
log
FFT
Ops
N
N
=
	
(9.55)
More specifically, there are N log2 N complex additions required, as well as 
(N/2) log2 N – 3/2 N + 2 complex multiplications, see Section 3.5.1 of Diniz, da 
Silva, and Netto’s book [7].
An FFT performance test for a complex FFT with 32-bit floating-point values 
and with 16-bit fixed-point values gave typical performance values of around 2.4–
2.8 GOPS (giga operations per second; either floating-point or integer) for the test 
system described in Table 9.1 and as shown in Figure 9.12. As the FFT library, 
the well-performing Intel library was used [2]. An N = 8,192 FFT can thus be 
calculated within around 200 ms. The performance depends on the FFT size and a 
relative performance reduction can be seen if the FFT size exceeds a value of 216 = 
65,536. Presumably, for larger FFTs the CPU L2 cache (see Table 9.1) is too small. 
Interestingly the fixed-point 16-bit FFT performs with a similar speed as the 32-bit 
Table 9.6  Asymtotic Computational Performance of Different Acquisition Schemes
Scheme
Assumption
Number of Operations
Time-domain correlation, Figure 9.3
None
O(Tcoh
3)
Spectral shifting, Figure 9.6
Periodic reference signal
O(Tcoh
2 log Tcoh)
Secondary code, Figure 9.11
Periodic tiered code, periodic 
  secondary code
O(Tcoh)


9.5  Fast Fourier Transform	
269
FFT sizes, and the Playstation behaves exactly the opposite. The reason lies in the 
fact that, for cache-based systems (like the Pentium processors), the FFT perfor-
mance breaks down if the data does not fit into the cache, whereas for multicore 
systems like the cell, the data-transfer overhead is simply too large for short FFTs. 
The FFT characteristics of both systems are compared in Table 9.7. It should be 
noted that the values reported therein should not be taken literally, especially be-
cause reported FFT-performance values are highly implementation-dependent and 
because power consumption values have only indicative character as they are not 
based on real measurements [13].
Two things should, however, be noted. First, the cell gives significantly more 
GFLOPS per consumed electrical power, which may be explained by the fact that 
this system is newer (see also Section 9.7). Second, the ratio between the reported 
peak-performance values (which is, in both cases, derived from the performance of 
the multiply-and-add command) and the achievable FFT performance is, in both 
cases, around 0.2–0.3.
9.5.10  Discussion and Number of Correlators
In the following discussion, the frequency-domain and time-domain correlations 
shall be compared in terms of operations (i.e., multiplications and additions) re-
quired to achieve the same result. The figure number of equivalent correlators will 
be introduced. Frequency-domain techniques gain performance with an increasing 
number of correlators. Their use in signal acquisition is common practice in GNSS 
SDRs. For the following example, we assume a conventional frequency technique, 
namely zero padding, as described in Section 9.5.3.1. 
If M correlation values of two real-valued signals of length N shall be calculated 
in the time domain, then for each sum a number of N multiplications and N addi-
tions have to be performed, resulting in 
	
#
2
time
Ops
MN
=
	
(9.56)
operations. Here, we assume that the first signal is of a fixed length and it is not 
periodic. For each correlation value, the second signal is taken from a vector of size 
M + N – 1, each time shifted by one sample. We assume that M  N and that M + 
N – 1 is an integer power of two.
Table 9.7  Comparison Between Two CPU Architectures for FFT
Parameter
Test System, Table 9.1
Cell Broadband Engine
Number of cores
1
1+8
CPU clock speed
2.26 GHz
3.2 GHz
Peak performance 32-bit float
9 GFLOP
205 GFLOPS (SPEs only)
Peak Performance 16-bit int
18 GOPS
—
CPU power consumption
5–27 
50–80  
CPU chip technology
90 nm
90 nm
Max. reported FFT performance
2.8 GOPS, 2.6 GFLOP
46.8 GFLOPS
FFT GFLOP/watt
0.096 GFLOP/W
0.61 GFLOP/W
FFT performance ratio (float)
0.29
0.23
Preferred FFT length
Short
Long

270	
Receiver Core Operations
To achieve the same result with frequency-domain techniques, the following 
steps have to be performed (see Figure 9.4):
Zero pad the first signal to a length of M + N – 1;
Forward FFT of the real-valued zero-padded first signal;
Forward FFT of the real-valued second signal;
Frequency-domain multiplication;
Inverse FFT of the frequency-domain product.
A real-valued FFT needs half the operations as a complex valued FFT, thus (2), 
(3), and (5) need all together
	
,1
2
#
10(
1)log (
1)
FFT
Ops
M
N
M
N
=
+
-
+
-
	
(9.57)
operations. The spectral multiplication needs
	
,2
#
6(
1)
FFT
Ops
M
N
=
+
-
	
(9.58)
operations, yielding an overall number of operations of
	
,1
,2
2
#
#
#
(
)(10log (
)
6)
FFT
FFT
FFT
Ops
Ops
Ops
M
N
M
N
=
+
+
+
+
	
(9.59)
The last expression shows that for large N, the number of operations increases 
with N log N, whereas in the time domain the increase is quadratic (assuming M 
proportional to N).
In the following example, the break-even number of correlators Mbe shall be de-
termined, for which both the time domain and frequency domain require the same 
amount of operations. It is obtained by solving the equation 
	
2
2
2
2
(
)(10log (
)
6)
10
log
5log
be
be
be
be
M N
M
N
M
N
N
N
M
N
=
+
+
+
	
(9.60)
where we assume that the number of correlators is much smaller than the number 
of samples. For example, if a GPS C/A-code signal with a coherent integration time 
of 1 ms and a sample rate of 20.48 MHz is considered, then frequency-domain 
techniques become more efficient if more than 71 correlators need to be calculated, 
which corresponds to a code-phase range of 3.5 chips. 
The ratio between the time span represented by N samples divided by the CPU 
time of the FFT implementation to complete the correlation defines the correlation 
efficiency of an FFT-based correlator algorithm. The effective number of correla-
tors #Corr is defined as the product of correlation efficiency multiplied with N. The 
effective number of correlators corresponds to the number of hardware correlators 
that would give the exact same result within the same time. Note that hardware 
correlators are understood to work intrinsically in real time (and not faster). The 
definition of #Corr assumes that all available correlation values from the frequency 
1.
2.
3.
4.
5.

9.6  Reality Check for Signal Tracking	
271
domain correlation are exploited (i.e., M = N is assumed for the most effective use 
of the frequency-domain correlation). The effective number of correlators is thus
	
2
2
#
2
(10log (2
)
6)
2(10log
16)
coh
coh OPS
coh OPS
CPU
T
NT
f
T
f
Corr
N T
N
N
N
=
=
=
+
+
	
(9.61)
Here Tcoh denotes the length of the signal in seconds (usually the coherent inte-
gration time given as the number of samples N divided by the sample rate). TCPU is 
the time of the CPU to perform the computation in seconds, fOPS is the number of 
FFT operations the CPU can perform within one second. The longer Tcoh is, the more 
efficient the FFT. For example, for a 20-ms signal, N = 215, and fOPS = 2.5 GOPS, the 
effective number of correlators evaluates to 150,602. If Doppler preprocessing can 
be applied (see Section 9.5.6), the number of effective correlators further increases 
(e.g., by a factor of approximately 10–20 for the case of the GPS C/A-code).
9.6  Reality Check for Signal Tracking
Based on the clock-tick measurements of the preceding sections, an estimate on how 
many channels the system of Table 9.1 can track in real time shall be presented. 
Acquisition is not considered here. It is assumed that the system runs a GPS L1 C/A-
code receiver using a sample rate of 23.104 MHz with a 1.5-bit sign/magnitude rep-
resentation. Let N denote the number of channels in the following Table 9.8, which 
gives an overview of how many clock ticks are required to process one IF sample. 
Each sample has to be converted to 16 bits, then, for each channel, four refer-
ence signals have to be generated (i.e., the I/Q component of the D- and P-correlator 
signals) and then those signals are correlated with the received sample. It is assumed 
that all data is read from the main memory and not from the CPU caches. 
The CPU clock frequency shown in Table 9.1 is 2.26 GHz and thus, at maxi-
mum, 97.8 clock ticks are available to process one IF sample. If more clock ticks 
would be consumed, then the software does not run in real time anymore, simply 
because it gets too slow. Solving the equation for the total number of clock ticks of 
Table 9.8 for N yields a value of N = 3.07, which would limit the laptop to track 
only three channels in real time.
It is clear that a direct implementation of a GNSS SDR on the laptop would not 
be feasible, even though optimized assembler routines are used. Optimization at the 
algorithmic level is therefore required. 
From Table 9.8 it is evident that most time is spent in generating the reference 
signals. As mentioned above, a possible solution to reduce the efforts for refer-
ence signal generation is to reuse already-generated reference signals for multiple 
Table 9.8  Clock Ticks Per Sample for a GPS L1 Receiver
Operation
Clock Ticks
Multiplicity Factor
Sum
Bit conversion
5.48
1
5.48
Reference-signal generation
5.64
4N
22.56N
Correlation
1.88
4N
7.52N
Total of clock ticks
5.48 + 30.08N


9.7  Power Consumption	
273
CPU processing power is needed to run the receiver core algorithms discussed in 
this chapter. In a typical high-end GPS C/A-code configuration, tracking all satel-
lites in view, the average CPU load is about 80%. The L1 USB front end consumes 
less than 2.5W, yielding an (theoretical) overall receiver power consumption of 
below 30W, ignoring the power consumption of hard disks, screens, and other 
peripherals. 
A real test showed that the run time of the system is around two hours (display 
switched off), depending on the chosen sample rate as listed in Table 9.9. One 
recognizes that reducing the sample rate by a factor of four increases the runtime 
by 35%. This indicates that the receiver power consumption is less affected by the 
actual processing done and that most of the power is needed to keep the system 
alive (e.g., to power the hard disk, mainboard, and chip set). Furthermore, the CPU 
cannot reduce its clock rate (to save power) even when the low sample rate is used 
because it is constantly working. In the high-sample-rate mode, the system seems to 
consume a power of 42W.
The runtime of the presented system is not particularly high. Although the sys-
tem is not optimized for GNSS receiver usage (e.g., the hard disk is always powered 
on) it might be interesting to know when technology evolution can allow using a 
laptop as a GNSS receiver replacement. To be more specific, we would like to es-
timate when this software allows 10 hrs of continuous operation without external 
power having a performance of a geodetic GPS L1/L2 receiver. 
The answer can only be found on a qualitative basis founded on Moore’s law. 
It predicts that the number of gates doubles every 18 months. On the other hand, 
it is observed that dissipated power by CPUs is approximately constant. Thus, it is 
expected that for a given algorithm, the required power halves every 18 months. As 
we need an increase in power of 526% (= 600 minutes / 114 minutes), we estimate 
that this will be available in 3.6 years. Furthermore, increasing the number of fre-
quency bands from L1 to L2 requires doubling the processing power, which needs 
1.5 additional years. Thus, we could estimate that in 2011, laptop systems could 
be available that would allow for running a L1/L2 GNSS SDR continuously for 10 
hours. Although these arguments are very heuristic, they indicate that a high-end 
portable GNSS SDR could be realized by COTS components in the not-so-distant 
future. The discussion also indicates that a laptop may not be the best hardware 
platform for a GNSS SDR in terms of power consumption. A dedicated hardware 
platform development would bring a significant increase in power efficiency.
For example, an embedded system like that described in the work by Toradex 
delivers about 2.15 GOPS with a power consumption of around 800 mW [15]. The 
board is based on an Intel PXA320 processor running at 806 MHz. A multiply-and-
add command accumulating 2  4 16-bit integers (thus performing 8 operations) 
needs 3 clock ticks to be executed [16]. The ratio between peak performance and 
Table 9.9  Run Time of Test System Table 9.1 
Without External Power
Run Time
Sample rate = 5.776 MHz
154 min
Sample rate = 23.104 MHz
114 min

274	
Receiver Core Operations
power consumption is about six times better than for the test system of Table 9.1. 
The extent to which this can be attributed to the processor architecture or to the 
general system design is, however, unclear. The cell processor alone (without other 
components like chip set, memory, and so forth) has a similar ratio between peak 
performance and power consumption like the embedded system (see Table 9.7) but 
works with 32-bit floating point numbers. 
9.8  Discussion
The presented algorithms form the core of a GNSS SDR. For signal tracking, ef-
ficient implementations have been sought and, for acquisition, frequency-domain 
techniques are used. Tracking and acquisition behave differently. Whereas acquisi-
tion is performed on-demand, tracking algorithms run continuously and define the 
ultimate real-time behavior of a GNSS SDR.
From the discussion of Section 9.6, it is obvious that the presented reference 
assembler implementation of the core (tracking) algorithms is not efficient enough 
to allow a direct coding of a multichannel high-end SDR under the given premises 
(like multibit signal representation and a high sample rate of, e.g., 23.104 MHz). 
Although the implementation itself is optimized and uses only a few assembler in-
structions, signal generation and bit conversion execute rather slowly on the given 
CPU architecture, mostly because the required assembler command (table lookup) 
is not well supported by the CPU. By contrast, correlation and FFT execute suf-
ficiently fast. Modern general-purpose processors partly support the implementa-
tion of those algorithms because they provide special vector instructions, and due 
to the multicore architecture they natively facilitate processing of GNSS signals in 
parallel. So far, there is no support for instructions working with a small (e.g., 2–4) 
number of bits, which would be particularly advantageous for processing GNSS-
signal samples. Indeed, the processors either support at minimum 8- or 16-bit in-
structions causing mainly a memory-bus bandwidth problem. Some algorithms, 
however, (e.g., vector multiplication) can be efficiently implemented with 1-bit data. 
Signal-processing algorithms benefit only partly from a large number of bits: cor-
relation benefits to some extent (e.g., interference cancellation), but FFT algorithms 
do benefit, allowing longer FFT lengths.
The most efficient way to speed up a GNSS SDR to allow real-time operation is 
higher-level optimization. Two key issues have been identified. First, massive paral-
lel correlators should be implemented via FFT techniques. Second, reuse of refer-
ence signals should be done to avoid reference-signal generation via resampling. 
Both techniques in unison are the key ingredients for a real-time multifrequency 
GNSS receiver. 
It is essential that a GNSS SDR respects the CPU memory architecture and 
tries to exploit the various CPU caches. A GNSS SDR processes a large amount 
of data and reading those data from main memory would cause a drastic perfor-
mance reduction. Working with a 1-bit or 2-bit signal representation, as proposed 
by Ledvina, definitely reduces the memory bus load and also allows efficient signal 
correlation [4]. The main drawback of this method is, however, the cumbersome 
access of signal samples because the CPU does not support direct bit access and, 

9.8  Discussion	
275
of course, the increased implementation losses of the receiver due to the low 
number of bits. 
A software radio requires a suitable hardware platform. Modern embedded (or 
UMPC) processors with high computational power only need a few watts in op-
eration. This advantageous benefit is lost if the software radio runs a conventional 
PC whose other components (graphic chip, hard disk, or display) need much more 
power and are not needed for a software radio. For example, a laptop like that 
described in Table 9.1 is definitely not the best platform to run a GNSS SDR. An 
embedded system like [15], the proposed RTK system of Chapter 10, or a system 
built around the cell processor yields around six times more operations per watt 
than the laptop of Table 9.1.
References
  [1]	 SiSoftware Ltd., “SiSoftware Sandra Lite (Win32 x86), 2008.1.12.34,” http://www. 
sisoftware.eu/, 2007.
  [2]	 Intel Corp., “Intel Integrated Performance Primitives v5.0 for Windows on Intel Pentium 
Processors,” http://www.intel.com, 2007.
  [3]	 Fog, A., “Instruction Tables, Lists of Instruction Latencies, Throughputs and Microopera-
tion Breakdowns for Intel and AMD CPU’s,” http://www.agner.org/optimize, 2008.
  [4]	 Ledvina, B., et al., “Performance Tests of a 12-Channel Real-Time GPS L1 Software Re-
ceiver,” Proc. 16th Int. Technical Meeting of the Satellite Division of the Institute of Navi-
gation (ION-GPS) 2003, Portland, September 9–12, 2003, pp. 679–688.
  [5]	 Frigo, M., and S. G. Johnson, “FFTW: Fastest Fourier Transform in the West,” http://www.
fftw.org, 2007.
  [6]	 Cooley, J. W., and J. W. Tukey, “An Algorithm for the Machine Computation of Complex 
Fourier Series,” Math. of Comput., Vol. 19, No. 1965, pp. 297–301.
  [7]	 Diniz, P. S. R., E. A. B. da Silva, and S. L. Netto, Digital Signal Processing, System Analysis 
and Design, Cambridge, U.K.: Cambridge University Press, 2002.
  [8]	 Sagiraju, P. K., S. Agaian, and D. Akopian, “Reduced Complexity Acquisition of GPS Sig-
nals for Software Embedded Applications,” IEE Proc. Radar, Sonar, and Navigation, Vol. 
153, No. 1, 2006, pp. 69–78.
  [9]	 Akopian, D., “A Fast Satellite Acquisition Method,” Proc. 14th Int. Technical Meeting of 
the Satellite Division of the Institute of Navigation (ION-GPS) 2001, Salt Lake City,  UT, 
September 11–14, 2001, pp. 2871–2881.
[10]	 Sagiraju, P. K., G. V. S. Raju, and D. Akopian, “Fast Acquisition Implementation for 
High Sensitivity Global Positioning Systems Receivers Based on Joint and Reduced Space 
Search,” IET Radar, Sonar & Navigation, Vol. 2, No. 5, 2008, pp. 376–387.
[11]	 Hofstee, H. P., “Introduction to the Cell Broadband Engine,” http://www-05.ibm.com/ 
e-business/uk/innovation/special/satin/nonflash/pdf/2053_IBM_CellIntro.pdf, 2005.
[12]	 Chow, A. C., G. C. Fussum, and D. A. Brokenshire, “A Programming Example: Large 
FFT on the Cell Broadband Engine,” http://www-01.ibm.com/chips/techlib/techlib.nsf/
techdocs/0AA2394A505EF0FB872570AB005BF0F1/$file/GSPx_FFT_paper_legal_0115.
pdf, 2005.
[13]	 Wang, D.T., “ISSCC 2005: The CELL Microprocessor,” http://www.realworldtech.com/
page.cfm?ArticleID=RWT021005084318&p=2, 2005.
[14]	 Anghileri, M., et al., “Performance Evaluation of a Multi-Frequency GPS/Galileo/SBAS 
Software Receiver,” Proc. 20th Int. Technical Meeting of the Satellite Division of the In-
stitute of Navigation (ION-GNSS) 2007, Fort Worth, September 25–28, 2007, pp. 2749–
2761.

276	
Receiver Core Operations
[15]	 Toradex AG, “Colibri XScale(R) PXA320 Datasheet,” Rev. 1.3, http://www.toradex.com/
downloads/Colibri_PXA320_Datasheet_Rev_1.3.pdf, 2007.
[16]	 Intel Corp., “Intel XScale® Technology: Intel® Wireless MMX™ 2 Coprocessor, Program-
mers Reference Manual,” Rev. 1.5, http://download.intel.com/design/intelxscale/31451001.
pdf, 2006.

277
c h a p t e r  1 0
GNSS SDR RTK System Concept
In this chapter, an innovative receiver concept will be outlined. It exploits the inher-
ent software-receiver advantages to realize a real-time kinematic (RTK) positioning 
system. RTK positioning relies on a roving receiver that is aided by a reference sta-
tion providing correction data to the rover in real time. It aims at a 2-cm accuracy 
level, required to perform geodetic measurements, in forest areas. 
The proposed RTK concept exploits the following advantages of software radio 
technology:
Incorporation of aiding data at correlator level (plus conventional code and 
phase pseudorange correction), thereby increasing carrier tracking stability 
significantly;
Use of a high performance computing platform to realize high sensitivity 
acquisition, sophisticated multipath mitigation, and carrier-phase processing 
algorithms;
Optional incorporation of low-cost pseudolites, whose signals penetrate ar-
eas of high signal attenuation.
The proposed RTK system should thereby outperform available hardware-based 
receivers, where it is difficult to realize the above-mentioned techniques and of which 
the author has no knowledge at this time. The development costs for this system 
are significantly reduced by using SDR technology, which is important to this niche- 
market application. 
The RTK system relies on two main technology enablers (a low power plat-
form and a cost-efficient high data-rate communication link). In this chapter, these 
enablers and the system design will be presented and the key algorithms will be 
given.
10.1  Technology Enablers
The ever-increasing mobile Internet applications drive the development of low-
power CPUs, increase the data rate of mobile phone networks, and cut data transfer 
costs. A summary of recent developments will be given later. 
10.1.1  Ultra-Mobile PCs
Since 2007, personal computers with very small form factors and low power con-
sumption have become increasingly popular. These PCs are termed ultra-mobile 
PCs, mobile Internet devices, or netbooks. The application domain of those devices 

278	
GNSS SDR RTK System Concept
ranges from embedded solutions or help provisions for inexpensive laptops for de-
veloping countries or for educational purposes.
These devices rely on recently developed components minimizing the power 
consumption. An exemplary selection of devices is listed in Table 10.1 [1, 2]. Inte-
grating these components into a single module yields a computing platform with 
50%–100% computational performance as in the laptop test system of Table 9.1 
[3]. However, the power consumption is drastically reduced. It should, however, be 
noted that an integrated module like the one by LiPPERT supports only a simple 
graphical display. 
Both CPUs—the Pentium M 780 [4] and the Atom Z530 [1]—have a similar 
clock rate (2.26 MHz/1.6 MHz) and support the same assembler instructions (the 
Atom additionally supports SSE3 instructions). Both are single-core CPUs, but the 
Atom supports hyper-threading, thus simulating two cores. The Pentium M was in-
troduced in March 2003, the Atom Z530 in April 2008. Their ratio of the thermal 
design power is 27W/2.2W = 12.3.
On the other hand, Moore’s law for power consumption, as discussed in Sec-
tion 9.7, predicts a power ratio of 261/18 = 10.5, which agrees with the observation. 
Here, 61 is the number of months that passed between the market introduction of 
the two CPUs and Moore’s law predicts halving of the power consumption every 
18 months. 
Overall, a clear tendency toward low-power-consumption computing platforms 
is observed, which is well-suited for the implementation of a GNSS SDR. 
10.1.2  Cost-Effective High-Rate Data Links
The data link between the reference station (network) and the roving receiver is 
a critical element in a RTK system. A potential failure and/or latency may signifi-
cantly disturb the system performance. In the late eighties, when the RTCM 2.x 
standards were introduced, the maximum possible data rate enforced considerable 
constraints on the amount, type, and format of the data to be exchanged between 
the reference and the rover receiver [5]. For example, radio modems or, later in the 
early 1990s, GSM-based modems were used where the data rate was 9,600 bit/s. It 
should also be mentioned that transferring the RTK data stream involved significant 
costs for the user.
Due to the still-increasing popularity of mobile Internet applications, strong 
efforts have been put into the development of modernized mobile-phone networks. 
Currently, mobile-phone terminals allow much higher data rates. A GSM-based 
EDGE class-10 phone allows a downlink rate of 220 kbit/s and an uplink rate of 
Table 10.1  Thermal Design Power of UMPC Components
Unit
Solution
Thermal Design 
Power
CPU
Intel Atom Z530
2.2W
Chipset
Intel System Controller  
  Hub US15W
2.3W
Memory (DDR2)
—
< 1W
Hard disk (mechanical)
—
< 3W
Hard disk (solid state drive)
DuraDrive AT SATA 35
< 1W

10.2  System Overview	
279
110 kbit/s. The availability of the EDGE-based data transfer is high. For exam-
ple, T-Mobile offers EDGE over most of Germany and other providers upgraded 
their GSM-based networks with EDGE in 2008. Higher data rates can be achieved 
with UMTS (downlink 384 kbit/s, uplink 64 kbit/s) or HSDPA/HSUPA (downlink 
7.2 Mbit/s, uplink 3.6 Mbit/s), but the availability of these services, especially in 
rural areas, is questionable. Also, other services like WiMAX (IEEE 802.16) will 
offer high data rates in the future. A second important observation is the introduc-
tion of flat rates for data services. A monthly fixed price (e.g., 10 EUR per month 
in the German O2 network) covers all data transfers up to a volume of 200 MByte 
in 2008. 
Overall, a clear tendency is observed that data-link constraints are, at least by 
a factor of 10, less stringent than 10 years ago; this additional available bandwidth 
should be used to transfer more and better correction data between the reference 
station and the rover.
10.2  System Overview
This section gives an overview of the proposed system installation, target applica-
tions, used signals, and a possible test bed.
10.2.1  Setup
The core elements of the system are the reference and the rover GNSS receiver. The 
antenna of the reference receiver is installed at a fixed location with known coor-
dinates. The roving receiver moves dynamically in the vicinity of the reference re-
ceiver. The rover and reference receiver are connected by a data link. Both receivers 
process signals received from the same GNSS satellites. A schematic of the proposed 
system is shown in Figure 10.1.
The setup is basically identical to a conventional differential GPS system with 
one reference station. The important difference lies in the fact that the rover receiver 
Figure 10.1  RTK system overview.

280	
GNSS SDR RTK System Concept
is allowed to work in a degraded signal environment, for example within a forest. 
When a conventional RTK system is not able to process GNSS carrier-phase mea-
surements anymore, the proposed system continues to work. 
The test system can be enhanced by placing pseudolites around the area of 
operation. The carrier phase of the pseudolite signals is processed simultaneously 
and is identical to the GNSS signals and further stabilizes the position solution. 
The pseudolite signals have the advantage that the broadcast signal power can be 
adjusted to overcome high signal-attenuation effects. On the contrary, the pseu-
dolite signals are greatly affected by the multipath, because the pseudolite signals 
travel near the Earth’s surface and a building or trees can cause multiple reflections. 
Therefore, pseudolite-code pseudorange measurements are of reduced precision, 
but the carrier phase is still useful (carrier-phase multipath errors are maximally 
one quarter of the carrier wavelength). The key performance parameters are sum-
marized in Table 10.2.
10.2.2  Sample Applications
The proposed system targets precision surveying applications, which are carried out 
today using terrestrial means. This includes applications like cadastral surveying, 
identification, and monitoring of tree growth or tracking of people who are moving 
under canopies. Typical accuracy requirements are listed in Table 10.3 and point 
out that the use of carrier-phase measurements is inevitable because code measure-
ments affected by a multipath are typically distorted at the decimeter level, making 
it impossible to achieve submeter positioning accuracy. 
10.2.3  Test Installation and Used Signals
We chose as a test area the Galileo Test Bed GATE [6], which is a few-square- 
kilometer test range at the southern border of Germany equipped with six pseudo-
lites that are normally used to simulate Galileo satellites [7]. The pseudolites can be 
operated in a base mode, where they act as normal pseudolites. Within this area, 
GPS, (true) Galileo, and GLONASS signals can be received as well, rendering a nice 
range to validate the proposed RTK system.
Table 10.2  Target System Key Parameters
Parameter
Value Rover
Value Ref. Sta.
Time-to-first fix
10 sec
—
Forest penetration loss (GNSS)
< 25 dB
0 dB
Forest penetration loss (pseudolite)
< 50 dB
< 25 dB
Minimum C/N0
20 dBHz
45 dBHz
Horizontal accuracy
2 cm (2DRMS)
—
Maximum baseline length
500m
—
Maximum user speed
2 m/s
—
Table 10.3  Required Accuracy for Different Applications
Application
Horizontal 2DRMS
Cadastral surveying
2 cm
Tree location
20 cm
People tracking
1m

10.4  High-Sensitivity Acquisition Engine	
281
For this discussion, we assume that the system will process GPS C/A-code mea-
surements and the pseudolites will broadcast a BOC(1,1) Galileo E1 OS-like signal. 
The extension of the proposed system to other and more frequencies is possible, but 
will not be discussed here. Signal parameters are summarized in Table 10.4. The use 
of only one signal carrier frequency implies that the baseline length (i.e., the dis-
tance between reference receiver and rover) is limited to a few kilometers, because 
ionospheric effects are not corrected. Nevertheless, the reader shall be reminded 
that this is a niche-market application, providing the user with high accuracy in 
an area that, so far, is not covered. Therefore, it is expected that the limited range 
is acceptable. Additionally, it should be mentioned that the range of a pseudolite 
signal is also limited, because the pseudolite signals require a free line of sight (at 
least with respect to topographic variations). 
10.3  Key Algorithms and Components
The proposed system concept follows a conventional RTK system design, which 
is not be reviewed here. Instead the reader is referred to well-known GNSS text-
books [8–10]. The roving system determines its position based on double-difference 
carrier-phase measurements and fixes the carrier-phase integer ambiguities based on 
integer LSQ adjustments, also using code pseudorange measurements. It is widely 
recognized that the ability of an RTK system to correctly resolve double-difference 
carrier-phase ambiguities is essential for centimeter-accurate positioning. The abil-
ity of the system to correctly resolve the carrier-phase ambiguities strongly depends 
on the number of received and processed signals [11]. Therefore, it is required that 
both receivers track all in-view signals and continuously output code-pseudorange, 
Doppler, and carrier-phase measurements. 
In the following section, the innovative aspects of the proposed system are de-
scribed; these are required to achieve the high navigational accuracy in a degraded 
signal environment. They are based on SDR technology and include a high-sensitivity 
acquisition engine, assisted tracking, and low-cost pseudolites.
10.4  High-Sensitivity Acquisition Engine
The roving system works in a degraded signal environment; the GNSS signals are 
especially attenuated by the canopy. Therefore, the roving receiver requires a high-
sensitivity acquisition engine. Conventional RTK GNSS receivers are typically not 
equipped with such an engine because conventional carrier-phase measurements 
Table 10.4  Signal Parameters
Parameter
Value
GNSS signal
GPS C/A
Pseudolite signal
Galileo E1 OS-like  
  (optionally pulsed)
Pseudolite PRN chip length  
  (data/pilot)
4,092/4,092
Pseudolite chip rate
1.023 Mchip/s

282	
GNSS SDR RTK System Concept
in a degraded signal environment have many cycle slips, or the carrier phase can-
not be tracked at all. Therefore, there is little need to acquire low-power signals. 
In contrast, most mass-market GPS receivers are equipped with a high-sensitivity 
engine, which is based on massive parallel correlators or on frequency-domain tech-
niques [12]. 
For the proposed RTK system, a special acquisition unit is designed. It is based 
on several key components:
A relatively stable oscillator (e.g., a TCXO) used in both receivers, whose 
short-term stability can be predicted with an accuracy of several hertz;
Exploiting the knowledge of an approximate initial position (rover distance 
< 500m from the reference station);
Provision of aiding data in the form of satellite ephemeris, clock corrections, 
and broadcast navigation data bits;
Time synchronization of a rover and reference station with an accuracy of bet-
ter than 30 ms using the data link via, for example, the NTP protocol [13].
10.4.1  Doppler Search Space
A stable reference clock allows limitation of the Doppler search range during the 
signal-acquisition phase. Figure 10.2 shows the clock drift of a TCXO measured 
over 10 days [14]. This oscillator is integrated in a USB front end of a software 
receiver and the drift is computed by using GPS measurements on a fixed-site loca-
tion [15]. The drift is with respect to the GPS time scale. The TCXO has a nomi-
nal frequency tolerance of ±2,000 ppb and a frequency stability over temperature 
(–30°C to –85°C) of ±500 ppb. In fact, the strong variations shown in Figure 10.2 
are caused by temperature variations, caused by heating the room where the front 
end was located. 
Figure 10.2 demonstrates that the frequency is stable within a few hertz 
accuracy when no temperature changes occur. Temperature changes may cause a 
frequency change of ±100 ppb/°C, but are unlikely to occur [14]. In Figure 10.2, a 
temperature change of 10°C causes a frequency change of 60 ppb, corresponding 
to a Doppler shift of 94.52 Hz at the GPS L1 frequency. 
Figure 10.2  Long-term clock drift for a TCXO [14].

10.4  High-Sensitivity Acquisition Engine	
283
The absolute value of the clock drift of the roving receiver can be calibrated if at 
least one satellite signal is acquired (or tracked), because satellite/pseudolite param-
eters are known and the user dynamics are limited to less than 2 m/s (corresponding 
to a Doppler uncertainty of ±10.51 Hz at GPS L1). This allows for the calculation 
of a predicted Doppler value, and the difference between the predicted minus the 
observed Doppler value can be attributed to the clock drift.
An uncertainty in the user position causes a Doppler variation, which shall be 
assessed below. This uncertainty is important for the satellite signals (but not for the 
pseudolite signals) because the satellite moves with the speed of several km/s.
The range rate r is defined as a timely variation of the geometric distance be-
tween the transmitter located at xsat and the receiver at xrec. The transmitter and 
the receiver have a velocity of vsat and vrec. The range rate r is given as the velocity 
difference projected into the line of sight
	
1
(
) (
)
sat
rec
sat
rec
sat
rec
r =
-
×
-
-
x
x
v
v
x
x
	
(10.1)
If we assume that the receiver position changes by an amount of dxrec, the range 
rate changes will be in an amount of dr
	
1
(
) (
)
sat
rec
rec
sat
rec
sat
rec
rec
r
r
δ
δ
δ
+
=
-
-
×
-
-
-
x
x
x
v
v
x
x
x
	
(10.2)
A first-order Taylor series expansion in the position change of the geometric 
distance yields
	
1
1
2
(
)
1
sat
rec
rec
sat
rec
rec
sat
rec
sat
rec
δ
δ
-
-
-
×
-
-
-
-
÷÷
-
x
x
x
x
x
x
x
x
x
x
	
(10.3)
which is used to obtain a first order approximation of the range rate change as
	
1
2
1
3
1
(
)
1
(
) (
)
(
) (
)
((
)
)
((
) (
))
(
sat
rec
rec
sat
rec
sat
rec
rec
sat
rec
sat
rec
sat
rec
sat
rec
sat
rec
sat
rec
sat
rec
rec
sat
rec
sat
rec
sat
rec
rec
sat
r
r
r
δ
δ
δ
δ
δ
-
-
-
-
-
×
+
-
-
-
-
×
-
÷÷
-
-
-
×
-
-
-
-
×
-
×
-
-
-
×
-
x
x
x
x
x
x
x
x
v
v
x
x
x
x
x
x
v
v
x
x
x
x
x
x
x
v
v
x
x
x
v
v
3
1
)
((
)
)((
) (
))
(
)
ec
sat
rec
sat
rec
rec
sat
rec
sat
rec
sat
rec
rec
sat
rec
r
δ
δ
-
-
=
-
-
-
×
-
×
-
-
-
×
-
x
x
x
x
x
x
x
v
v
x
x
x
v
v
	(10.4)
The maximum absolute value of the range rate change is bounded by assuming 
the in-products in (10.4) and their maximum or minimum values. Furthermore, the 
receiver velocity can be ignored with respect to the satellite velocity, finally yielding

284	
GNSS SDR RTK System Concept
	
1
1
1
2
sat
rec
rec
sat
rec
sat
rec
rec
sat
rec
sat
rec
rec
sat
r
δ
δ
δ
δ
-
-
-
-
-
+
-
-
-
x
x
x
v
v
x
x
x
v
v
x
x
x
v
	
(10.5)
Assuming a maximum position error of 500m, a satellite–receiver distance of 
20,000 km, and a satellite velocity of 5 km/s yields a maximum range rate error of 
0.25 m/s that translates on GPS L1 to a Doppler error of 1.2 Hz.
Overall, we expect that after an initial acquisition of one signal (or other fre-
quency calibration of the rover receiver clock), the Doppler search range is limited 
to be within ±24 Hz at GPS L1 for the rest of the signals to be acquired. 
10.4.2  Correlation Method
We propose as acquisition method to use a single coherent integration as discussed 
in Section 5.7.1. There are a number of arguments that favor this solution over a 
noncoherent detection:
The method achieves a higher sensitivity with the same total integration 
time. 
Mitigation of signal interference is improved by taking into account the navi-
gation data bits. Aiding data is available for GPS C/A-code signals to perform 
a data wipe-off. 
Due to the long coherent integration time, the obtained frequency estimate is 
precise, allowing an easy handover to tracking.
Efficient implementations exist for time-assisted acquisition.
The Doppler search space is narrow; thus, the number of Doppler bins is 
limited and the computational demands are reasonable. 
For a coherent integration time of 1 second, 24 Doppler bins have to be searched 
(after coarse clock calibration). If we assume a code-phase resolution of 0.25 ms and 
a time search range of 60 ms, 240,000 code phase bins need to be searched. Assum-
ing all bins are independent (see Section 5.8), 5.76 million bins need to be tested. If 
we require a system false-detection probability of 1%, this translates to a single-bin 
false-detection probability of 1.7  10–9.
Assuming further a detection probability of 0.9, the clairvoyant sensitivity is 
shown in Table 10.5. Because an FFT-based acquisition scheme will be used, the 
maximum Doppler error is (2Tcoh)–1 and, as described in Section 5.8.5, the Doppler 
loss is 3.9 dB in this case. The sum of further losses caused by the finite code-phase 
resolution (see Section 5.8.5), by nonlinear oscillator jitter (see Section 10.4.3), and 
by line-of-sight dynamics (see Section 10.4.4) is assumed to be less than 1 dB.
10.4.3  Clock Stability
The receiver oscillator has to be stable during the coherent integration time so that 
the summation of the samples is not corrupted by carrier-phase variations. The 
effect of clock stability on coherent integration has been investigated by Sıçramaz 
Ayaz and López-Risueño [16, 17], and both papers indicate that the TCXO stability 

10.4  High-Sensitivity Acquisition Engine	
285
is sufficient to support a coherent integration time of 1 second. In the next section, 
the key results will be summarized and verified by a Monte Carlo simulation.
The clock stability may be expressed as the power spectral density of frequency 
fluctuations Sy( f ) in [Hz–1] [16]
	
2
1
2
1
0
( )
y
S f
h
f
h f
h
-
-
-
-
=
+
+
	
(10.6)
We use y to denote the instantaneous clock frequency divided by the nominal 
frequency, to be distinguished from the frequency argument f of the power spectral 
density. The parameters h–2, …, h0 are explained in Table 10.6. A more convenient 
way to express the clock stability is the Allan variance, which is the variance of the 
instantaneous frequency difference over a given period t. It is related to the spectral 
density via [16]
	
π
σ
τ
τ
τ
τ
-
-
=
+
-
=
+
+
2
2
2
2
1
0
1
(2 )
1
( )
( (
)
( ))
2log2
2
6
2
y
y t
y t
h
h
h
	
(10.7)
It is natural to assume that, during the coherent integration time, carrier-phase 
fluctuations caused by the clock jitter should be much smaller than half of the car-
rier wavelength. Fluctuations in y multiplied by the nominal carrier frequency fRF 
yield frequency fluctuations. The latter fluctuations need to be multiplied by the 
coherent integration time to get carrier-phase fluctuations in cycles. Overall, one 
would expect that the following guideline should hold
	
(
)
0.5
coh
y
coh
RF
T
T
f
σ

	
(10.8)
However, López-Risueño has shown that this guideline is too conservative and 
should be replaced by the requirement
	
10
(1
)
0.5
coh
RF
y
s
s
T
f
f
f
σ

	
(10.9)
where fs denotes the sampling frequency in hertz.
A more precise estimate of the influence of the clock stability on the coher-
ent integration can be obtained via simulation. Therefore, specific parameters of a 
TCXO, which are listed in Table 10.6, have to assumed.
Winkel presented a method to simulate a stochastic process of a power spectral 
density given by (10.6) [18]. The inputs of this simulation are the clock parameters 
and the output is the instantaneous clock error in seconds. Multiplying it by the 
speed of light gives the clock error in meters, denoted as F(t). As pointed out by 
Table 10.5  Acquisition Sensitivity Budget
Parameter
Value
Coherent integration time Tcoh
1,000 ms
Single bin sensitivity
14.6 dBHz
Max. Doppler losses
3.9 dB
Other losses (code-phase, nonlinear  
  carrier-phase)
1 dB
Total sensitivity
19.5 dBHz




10.5  Assisted Tracking	
289
9.3 and for all other operations it is assumed that their performance is determined 
by the memory bandwidth. This is a realistic assumption because the actual op-
eration to be performed is almost trivial; only getting and storing the values from 
and into memory requires significant time. For example, to multiply the signal and 
replica spectrum in the frequency domain, 3 (= two input vectors plus one output 
vector)  8 (= a complex number is represented as two float numbers each 4 bytes 
long)  4,194,304 (= FFT length) MBytes of data needs to be transferred, which 
takes 37.5 ms for a memory bandwidth of 2.5 GByte/s.
Tables 10.8 and 10.9 give the time needed to acquire the first and following sig-
nals. Assuming that each signal acquisition is successful, four signals are acquired 
after 7.4 seconds. This allows the receiver to compute a position and stop the acqui-
sition process. Note that for Table 10.9 the timing uncertainty is at the microsecond 
level. Thus, the IFFT computation time is negligible.
10.5  Assisted Tracking
The assistance data provided by the reference station to the rover receiver includes 
information to aid tracking. The assistance data link provides:
Code and phase pseudorange measurements of the reference receiver;
Broadcast navigation data bits;
Prompt correlator values of the reference receiver.
Figure 10.6  Timing of received and local signal.
Table 10.7  Summary of Warm-Start Acquisition Parameters
Parameter
Value
Signal
GPS C/A
Sample rate
3.96 MHz
Code-phase resolution
0.26 chip
Total correlation time
1,060 sec
Code-phase search window
60 ms
Forward FFT order N/size
222 = 4,194,304
Inverse FFT order N/size
217 = 131,072
Decimation factor before IFFT
25 = 32
Number of Doppler bins
24
Memory bandwidth
2.5 GByte/s
FFT performance for N =17 / 22
2.4/1 GFLOP

290	
GNSS SDR RTK System Concept
First, the broadcast navigation data bits allow the rover receiver to remove 
them and to extend the coherent integration time during tracking. More specifically, 
the dependency on the broadcast navigation data bits is removed by multiplying the 
rover correlation values with the data-bit values obtained through the assistance 
link (data wipe-off process). The assistance data also allows limiting the region of 
Doppler and code-phase values for single channels (vector-hold tracking). Double-
difference correlator values are formed for high carrier-phase tracking stability. 
Vector-hold tracking and double-difference correlators are described in the follow-
ing section.
10.5.1  Vector-Hold Tracking
In Section 4.3.3, vector tracking and independent channel tracking are discussed and 
it is shown that estimated pseudoranges are independent of the correlation point, as 
long as the correlation point is within the linear region of the discriminators. 
For the proposed system, conventional DLL/FLL tracking will fulfill the re-
quirement to track signals down to 20 dBHz [19]. DLL/FLL parameters, which 
allow tracking of GPS C/A-code signals even down to 10–12 dBHz, are shown in 
Table 10.10 [20].
Tracking problems occur if a signal is further attenuated; the channel may lose 
its lock. Loss-of-lock detection is done via signal-power estimation. If the signal 
power estimate falls beyond a certain tracking threshold, its function for navigation 
is discontinued and the vector-hold tracking method is applied. 
Vector-hold tracking is a hybrid tracking method between independent channel 
tracking and vector tracking. Vector-hold tracking uses a similar DLL/FLL loop 
architecture as independent channel tracking, but continuously compares the in-
Table 10.8  Warm-Start Acquisition Execution Time (First Signal)
Parameter
Number of Runs Time per Run
Total Time
Signal generation
1
10 ms
10 ms
Resampling
1
13 ms
13 ms
Forward FFT
2
461 ms
922 ms
Frequency multiplication
24
38 ms
912 ms
Decimation
24
13 ms
312 ms
Inverse FFT
24
5 ms
120 ms
Peak search
24
0.4 ms
10 ms
Total
2,299 ms
Table 10.9  Warm-Start Acquisition Execution Time (After the First Signal Has Been Acquired)
Parameter
Number of Runs
Time per Run
Total Time
Signal generation
  1
  10 ms
  10 ms
Resampling
  1
  13 ms
  13 ms
Forward FFT
  1
461 ms
461 ms
Frequency multiplication
24
  38 ms
912 ms
Decimation
24
  13 ms
312 ms
Inverse FFT
24
—
—
Peak search
24
—
—
Total
1,708 ms

10.5  Assisted Tracking	
291
stantaneous code-phase/Doppler values against nominal values derived from the 
receiver’s PVT estimate. The nominal DLL code-phase value is derived from the 
nominal pseudorange and the nominal Doppler value is derived from the pseudo-
range rate value. Vector-hold tracking requires a valid PVT solution, transmitter 
positions, and clock corrections. If the code-phase or Doppler value of a single 
tracking channel deviates from the nominal value more than a certain threshold, 
the receiver forces the channel to stay within the threshold by adjusting the code-
phase and/or Doppler values of the NCO. The value of the threshold equals the size 
of the linear region of the code-phase and frequency discriminators as discussed in 
Section 4.3.2.10.
The main advantage of vector-hold tracking compared to vector tracking is that 
truly independent measurements are obtained for each channel above the signal-
power threshold, making it easier to attribute measurement errors (e.g., multipath) to 
single channels, whereas in full vector tracking, all error sources are mixed together 
in the final position estimate. On the other hand, weak-signal tracking is aided by the 
strong signals, thereby periods of signal outages are bridged. Vector-hold tracking 
does not improve the tracking stability if all signals are attenuated identically.
10.5.2  Double-Difference Correlator
Using single- or double-difference code/phase pseudorange measurements is a com-
monly used method to eliminate common mode errors in GNSS positioning [9]. 
Forming receiver single-difference observations between two receivers removes 
the observation dependency on the satellite clock error and satellite hardware bi-
ases. Forming single-difference observations between two satellites removes the 
observation dependency on the receiver clock error and receiver hardware biases. 
Double differencing combines a receiver plus a satellite single difference and is a 
commonly used method for carrier-phase-based positioning. Double-differencing 
allows the carrier-phase ambiguities to be constrained to their integer values within 
the positioning algorithm [9]. 
For the proposed positioning system, double-differencing will already be done 
at the correlator level to increase the coherent integration time and to increase 
the carrier-phase tracking stability. Double-difference correlators are formed at the 
rover receiver and are used to track the (double-difference) carrier phase, which is 
then used for positioning.
10.5.2.1  Tracking Scheme
Forming double-difference correlators implies that two receivers track signals from 
two transmitters, as shown in Figure 10.7.
Table 10.10  DLL/FLL Parameters for GPS
Parameter
DLL Value
FLL Value
Order
2
1
Bandwidth
0.5 Hz
0.25 Hz
Coherent integration time
20 ms
10 ms



294	
GNSS SDR RTK System Concept
	
(
)
2
2
ϕ
ϕ
δ
ω
δ
ω
δ
ω
δ
ω
π
δ
δ
δ
δ
ϕ
δ
ω
δ
ω
δ
ω
δ
ω
π
δ
D
=
D
-
+
+
-
+
-
+
-
=
D
-
+
+
-
+
D

,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
k m
k m
l m
l m
k n
k n
l n
l n
rec
rec
rec
rec
l m
l n
k n
k m
nom
rec
rec
rec
rec
k m
k m
l m
l m
k n
k n
l n
l n
rec
rec
rec
rec
nom
rec
t
t
t
t
f
t
t
t
t
t
t
t
t
f
t
	 (10.18)
The value of the last term 2 pf nom Ddtrec can be calculated exactly because 
it is completely based on internal receiver time readings. Based on the channel 
output of Figure 10.8, a carrier-phase-related exponential Pk,m is obtained from 
the P-correlator CP
k,m and the midpoint phase j0
k,m of the reference signal (see 
Section 7.3.1)
	
,
,
,
,
0
exp{
}
exp{
}
k m
k m
k m
k m
P
P
C
i
i
ϕ
ϕ
=
µ
	
(10.19)
where the symbol µ denotes proportionality. The unsynchronized double-difference 
prompt correlator is defined as
	
,
,
,
,
exp{
}
k m
l m
k n
l n
P
P
P
P
P
i
ϕ
D
=
µ
D
	
(10.20)
yielding an unsynchronized carrier-phase estimate as 
	
angle{
}
P
ϕ
D
=
D
	
(10.21)
A synchronized double-difference prompt correlator is given as
π
δ
ω
δ
ω
δ
ω
δ
ω
δ
D
=
D
-
+
+
-
+
D

,
,
,
,
,
,
,
,
exp{2
(
)}
k m
k m
l m
l m
k n
k n
l n
l n
rec
rec
rec
rec
nom
rec
P
P
i
t
t
t
t
f
t
	
	
	
	
(10.22)
and a synchronized carrier-phase estimate as
	
angle{
}
P
ϕ
D
=
D

	
(10.23)
10.5.2.3  Unwrapping
The double-difference correlator principle relies on first forming the double- 
difference correlator via (10.20) and synchronizing the correlator by apply-
ing (10.22). Then those correlator values are used to set up a carrier-phase 
unwrapping algorithm. The advantage of (10.22) over undifferenced carrier-
phase tracking is that common mode errors like receiver and satellite clock 
errors are eliminated and tracking-loop bandwidths can be chosen to be much 
smaller. Also, possibly present navigation data bits can be ignored when forming 
(10.20).
For simplicity, a conventional PLL is used to perform the double-difference 
phase unwrapping process. A PLL unwraps and filters the carrier-phase estimates 
simultaneously. PLL equations for various loop orders are readily available [19]. 
The PLL noise performance is characterized by the tracking loop bandwidth BPLL. 
The reader should keep in mind that other unwrapping algorithms and/or filter 
algorithms can also be used.

10.5  Assisted Tracking	
295
10.5.2.4  Stability Condition
Based on (10.23), an estimate of the reduced double-difference carrier phase is 
obtained. This carrier-phase estimate needs to be unwrapped to include the full 
carrier cycle count in the estimate. For the unwrapping to work in a stable manner, 
noise in the estimated wrapped phase needs to be limited (i.e., the 3-sigma noise 
needs to be less than p/2 to avoid a 2p ambiguity (a cycle-slip) during unwrapping). 
The related double-difference carrier-phase tracking-loop stability is determined by 
thermal noise, interpolation noise, and, eventually, atmospheric noise. Ignoring the 
last contribution, the stability equation adapted from [19] is 
	
2
2
2
2
6
in
th
ϕ
π
σ
σ
σ
D
=
+
<
÷

	
(10.24)
The closed-loop thermal-noise variance sth in radians is considered to be inde-
pendent from the interpolation noise sin in radians. Both variances are discussed 
below.
We assume that a double-difference carrier-phase tracking loop with a band-
width of BPLL is used. We assume that two strong signals are tracked (by the ref-
erence receiver) with two weak signals (by the rover receiver). The weak signals 
dominate the thermal-noise error budget. Both weak signals are assumed to have 
identical power.
The closed-loop thermal noise is related to the carrier-phase discriminator noise 
of Sections 4.3.2.8 and 8.1.3 [19] and
	
2
2 strong, 2 weak
signals
2
var
4
var
coh
PLL
coh
PLL
th
T
B
T
B
σ
ϕ
ϕ
=
D
	
(10.25)
The variance of the double-difference noise is twice the variance of the weak-
signal undifferenced noise. Contributions from the strong signals are disregarded. 
Based on (4.88) we obtain
	
2
0
0
2
1
1
/
2
/
PLL
th
coh
B
C N
T
C N
σ
=
+
÷
	
(10.26)
The interpolation noise is treated in a similar manner as the thermal noise. The 
interpolation noise is caused by frequency-tracking errors and is then filtered by 
the double-difference PLL. The frequency-tracking-error variance sω is described 
in Sections 4.3.2.7 and 8.1.2. By simple error propagation based on (10.18) and 
(10.25), the closed-loop interpolation noise variance is given by
	
2
2
2
4
in
coh
PLL
Time
T
B
t
ω
σ
δ
σ
=
	
(10.27)
where 
2
Time
t
δ
 is the RMS interpolation time. Again, we assume that the closed-
loop interpolation noise error budget is dominated by the two weak signals (i.e., the 
Doppler of the strong signals is sufficiently well known).
Using, for example, (4.84) to describe the Doppler-discriminator noise and con-
verting the Doppler-discriminator noise into a closed-loop frequency-tracking error 
(assuming a frequency-loop bandwidth BFLL), we obtain


10.6  Low-Cost Pseudolites	
297
Equation (10.30) allows calculating the maximum allowable BPLL value for a 
given value of BFLL. An exemplary evaluation is shown in Figure 10.9. The figure 
shows that BFLL = 1 Hz and BPLL = 10 Hz allow cycle-slip-free tracking of 20-dBHz 
signals. For a slowly moving user, BPLL = 1 Hz allows tracking signals down to 
13 dBHz.
10.6  Low-Cost Pseudolites
The proposed positioning system can be enhanced by pseudolites if the GNSS signal 
attenuation is too strong to allow precise positioning. The pseudolite signals are de-
signed to overcome an additional penetration loss of 25 dB (see Table 10.2). A key 
requirement on the pseudolites is that they are of low complexity (and thus of low 
cost) and that they can be installed easily. The basic idea is to set up the pseudolites 
at points with known coordinates. After switching them on, they start broadcasting 
their signal autonomously and independent of other pseudolites or the GPS signals. 
Neither calibration nor any other complex startup procedure is required. 
Pseudolite signals match well with a software radio, because the signal pro-
cessing as described for example in Chapter 9 works with 16 bits, which repre-
sents a dynamic amplitude range of 96 dB. Multibit ADCs are readily available; 
for example, the ADC14L020 provides 14-bit resolution at 20 MHz with a power 
consumption of 150 mW [22]. Overall, a software radio can cope well with strong 
signal-power variations caused by the near–far effect and the timely variable at-
tenuation of a pseudolite signal. Furthermore, the proposed positioning system is 
based on differential methods. Thus, neither the pseudolite clock error needs to 
be determined, nor is there a need to broadcast a navigation data message by the 
pseudolite. Because of the differential positioning method, pseudolite hardware bi-
ases are partly eliminated. Furthermore, the use of the carrier phase makes the 
system robost against distortions of the signal-autocorrelation function caused by 
amplitude-dependent front-end effects. A low complexity pseudolite can be used as 
discussed by Manandhar [23]. In the latter work, the pseudolites act as proximity 
sensors and are not used for ranging.
In Table 10.11, a possible pseudolite configuration is presented, which is adapted 
from the existing transmitters placed in the GATE area [7]. However, in contrast to 
the real GATE transmitters, only a pilot signal is broadcast. The broadcast signal is 
not synchronized to any time frame and a comparably low quality oscillator is used. 
Therefore the pseudolite can, in principle, be realized with a small FPGA for IF 
signal generation plus an RF upconverter reducing components’ costs to a mini-
mum. The pseudolite can operate autonomously or, eventually, a low data-rate data 
link allows control of the broadcast signal power.
The major disadvantage of pseudolite signals in comparison to satellite-borne 
signals is the near-far effect. Signals received from nearby transmitters are of much 
higher power than signals received from more distant transmitters. A worst-case 
situation is depicted in Figure 10.10.
If we assume that the minimum distance from the rover to the pseudolites can 
be limited to be larger than 50m, geometric signal-power variations on the order of 
26 dB are the consequence (assuming that the inverse signal power is proportional 


10.6  Low-Cost Pseudolites	
299
10.6.1  Continuous-Time Signals
If the pseudolite signals were broadcast continuously in time, the high interference 
caused by the extreme signal-power variation would make tracking of weak signals 
impossible. For the presented pseudolite signal, the cross-correlation protection is 
of a similar magnitude as between two GPS C/A-code signals [24]. Two methods are 
proposed to overcome the interference problem [25]. The GPS signals have a cross-
correlation protection of around –21 dB against Galileo or GPS signals, and the 
Galileo signals have a protection of around –23 dB against Galileo or GPS signals.
10.6.1.1  Signal-Power Adaption
The transmitted signal power can be dynamically adjusted based on actual mea-
surements of rover and reference station received power levels. The pseudolite sig-
nals can be adjusted in a way that the rover receives signals approximately at a 
level not much greater than 41 dBHz. In this case the PRN-code cross-correlation is 
high enough to avoid any incorrect locks on false cross-correlation peaks. Dynamic 
signal-power adaptation is realized in GATE within the extended base mode [7].
10.6.1.2  Interference Cancellation
Interference-cancellation schemes can be employed in the receiver to reduce the ef-
fect of a strong signal. Signal-cancellation schemes require generation of a strong 
signal replica in the channel tracking the weak signal and are touched upon in Sec-
tions 4.2.3 and 5.7.3. Interference cancellation might be necessary at the reference 
station, if the dynamic signal-power adaptation requires that a pseudolite trans-
mits with full power and simultaneously the reference station receives a low power 
signal with 45 dBHz. In this case, the high-power pseudolite signal has 76.4 dBHz 
and the difference at the reference station between the high-power and low-power 
signal is 31.4 dB. This value is around 10 dB above the cross-correlation protection. 
Cancellation schemes are comparably easy to implement in a software receiver, but 
require a significantly greater computational load. 
10.6.2  Pulsed Signals
Using pulsed-pseudolite signals is common practice to reduce the near–far effect. 
This method is based on first detecting a pulse from a strong pseudolite and blank-
Table 10.12  Pseudolite Near–Far Parameters Without Dynamic Pseudolite 
Power Adjustment
Parameter
Value Rover
Value Ref. Sta.
Minimum distance pseudolite-receiver
50m
500m
Maximum distance pseudolite-receiver
1,050m
550m
Geometric signal-power variation
26.4 dB
0.8 dB
Minimum received signal power
20 dBHz
45 dBHz
Maximum received signal power
96.4 dBHz
70.8 dBHz
Worst-case signal-power difference  
  between two different signals
76.4 dB
25.8 dBHz

300	
GNSS SDR RTK System Concept
ing it out for the channels tracking other signals [25]. Two conditions need to be 
fulfilled when pseudolite signals are present:
The system must be able to detect strong pulses and mitigate the effect on 
weaker signals. The degradation caused by the pulsed signals needs to be 
acceptable.
The pulse repetition rate must be high enough to allow continuous-phase 
tracking.
In the next section it shall be demonstrated that the proposed pulsing scheme is 
able to fulfill both requirements.
10.6.2.1  Pulse Repetition Rate
First, the pulse repetition rate is, according to Table 10.11, 100 ms. Correlator val-
ues are therefore available with a rate of 10 Hz, which allows a maximum tracking-
loop bandwidth of 4 Hz [26]. This is sufficient for the DLL/FLL/PLL parameters, 
which were introduced above.
10.6.2.2  Pulse Detection
Pulse detection can basically be performed by two means: by using a properly cho-
sen detection algorithm as described in Chapter 5 or by predicting the pulse arrival 
time if sufficient information is available to the signal-processing unit.
For pulse detection, the use of an energy detector is advisable (see section 5.5) 
because of its simple implementation. Its detection performance is less than that of 
a matched filter, but undetected weak pulse signals do not degrade the other signals. 
This will be demonstrated later. An energy detector working with 1-ms batches as-
suming pf = 10-5 and pd = 0.9 can detect pulsed signals with a C/N0 value (during 
transmission) of 53 dBHz in the background of white noise. It should be noted that 
this corresponds to an average C/N0 value of 39 dBHz (a pulsing ratio of 25 cor-
responds to 14 dB). Figure 10.11 shows a simulated energy detector output for two 
different pseudolite signal-power levels. A detailed list of simulation parameters can 
be found in Table 10.13. On the right side of Figure 10.11, cases are clearly visible 
in which two or more pulses overlap.
Overall, pulses can be detected with sufficient sensitivity and signal samples af-
fected by pulsed signals can be identified. 
Once both receivers have computed a first positioning solution (for example 
using the GPS signals), the reference receiver is able to communicate pulse trans-
mission periods to the roving receiver. In this case, the roving receiver can precisely 
predict the pulsed signal arrival time. Consequently, an energy detector to detect 
pulses is required only during signal acquisition but not during tracking.
10.6.2.3  Mitigation
Once a pulse has been detected, its effect has to be mitigated. As has been men-
tioned above, the advantage of a pulsed signal is the use of pulse blanking, which is 

10.6  Low-Cost Pseudolites	
301
Figure 10.11  Energy detector (1 ms) output receiving thermal noise plus one weak GPS C/A-code 
signal (20 dBHz) plus 6 pseudolite signals. Mean single pseudolite C/N0: left = 39 dBHz, right = 
49 dBHz.
a comparably simple to implement mitigation scheme. The fundamental assumption 
of pulse blanking is that the affected signal samples do not carry any useful infor-
mation and can therefore be ignored. Pulse blanking is applied for all channels, but 
obviously not for the channel tracking the respective pseudolite whose pulse has 
been detected. 
When the correlator values are formed, the integration interval must exclude 
the affected samples. This can be achieved either by properly chosen integration 
indices or by setting the affected signal samples to zero. 
Pulse blanking reduces the GPS C/A-code signal-tracking performance, because 
fewer discriminator values are available to steer the tracking loops. If pulse blank-
ing occurs with a rate much higher than typical loop bandwidths, pulse blanking 
reduces the effective received signal power by

302	
GNSS SDR RTK System Concept
	
-
= -
10
10log
total
blan
PB
total
T
T
L
T
	
(10.31)
where LPB is the pulse blanking loss in decibels, Tblank is the duration of pulse blanking 
in seconds within the repetition rate Ttotal in seconds. For an assumed number of six 
pseudolite signals of Table 10.13, the pulse blanking loss is therefore around 1.2 dB.
10.6.2.4  Navigation Data-Bit Decoding
Pulse blanking also reduces the GPS C/A data-bit estimation performance. In the 
worst case, a consecutive train of pulses may completely hide a broadcast naviga-
tion data bit, making it impossible to retrieve its value. This situation is, however, 
unlikely to occur and is not repeatable in time. Only a detailed simulation could 
clarify the percentage of affected data bits (which is, however, beyond the scope 
of this text). Eventually the proposed navigation system has to rely on external 
ephemeris data. 
10.6.2.5  Overlapping Pseudolite Pulses
If two or more pulses overlap, the respective pulsed signal-correlator values are 
degraded due to the blanking and are eventually useless. The correlation values are 
reduced by 
	
η
= -
-
10
10log
(1
)
over
L
	
(10.32)
where Lover is the overlapping loss in decibels and h is the overlapping ratio (0, no 
overlap; 1, total overlap). For a total overlap, the respective correlator values are 
useless. In order to avoid timely constant situations of totally overlapping pulses, 
the pulse-repetition periods are chosen to be non-equal and are chosen to be
	
,
,
,
R k
R nom
R delta
T
T
kT
=
-
	
(10.33)
TR,k is the pulse-repetition time for the pseudolite k in seconds. TR,nom is the 
nominal repetition rate and TR,delta is the repetition rate decrement between two 
pseudolites. Partial overlapping of two pseudolites pulses with an index difference 
of Dk occurs approximately every Tover;rep seconds,
	
2
,
;
,
R nom
over rep
R delta
T
T
kT
= D
	
(10.34)
Table 10.13  Simulation Parameters for Pulsed Signal Detection
Parameter
Value
Number pseudolite signals
6
Pseudolite repetition rate
PRN1: 99 ms, PRN2: 98 ms, . . . , PRN6: 94 ms
Single pseudolite mean power
39, 49 dBHz
Single pseudolite peak power
53, 63 dBHz
Number of GPS signals
1 (PRN 1)
GPS signal power
20 dBHz
Sample rate
4.19 MHz
Sample type
Complex
Duration
1 sec

10.6  Low-Cost Pseudolites	
303
and overlapping lasts for Tover;dur seconds, 
	
,
;
,
R nom
P
over dur
R delta
T
T
T
kT
= D
	
(10.35)
where TP is the pulse duration in seconds. For the chosen settings, overlapping be-
tween two pseudolites with an index difference of 1 occurs every 10 seconds with 
a duration of 0.4 second (3 correlator values are partly degraded, 1 is strongly de-
graded). Overlapping between two pseudolites with an index difference of 4 occurs 
every 2.5 seconds with a duration of 0.1 second (one correlator value). One would 
expect that periods of overlapping can be bridged by the tracking loops, which have 
a loop bandwidth of less than 1 Hz. However, a final conclusion can only be drawn 
after a detailed simulation has been performed. 
10.6.2.6  Undetected Pulses
The most severe signal degradation due to the presence of undetected pseudolite 
signals is expected to occur when a weak GPS C/A-code signal is acquired. This 
case is investigated by a numerical simulation. The GPS C/A-code signal power is 
20 dBHz and 6 pseudolite signals are present each with a mean C/N0 power of 39 
or 59 dBHz (corresponding to a peak C/N0 during transmission period of 53 or 
73 dBHz). We assume that the pulses have not been detected and are present during 
the signal-acquisition process. This is likely to occur for the 39-dBHz pseudolite 
signals, because this signal power value is near the energy detector sensitivity. The 
Figure 10.12  GPS C/A-code acquisition results, with and without the presence of pseudolite 
signals.


10.7  RTK Engine	
305
The rover receiver gets all reference station data and forms double-difference 
code pseudoranges and double-difference correlator values. The double-difference 
correlator values are used to estimate the double-difference carrier phase as de-
scribed in Section 10.5.2. Code and phase observations are processed in a Kalman-
filter to estimate the float position with the float carrier-phase ambiguity. Based 
on the ambiguity covariance matrix, the Z-transform is used to de-correlate the 
ambiguities and to possibly constrain the ambiguities to their integer values [11]. 
Proper verification is needed to avoid false ambiguity fixing. If the ambiguities are 
fixed, the position is recalculated using the integer ambiguity values to obtain the 
fixed solution. During the double-difference phase tracking process, cycle-slip de-
tection and eventually correction are necessary to avoid gross errors in the fixed 
ambiguities. 
References
  [1]	 Intel Corp., “Intel® Atom™ processor Z5xx Series, Data Sheet,” Rev 1, Doc. No. 319535-
001US, http://download.intel.com/design/chipsets/embedded/datashts/319535.pdf, 2008.
  [2]	 Intel Corp., “Intel® System Controller Hub US15W for Embedded Computing,” Doc. 
No. 319545-002, http://download.intel.com/design/chipsets/embedded/prodbrf/319545.
pdf, 2008.
  [3]	 LiPPERT, t. e. c., “CoreExpress™-ECO, Next Generation Computer-On-Module, Specifi-
cations,” http://www.lippertembedded.com, 2008.
  [4]	 Intel Corp., “Intel® Pentium® M Processor with 2-MB L2 Cache and 533-MHz Front Side 
Bus, Data Sheet,” Rev 2, Doc. No. 305262-002, http://download.intel.com/design/mobile/
datashts/30526202.pdf, 2005.
  [5]	 Radio Technical Commission For Maritime Services, S. C. No. 1, “RTCM Recommended 
Standards For Differential GNSS (Global Navigation Satellite Systems) Service, Version 
2.3,” RTCM Paper 136-2001/SC104-STD, 2001.
  [6]	 IFEN GmbH, “GATE Home, Hompage of the Galileo Test and Development Environ-
ment,” http://www.gate-testbed.com, 2008.
  [7]	 Heinrichs, G., et al., “First Outdoor Positioning Results with Real Galileo Signals by Using 
the German Galileo Test and Development Environment,” Proc. 20th Int. Technical Meet-
ing of the Satellite Division of the Institute of Navigation (ION-GNSS) 2007, Fort Worth, 
TX, September 25–28, 2007, pp. 1576–1587.
  [8]	 Hofmann-Wellenhof, B., H. Lichtenegger, and E. Wasle, GNSS: Global Navigation Satellite 
Systems: GPS, GLONASS, Galileo & More, Vienna: Springer, 2008.
  [9]	 Leick, A., GPS Satellite Surveying, New York: Wiley, 2004.
[10]	 Teunissen, P. J. G., and A. Kleusberg, GPS for Geodesy, Berlin: Springer, 1996.
[11]	 Tiberius, C., et al, “0.99999999 Confidence Ambiguity Resolution with GPS and Galileo,” 
GPS Solutions, Vol. 6, No. 1–2, 2002, pp. 96–99.
[12]	 SiRF Technology, Inc., http://www.sirf.com, 2008.
[13]	 Wikipedia, “Network Time Protocol (NTP),” http://en.wikipedia.org/wiki/Network_Time_
Protocol, 2008.
[14]	 Rakon Ltd., “IT5305BE, 23.104 MHz, SMD GPS TCXO,” http://www.rakon.com, 
2008.
[15]	 IFEN GmbH, “NavX®-NSR: GPS/Galileo Navigation Software Receiver,” Brochure, 
http://www.ifen.com, 2007.
[16]	 López-Risuen´o, G., et al., “User Clock Impact on High Sensitivity GNSS Receivers,” Proc. 
ENC-GNSS 2008, Toulouse, April 22–25, 2008.

306	
GNSS SDR RTK System Concept
[17]	 Sıçramaz Ayaz, A., T. Pany, and B. Eissfeller, “Performance of Assisted Acquisition of the 
L2CL Code in a Multi-Frequency Software Receiver,” Proc. 20th Int. Technical Meeting of 
the Satellite Division of the Institute of Navigation (ION-GNSS) 2007, Fort Worth, TX, 
September 25–28, 2007, pp. 1830–1838.
[18]	 Winkel, J. Ó., Modeling and Simulating GNSS Signal Structures and Receivers, University 
of Federal Armed Forces Munich, Werner-Heisenberg-Weg 39, D-85577 Neubiberg, http://
www.unibw.de/unibib/digibib/ediss/bauv, 2003.
[19]	 Kaplan, E. D., and C. J. Hegarty, (eds.), Understanding GPS: Principles and Applications, 
2nd ed., Norwood, MA: Artech House, 2006.
[20]	 Anghileri, M., et al., “Performance Evaluation of a Multi-Frequency GPS/Galileo/SBAS 
Software Receiver,” Proc. 20th Int. Technical Meeting of the Satellite Division of the 
Institute of Navigation (ION-GNSS) 2007, Fort Worth, TX, September 25–28, 2007, 
pp. 2749–2761.
[21]	 Gurtner, W., “RINEX: The Receiver Independent Exchange Format Version 2,” ftp://igscb.
jpl.nasa.gov/igscb/data/format/rinex2.txt, 1998.
[22]	 National Semiconductor, “ADC14L020 - 14-Bit, 20 MSPS, 150 mW A/D Converter from 
the PowerWise® Family,” http://www.national.com, 2008.
[23]	 Manandhar, D., et al., “Development of Ultimate Seamless Positioning System Based on 
QZSS IMES,” Proc. 21st Int. Technical Meeting of the Satellite Division of the Institute of 
Navigation (ION-GNSS) 2008, Savannah, September 16–19, 2008, pp. 1698–1705.
[24]	 Ávila Rodríguez, J. Á., On Generalized Signal Waveforms for Satellite Navigation, Univer-
sity of Federal Armed Forces Munich, Werner-Heisenberg-Weg 39, D-85577 Neubiberg, 
http://www.unibw.de/unibib/digibib/ediss/bauv, 2008.
[25]	 Elrod, B. D., and A. J. van Dierendonck, “Pseudolites,” in Global Positioning System: 
Theory and Applications, Volume II, pp. 51–79, Parkinson, B. W., and J. J. Spilker, (eds.), 
Washington, D.C.: American Institute of Aeronautics and Astronautics Inc., 1996.
[26]	 Kazemi, P. L., “Optimum Digital Filters for GNSS Tracking Loops,” Proc. Int. Technical 
Meeting of the Satellite Division of the Institute of Navigation (ION-GNSS) 2008, Savan-
nah, GA, September 16–19, 2008, pp. 2304–2313.
[27]	 Spilker, J. J., Jr., “GPS Signal Structure and Theoretical Performance,” in Global Posi-
tioning System: Theory and Applications, Volume I, pp. 57–120, Parkinson, B. W., and 
J. J. Spilker, (eds.), Washington, D.C.: American Institute of Aeronautics and Astronautics 
Inc., 1996.

307
307
C H A P T E R  11
Exemplary Source Code
This book is accompanied by a few small computer programs to illustrate algo-
rithms and methods presented herein.* The selection of the methods reflects the au-
thor’s opinion of their relevance for a software receiver implementation. It includes 
the enhanced FFT acquisition algorithm of Section 9.5.7 and the multipath-estimat-
ing discriminator of Section 8.3. The latter program can be run with different sig-
nals and user dynamics, thereby allowing an easy adoption for a software receiver. 
Implicitly, the core algorithms of Chapter 9 are used. The simulation framework 
is MATLAB and the core algorithms are included as pieces of inline assembler 
code.
Additionally, exemplary code is provided to calculate the TCRLB (see Section 
4.7.1) and to calculate the code phase, the Doppler, and the carrier-discriminator 
noise for arbitrary navigation signals and tracking schemes (see Section 8.1). 
11.1  Intended Use
The software should allow better understanding of the material presented in the 
main text and allow easier use for the reader. The source code makes precise refer-
ence to sections and equation numbers of the main text. The reader should open the 
MATLAB scripts and the C files and work through the source code with the help 
of the book. The reader should then truly understand the methods and be able to 
modify them.
11.2  Setup
Running the computer programs requires only a few small steps, which are de-
scribed in the following. The software can be downloaded from http://www. 
artechhouse.com/static/reslib/pany/pany1.html to a directory in your PC. In the fol-
lowing, it is assumed that the software is copied to a folder named “c:\navsigproc.”
11.2.1  Required Software
The software was tested with MATLAB 7.2 (R2006a) and Microsoft Visual C++ 
2005. It should run (with minor modification) with any later version. The C++ 
compiler is required to compile the MATLAB mex files containing the C and as-
sembler code.
*    Software available at www.artechhouse.com.

308	
Exemplary Source Code
11.2.2  Preparing the Simulation
After copying the files and starting MATLAB, switch to the working directory 
“c:\navsigproc” and run the MATLAB script “prepareSimulation.m.” This script 
will configure the C++ compiler and then compile all mex files.
11.2.3  Signal Selection and Simulation Parameters
Before running any of the routines listed in the next sections, open the script “init.
m” from within MATLAB and adjust the simulation parameters according to your 
needs. Then, run “init.m.” It might be useful to change the navigation signal type 
(see Section 1.9), the used sample rate, or the user dynamics.
11.3  Routines
The provided routines are all located in the chosen directory, for example, “c:\nav-
sigproc,” and will be described in Sections 11.3.1 through 11.3.4.
11.3.1  True Cramér-Rao Lower Bound
The script “calcTcrlb.m” computes the two code-phase TCRLBs of Section 4.6 and 
the conventional code-phase CRLB of Section 4.3.2.6 (with and without squaring 
loss) for the navigation signal specified in “init.m.” After you start the script, the 
four bounds will be plotted as a function of C /N0. 
11.3.2  Discriminator Noise Analysis
The script “calcDiscNoise.m” should help carry out performance analyses of the 
waveform-based tracking scheme with the noncoherent discriminators of Section 
8.1. Before starting “calcDiscNoise.m,” you may set the considered navigation sig-
nal and the used D- and P-correlator reference signals. The script will visualize the 
code-phase error, the Doppler error, and the carrier-phase error as a function of the 
C /N0 value. In addition, a code multipath error envelope will be plotted assuming 
one line-of-sight signal and one multipath signal with a constant attenuation and a 
variable geometric delay.
11.3.3  FFT Acquisition
The script “FftAcquisition.m” implements two FFT acquisition schemes and com-
pares the results. After start-up, a window will appear visualizing the correlation 
function as a function of the code phase. 
The script implements the circular shift method of Section 9.5.4 and the second-
ary code acquisition scheme of Section 9.5.7 (note that the Doppler preprocessing 
method of Section 9.5.6 is a special case of Section 9.5.7). An artificial tiered-code 
input signal is used and primary and secondary code can be changed in the script. 
The input signal is a code-phase-shifted version of the reference signal. The input 

11.3  Routines	
309
signal is not related to the settings in “init.m.” The Doppler search bin as well as the 
the Doppler summation range B can be modified. The latter parameter allows the 
computational burden to be reduced at the cost of reduced sensitivity.
11.3.4  Simplified Vector Tracking with Multipath Mitigation and  
Spectral Whitening
The script “track.m” includes a bit-true simulation of a received and quantized 
navigation signal and processes this signal with the multipath-estimating discrimi-
nator of Section 8.3. The signal is first generated by starting the script “generate­
Signal.m.” After starting “track.m,” code-phase, Doppler, and carrier-phase errors 
are plotted as a function of time. Additionally, the estimated number of multipath 
signal components are displayed.
You may specify the used navigation signal type, the user dynamics, and the 
multipath settings in the script “init.m.” Furthermore, the position and type of the 
correlators can be modified within “track.m.” The underlying P- and D-correlator 
reference signals can be changed in “init.m.” as well as the number of ADC bits, 
sample rate, and bandwidth. The spectral characteristics of the received noise can 
be selected and the method of spectral whitening (see Section 6.4) can be switched 
on or off. 
The script “track.m” also demonstrates how the estimated errors have to be 
combined with predicted-pseudorange values. This is the basis for vector tracking, 
where the prediction is based on the receiver’s position estimate.

311
Appendix
This appendix summarizes a few methods that are used to derive detection and 
estimation algorithms in the main text. 
A.1  Complex Least-Squares Adjustment
This section extends a standard least-squares adjustment [1], which is modified to 
include complex-valued random variables as parameters and as observations. By 
using complex-valued random variables, we obtain a more compact notation for 
the least-squares adjustment. Complex-valued random variables appear for I- and 
Q-components of the IF signal, for the correlator outputs, or for the complex- 
valued signal amplitude. In that case, the I- and Q-components share the same sto-
chastic and functional model allowing the use of the compact complex notation.
A.1.1  Definitions
In this section, lower case letters are used to indicate all random variables. If we 
have two i.i.d. real-valued random variables x and y, then we define a new complex-
valued random variable z as
	
=
+
z
x
iy	
(A.1)
The mean value <. . .> and the variance var <. . .> of z is given by
	
=
+
=
-
=
+
-
-
=
=
2
2
2
2
var
2var
2var
z
x
i y
z
zz
z
z
x
y
x
y
x
y
	
(A.2)
This syntax can be extended to two vectors of real valued i.i.d. random vari-
ables x and y, namely
	
=
+ i
z
x
y	
(A.3)
With Q, a symmetric matrix and the hermitian conjugate z* of z, we obtain
	
(
) (
)
(
)
T
T
T
T
T
T
T
T
Q
i
Q
i
Q
Q
i
Qy
Qx
Q
Q
*
=
-
+
=
+
+
-
=
+
z
z
x
y
x
y
x
x
y
y
x
y
x
x
y
y
	
(A.4)
because the scalar value xTQy can be written as
	
(
)
T
T
T
T
T
T
Q
Q
Q
Q
=
=
=
x
y
x
y
y
x
y
x	
(A.5)

312 
Appendix
Furthermore, we see
	
(
)(
)
2
2
T
T
T
T
T
T
i
i
*
=
-
+
=
+
=
=
z z
x
y
x
y
x x
y y
x x
y y 	
(A.6)
Therefore, if we have two vectors of real-valued random variables whose 
respective covariance matrices are identical, then they can be combined to one 
complex-valued vector of random variables, whose covariance matrix is real-valued 
and two times the covariance matrix of one of the real-valued vectors. 
A.1.2  Probability Density Function
If the two vectors of i.i.d. random variables x and y are of length L, are Gaussian 
with mean mx and my, and have a common covariance matrix Q, the probability 
density function can be written as
	
(
)
( ) ( )
p
p
p
=
x,y
x
y 	
(A.7)
with 
	
1
/ 2
1/ 2
1
1
( )
exp
(
)
(
)
2
(2 )
det( )
T
L
p
Q
Q
π
-
=
-
-
-
x
x
x
x
x
µ
µ
	
(A.8)
and similarly for y. Therefore
	
=
-
-
-
+
-
-
1
1
1
( , )
1
1
exp
[(
)
(
)
(
)
(
)]
2
(2 ) det( )
1
1
exp
[(
)
(
)]
2
(2 ) det( )
T
T
L
L
p
Q
Q
Q
Q
Q
π
π
-
-
*
-
=
-
x
x
y
y
z
z
x y
x
x
y
y
z -
z -
µ
µ
µ
µ
µ
µ
	
(A.9)
with
	
i
=
+
z
x
y
µ
µ
µ 	
(A.10)
See also Theorem 15.1 in Kay’s book for further information [2]. There the 
matrix C=2Q is used yielding
	
p
C
=
-
z
z -
z -
1
1
( )
exp{ [(
)
(
)]}
det( )
L
C
π
*
-
z
z
µ
µ
	
(A.11)
We also obtain
	
2
C
Q
* =
=
zz
	
(A.12)
A.1.3  The Adjustment
The complex LSQ adjustment procedure is based on the following function model
	
( )
=
l
l x 	
(A.13)

A.1  Complex Least-Squares Adjustment 
313
where x is the vector of parameters and l is the deterministic part of the measure-
ments. Both are assumed to be complex-valued.
We assume the following linearized observation model 
	
0
(
)
A
=
+
D +
k
l x
x
v	
(A.14)
where the vector of parameters is split into the a priori values (initial guesses) x0 
and the corrections Dx, 
	
0
=
+ D
x
x
x	
(A.15)
The observations are denoted as k and the measurement errors as v. 
The observations k and the measurement errors v are assumed to be complex-
valued random variables. The a priori values x0 are assumed to be known deter-
ministic quantities and the corrections Dx are deterministic but unknown quantities. 
Both x0 and Dx are generally complex-valued. The measurement errors are assumed 
to have zero mean and a real symmetric covariance matrix Qv
	
0,
var
(
)(
)
Q
Q
*
*
*
=
=
=
-
-
=
v
v
v
vv
k
k
k
k
k
	
(A.16)
The design matrix A is given by
	
0
,
( )
i
i j
j
l
A
x
=
=
x x
x
	
(A.17)
The reduced observations are defined as
	
0
(
)
,
var
A
Q
=
-
=
D
=
v
k
k
l x
k
x
k
	
(A.18)
and the LSQ principle is formulated as
	
1
(
)
(
)
min
2
A
Q
A
χ
*
-
D
=
-
D
-
D
v
x
k
x
k
x
	
(A.19)
The derivative of c with respect to Dx* yields
	
1
1
(
)
(
)
(
)
0
A
Q
A
A Q
A
*
-
*
-
*
-
D
-
D
= -
-
D
=
D
v
v
k
x
k
x
k
x
x
	
(A.20)
Note, that this is a set of complex-valued equations. The derivative with respect 
to Dx yields the same set of equations (but complex-conjugated). When using the 
complex notation, the variables Dx and Dx* are considered to be independent (de-
terministic) variables; for example,
	
0
*
D
=
D
x
x
	
(A.21)
To prove this statement consider a sufficiently continuous real-valued function 
f(x,y) of two real-valued unknowns. A necessary condition that it achieves a mini-
mum or maximum value, is that its derivatives with respect to x and y are zero. 
Substituting x and y with two independent complex-valued variables defined by
	
1
1
z
i
x
i
y
z*
=
÷
÷
÷
-

	
(A.22)

314 
Appendix
results in
	
1
1
f
f
x
z
f
f
i
i
y
z*
÷
÷
=
÷
÷
÷
-
÷
÷

	
(A.23)
and thus
	
0
0
f
f
x
z
f
f
y
z*
÷
÷
=
=
÷
÷
÷
÷

	
(A.24)
Therefore looking for the function’s extreme values with respect to z and z*
  is 
equal to looking for the extreme values with respect to x and y. We require that 
the function f needs to be holomorphic (complex differentiable) in z and z*
  as its 
first derivative exists. We require that z and z*
  are complex-conjugate with respect 
to each other, thereby solving the original LSQ problem. This implies that the two 
equations on the right-hand side of (A.24) are identical, since
	
(
, (
))
(
, (
))
f z
z
i z
z
f z
z
i z
z
*
*
*
*
+
-
=
+
-




	
(A.25)
The solution of (A.20) is the well known LSQ estimator equation, but now in 
complex notation
	
1
1
ˆ
N
A Q
-
*
-
D
=
v
x
k 	
(A.26)
with the normal matrix N
	
1
N
A Q
A
*
-
=
v
	
(A.27)
The normal matrix and its inverse are hermitian (N* = N) and thus its eigen-
values are real-valued. The estimated corrections are themselves random variables 
(because they depend on the observations) and from (A.18) we obtain for the ex-
pected value
	
1
1
1
1
ˆ
N
A Q
N
A Q
A
-
*
-
-
*
-
D
=
=
D
= D
v
v
x
k
x
x ,	
(A.28)
and from (A.18) for the variance
	
1
1
1
1
1
1
1
1
1
1
1
1
ˆ
ˆ
ˆ
ˆ
(
)(
)
(
)(
)
N
A Q
Q
AN
N
A Q
Q Q
AN
N
A Q
AN
N
*
*
-
*
-
*
*
-
-
-
*
-
-
-
-
*
-
-
-
D - D
D
- D
=
-
-
=
=
=
v
v
v
v
v
v
x
x
x
x
k
k
k
k
	
(A.29)
A.1.4  Real- and Complex-Valued Estimated Parameters
The estimated corrections (and thus the estimated parameters themselves) are 
a vector of complex-valued random variables D ˆx . Choosing complex-valued 

A.1  Complex Least-Squares Adjustment 
315
parameters may be natural in the case of the signal amplitude (i.e., I- and Q-
component) but is less obvious for parameters such as the code-phase or 
Doppler frequency. In the latter case, it may be necessary to force the param-
eters to be real-valued by imposing boundary conditions (e.g., 
0
k
k
x
x
-
=
). 
This is most easily achieved after the setup of the LSQ adjustment by decompos-
ing the complex-valued normal equation in its real and imaginary part. As a ca-
veat, decomposing increases the dimension of the equation system by a factor of 
two. In case of an uncorrelated complex-valued variable (uncorrelated with respect 
to the other variables), the following observation is very useful to circumvent the 
decomposition. 
Suppose the complex-valued estimated parameter xi has a variance of
	
1
var
(
)
i
ii
x
N-
D
=
	
(A.30)
As N –1 is hermitian, its diagonal elements are real-valued, thus the variance of 
the real part is
	
,
1
1
var
var
(
)
2
1
1
(
)
(var
var
)
var
4
2
2
i re
i
i
ii
i
i
i
x
x
x
N
x
x
x
-
D
=
D
+ D
=
D
+
D
=
D
=
	
(A.31)
with the same being true for the imaginary part and
	
,
,
,
,
2
2
2
2
(
)(
)
1 (
)(
)
4
1 (
(
))
0
4
i re
i re
i im
i im
i
i
i
i
i
i
i
i
i
i
i
i
x
x
x
x
x
x
x
x
x
x
x
x
i
x
x
x
x
i
D
- D
D
- D
=
=
D
+ D
- D
- D
D
- D
- D
+ D
=
D
- D
+
D
- D
=
	
(A.32)
because Dxi and 
ix
D  are independent but identically distributed random variables. 
Thus, the covariance matrix of the real and imaginary component is given by
	
( )
( )
1
,
1
,
0
1
var
2
0
i re
ii
i im
ii
N
x
x
N
-
-
D
÷
=
÷
÷
D
	
(A.33)
In that case forcing the imaginary part to be zero does not change the real part, 
which greatly simplifies the whole adjustment procedure. The imaginary compo-
nent can simply be discarded. Note, however, that the same is generally not true if 
Dxi correlates with other parameters. 
A.1.5  A Posteriori Variance of Unit Weight
To calculate the a posteriori variance of unit weight, we expand the expression 
(A.20) after doing the LSQ adjustment into

316 
Appendix
	
Tr Q
Q
AN
A Q
Q
=
-
-
Tr Q
Q
AN
A Q
Q
AN
A Q
Q
AN
A Q
=
-
-
+
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
ˆ
ˆ
ˆ
ˆ
(
)
(
)
(
)
(
)
2
(
)
(
)
(
)
(
)
(
)
(
)
{(
A
Q
A
Tr
A
Q
A
Tr
AN
A Q
Q
AN
A Q
Tr
Q
AN
A Q
AN
A Q
Tr
Q
AN
A Q
AN
A Q
χ
*
-
*
-
-
*
-
*
-
-
*
-
*
-
-
*
-
-
*
-
-
-
*
-
-
*
-
*
-
-
-
*
-
=
-
D
-
D
=
-
D
-
D
=
-
-
=
-
-
=
-
-
v
v
v
v
v
v
v
v
v
v
v
v
v
v
k
x
k
x
k
x
k
x
k
k
k
k
k
1
1
k
1
1
k k
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
)
}
{(
)
}
{(
)
}
AN
A Q
Q
AN
A Q
AN
A Q
Tr Q
Q
AN
A Q
-
-
*
-
-
-
*
-
-
*
-
*
-
-
-
*
-
-
-
*
-
-
-
*
-
*
-
-
-
*
-
*
+
=
-
v
v
v
v
v
v
v
v
v
v
v
v
v
v
v
k k
k k
k k
(A.34)
The expected value for the reduced observations is obtained from
	
var
(
)(
)
Q
*
*
*
*
=
=
-
-
=
-
v
k
k
k
k
k
k k
k
k
	
(A.35)
yielding
	
Q
Q
A
A
*
*
*
*
=
+
=
+
D D
v
v
k k
k
k
x x
	
(A.36)
Inserting (A.36) into (A.34) we obtain
	
Q
AN
A
Tr
r
u
-
=
-
=
-
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
{(
)(
)}
2
{(
)}
{(
)}
{(
)}
{
Tr Q
Q
AN
A Q
Q
A
A
Tr
Q
AN
A
Q
A
A
Q
AN
A Q
A
A
Tr
Q
AN
A
A Q
A
A Q
AN
A Q
A
Tr
Q
AN
A
A Q
A
A Q
A
Tr
χ
-
-
-
*
-
*
*
-
-
*
-
*
*
-
-
*
-
*
*
-
-
*
*
-
*
*
-
-
*
-
*
-
-
*
*
-
*
*
-
*
=
-
+
D D
=
-
+
D D
-
D D
=
-
+
D D
-
D D
=
-
+
D D
-
D D
=
v
v
v
v
v
v
v
v
v
v
v
v
v
v
v
x x
1
x x
x x
1
x x
x x
1
x x
x x
1
1
(
)}
{(
)}
r
u
-
-
*
v
1
1
1
	
(A.37)
where 1h denotes a h times h unit matrix. The symbol r denotes the number of 
complex-valued observations, the symbol u the number of complex-valued esti-
mated corrections
The adjusted observations are given as
	
1
1
1
1
ˆ
(
)
a
A
AN
A Q
AN
A Q
-
*
-
-
*
-
=
-
D
=
-
=
-
v
v
k
k
x
k
k
1
k 	
(A.38)
with the stochastic properties

A.1  Complex Least-Squares Adjustment 
317
	
1
1
1
1
0,
(
)
(
)
a
a
a
AN
A Q
Q
AN
A Q
*
-
*
-
-
*
-
*
=
=
-
-
v
v
v
k
k k
1
1
	
(A.39)
We analyze the covariance matrix of the adjusted observations and obtain
	
1
1
1
1
1
1
1
1
1
1
(
)
(
)
a
a
AN
A Q
Q
Q
AN
A
Q
AN
A
AN
A
AN
A Q
AN
A
Q
AN
A
*
-
*
-
-
-
*
-
*
-
*
-
*
-
-
*
-
*
=
-
-
=
-
-
+
=
-
v
v
v
v
v
v
k k
1
1
	
(A.40)
Based on the adjusted observation the vector k  of complex-valued random 
variables is defined as
	
1
with
0
a
Q -
=
=
v
k
k
k
	
(A.41)
and we obtain for χ
	
2
χ
*
= k
k 	
(A.42)
For the covariance matrix of k  we obtain the matrix M given as
	
1
1
1
1
1
1
(
)
M
Q
Q
AN
A
Q
Q
AN
A
Q
*
-
-
*
-
-
-
*
-
=
=
-
=
-
v
v
v
v
v
k k
1
	
(A.43)
The matrix is idempotent as the following relation holds
	
=
-
-
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
(
)(
)
MM
Q
AN
A
Q
Q
AN
A
Q
Q
AN
A
Q
Q
AN
A
Q
Q
AN
A
Q
Q
AN
A
Q
Q
AN
A
Q
M
-
-
*
-
-
-
*
-
-
-
*
-
-
-
*
-
-
-
*
-
-
-
*
-
-
-
*
-
=
-
-
+
=
-
=
v
v
v
v
v
v
v
v
v
v
v
v
v
v
1
1
1
1
	
	
	
(A.44)
Furthermore, it is hermitian because
 	
1
1
1
M
Q
AN
A
Q
M
*
-
-
*
-
=
-
=
v
v
1
	
(A.45)
Since M is hermitian it only has real eigenvalues and it can be diagonalized. 
This is written as
	
M
D D
D MD
*
*
=
L
= L	
(A.46)
with an unitary matrix D 
	
DD* = 1	
(A.47)
and a diagonal matrix L. Since M is hermitian and idempotent, its eigenvalues can 
either be one or zero.

318 
Appendix
The vector of complex-valued random variables k  is defined as
	
D*
=
k
k 	
(A.48)
For the covariance matrix we obtain
	
D MD
*
*
=
= L
k k
	
(A.49)
where the L is a diagonal matrix containing the eigenvalues of M, and the main 
diagonal is populated either by zeros or ones. Thus the elements of k  are uncor-
related complex-valued random variables whose variance is either zero or one. If 
we express the expected value of c as a function of k , we obtain
	
1
2
r
jj
j
D D
χ
*
*
*
*
=
=
=
=
=
L
k
k
k
k
k
k
	
(A.50)
We know from (A.37) that this equation also evaluates to r–u and we conclude 
that the vector k  includes exactly r–u random variables with unit variance. The 
other u elements are random variables of zero variance.
So far, we made no assumption on the actual distribution of our measurement 
errors. However, to obtain a quality measure for the LSQ adjustment, we assume 
that the measurement errors v are Gaussian. Because the operations to this point 
involving random variables were linear, also the random variables contained in k  
are either complex Gaussian variables with unit variance or they vanish. Thus, for 
χ we obtain [see (A.2)]
	
2
2
,
,
1
1
2
2
(
)
(2(
)
2(
) )
r
r u
j
j
j re
j im
j
j
k k
k
k
χ
-
*
=
=
=
=
=
+
k
k
	
(A.51)
The minimum cost c is the sum of 2(r–u) real-valued random variables, each 
having unit weight. Therefore χ is distributed according to the chi-squared distribu-
tion with 2(r–u) degrees of freedom, which is formally written as
	
2
2(
)
r u
χ
χ
-
∼
	
(A.52)
Compared to the LSQ adjustment with real-valued observations and real- 
valued estimated parameters, we observe that the degree of freedom, the effective 
number of parameters and the effective number of observations, doubles. 
A.1.6  Example
To illustrate the complex LSQ adjustment method, let’s assume we have the follow-
ing simplified model for a correlator output l.
	
(
)
i
i
l
aR τ
τ
=
+
	
(A.53)
Here li is the complex valued correlator output for a correlator with an offset of 
ti  with respect to the prompt correlator value. The received code phase is symbol-
ized as t. The symbol a denotes the complex-valued signal amplitude.

A.1  Complex Least-Squares Adjustment 
319
	
exp{
}
a
a
iϕ
=
	
(A.54)
where j is the carrier-phase tracking error. The real-valued correlation function of 
the internal reference signal used for correlation with the incoming signal is denoted 
as R and we have a two-dimensional vector of unknowns
	
a
τ
=
÷
x
	
(A.55)
As a boundary condition, we require that the imaginary part of t vanishes. For 
simplicity we choose as linearization point
	
0
0
0
a
=
÷
x
	
(A.56)
We measure two complex-valued correlator values (with a code phase offset of 
t1 and t2). The design matrix is given by
	
1
0
1
2
0
2
(
)
(
)
(
)
(
)
R
a R
A
R
a R
τ
τ
τ
τ
=
÷
	
(A.57)
Assuming both observations are uncorrelated and each have unit weight, the 
normal matrix is given by
	
2
2
1
2
0
1
1
2
2
2
2
2
0
1
1
2
2
0
1
2
(
)
(
)
( (
)
(
)
(
)
(
))
( (
)
(
)
(
)
(
))
(
(
)
(
) )
R
R
a R
R
R
R
N
A A
a R
R
R
R
a
R
R
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
*
+
+
=
=
÷÷
+
+
	
(A.58)
and its inverse by
	
(
)
2
2
1
2
1
1
2
2
2
2
0
2
1
1
2
2
1
1
2
1
2
2
1
1
2
2
1
2
2
2
2
0
2
1
1
2
0
2
1
1
2
(
)
(
)
(
)
(
)
(
)
(
)
( (
)
(
)
(
)
(
))
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
( (
)
(
)
(
)
(
))
( (
)
(
)
(
)
(
))
R
R
R
R
R
R
a R
R
R
R
R
R
R
R
N
R
R
R
R
R
R
a R
R
R
R
a
R
R
R
R
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
-
+
+
-
÷
-
-
÷
=
+
+
-
-
-
÷
÷
÷
	
(A.59)
In case of a real and symmetric correlation function and if t1 = –t2, then
	
2
1
1
2
2
0
1
1
0
2 (
)
1
0
2
(
)
R
N
a
R
τ
τ
-
÷
÷
=
÷
÷
	
(A.60)
In that case, forcing the imaginary part of the code-phase error estimate to van-
ish will not influence the other parameters. In fact, the complex-valued estimated 
value for the code phase is given by

320 
Appendix
	
0
1
2
1
1
1
2
2
2
0
1
1
2
1
2
0
1
0
1
ˆ
(
)
(
(
)
(
)
)
2
(
)
1
1
(
)
(
)
2
(
)
2
(
)
a
N
A
R
k
R
k
a
R
k
k
l
l
a R
a R
τ
τ
τ
τ
τ
τ
-
*
D =
=
+
-
=
-
=
-
k
	
(A.61)
The difference of both observations is a conventional early-minus-late dif-
ference and dividing it by the complex-valued signal amplitude brings the early- 
minus-late difference into the real part of this expression, which is the estimated 
code phase.
A.1.7  Discussion
Using complex variables in the LSQ adjustment potentially simplifies expressions 
as the carrier-phase error dependence involving sine/cosine terms can be avoided 
by using a complex-valued signal amplitude and observations. This reduces the 
dimension of the involved matrices by a factor of 2. The expressions are especially 
useful if the estimated parameters are uncorrelated because, in that case, the re-
quirement of real-valued parameters is very easily formulated. Otherwise, those 
conditions have to be introduced as boundary conditions after forming the normal 
matrix.
A.2  Representing Digital GNSS Signals
In a navigation receiver, complex- and real-valued signal samples may be used to 
represent the received navigation signals. Both options are equivalent and will be 
discussed in this appendix.
The navigation signal is received at RF level as a single (i.e. real-valued) signal. 
It is down-converted to a lower frequency by one of the following methods:
1.  One or more real mixers plus lowpass filters;
2.  Filtering and direct RF (bandpass) sampling;
3.  One or more complex (I/Q) mixers.
Methods 1 and 2 result in a real-valued signal, whereas Method 3 produces a 
complex-valued signal. Some variants of the presented methods exist, such as a real 
mixer plus IF/4 down conversion, which also produces a complex-valued signal. 
After down conversion, the signal is either centered around an IF or it is located 
directly at baseband.
A.2.1  Complex-Valued Input Signal
The samples of a complex-valued navigation signal consist of two numbers (the real 
and the imaginary part). The samples may be generated by two independent ADCs, 
which are synchronized with each other. They capture the I- and the Q-component 

A.2  Representing Digital GNSS Signals 
321
of the output from a complex mixer bringing the navigation signal from the RF to 
the IF or even to baseband. 
For complex-sampling, the Nyquist criterion reads that the sampling frequency 
must be higher than the dual-sided signal bandwidth. The received samples are ran-
dom variables composed of a deterministic part rm and a stochastic-noise part Nm,
	
S
r
N
µ
µ
µ
=
+
	
(A.62)
The deterministic part is assumed to be of the form
	
(
)exp{ (
)}
µ
µ
r
ac t
i
t
µ
τ
ω
ϕ
=
-
-
	
(A.63)
This form is assumed to be valid for short time spans and during that time span 
the four signal parameters a,t, ω, and φ are assumed to be constant. The sampled 
noise can be assumed to be white and is then modeled as
	
,
2 µ
N N
µ
υ
υ
δ
=
	
(A.64)
In case the input signal samples are complex-valued, the total signal power Psig 
is given by
	
2
sig
P
a
=
	
(A.65)
The total noise power Pnoise for a complex-valued input signal is two, as can be 
seen from (A.64), and the sample rate equals the (dual-sided) noise bandwidth B. 
The (dual-sided) noise power spectral density N0 is thus
	
0
2
noise
s
P
N
B
f
=
=
	
(A.66)
and the C/N0 value is
	
2
0
0
/
2
sig
s
P
f a
C N
N
=
=
	
(A.67)
or equivalently the following expressions are helpful
	
0
0
2
0
2 /
2 /
2 /
s
s
C N
C N
a
af
C N B
f
B
=
=
=
	
(A.68)
A.2.2  Real-Valued Input Signal
To represent a real-valued navigation signal, each signal sample consists of one 
number generated by one ADC. It captures the I- or the Q-component of a complex- 
or real-mixer output. The ADC may also be connected directly to the amplified and 
filtered RF signal.
For real sampling, the Nyquist criterion states that the sampling frequency must 
be higher than two times the dual-sided signal bandwidth. The received samples are 
random variables composed of a deterministic part rm and a stochastic-noise part 
Nm,

322 
Appendix
	
S
r
N
µ
µ
µ
=
+
	
(A.69)
The real-valued signal samples share the same signal model as the complex 
samples and their relation is expressed as
	
;
;
Re{
}
real
complex
S
S
µ
µ
=
	
(A.70)
Consequently, the deterministic part is assumed to be of the form
	
(
)cos(
)
µ
µ
r
ac t
t
µ
τ
ω
ϕ
=
-
-
	
(A.71)
and the sampled noise can be assumed to be white; that is, 
	
,
µ
N N
µ
υ
υ
δ
=
	
(A.72)
In case the input signal samples are real-valued, the total signal power Psig is 
given by
	
2
2
sig
a
P
=
	
(A.73)
The (single-sided) noise bandwidth B is given by half of the sample rate fs (Ny-
quist criterion). Note, for a real-valued signal, only positive frequency values of its 
spectrum are considered. The complex-conjugated, but otherwise symmetric, part 
of the spectrum located at negative frequencies is irrelevant. Because we assume that 
the real part of the noise samples has unit variance, the total noise power Pnoise for a 
real-valued input signal is one, as can be seen from (A.72). The (single-sided) noise 
power spectral density N0 is 
	
0
2
noise
s
P
N
B
f
=
=
	
(A.74)
The C/N0 value is defined as the ratio between received signal power and noise 
spectral density
	
2
0
0
/
4
sig
s
P
f a
C N
N
=
=
	
(A.75)
or equivalently the following expressions are occasionally helpful
	
2 /
C N
af
a
C N B
0
2
0
4 /
2
s
sf
=
=
	
(A.76)
A.2.3  Comparing Real- and Complex-Valued Signals
Complex- and real-valued signals are two equivalent ways of representing the same 
navigation signal, which is ultimately defined by its frequency content (or, loosely 
speaking, by its spectrum). A real-valued signal can be represented by only the posi-
tive frequency portion of its signal spectrum, although the spectrum (defined via 
the Fourier transform) of a real-valued signal also consists of negative frequencies. 
However, the full spectrum of real-valued signals is symmetric with respect to the 
zero frequency. On the contrary, the spectrum of a complex-valued signal has posi-
tive and negative frequency components and is, in general, not symmetric.




326 
Appendix
signal. For the purpose of navigation signal processing, this can be ignored as long 
as the main lobes of the navigation signal are not located at that frequency. In that 
case, a possible conversion would, more or less, only affect the noise part of the 
signal, which can be ignored.
Neither of the conversions change a or n0. 
A.3  Correlation Function Invariance
This appendix outlines a proof, that the cross-correlation function of two wide-
sense stationary stochastic processes is invariant under the sampling process. It 
implies that the sampling frequency does not influence the shape of the cross- 
correlation function. Aliasing effects average out because of the wide-sense station-
ary property. 
Let S(t) and R(t) be two complex-valued continuous stochastic processes. Both 
processes are wide-sense stationary. This implies that first- and second-order mo-
ments are constant in time [4]. 
The continuous-time cross-correlation function is defined as
	
,
(
) ( )
( )
S R
S t
R t
R
τ
τ
-
=
S,R
	
(A.77)
Discrete-time stochastic processes are obtained via sampling the continuous-
time processes, like
	
(
)
R
R t
µ
µ
=
	
(A.78)
with the sample index m
	
s
t
f
µ
µ
=
	
(A.79)
and fs being the sample rate. 
Both processes are wide-sense stationary, thus
	
,
1
1
(
) ( )
(
) ( )
( )
2
2
T
T
S R
t
T
t
T
S t
R t dt
S t
R t
dt
R
T
T
τ
τ
τ
=-
=-
-
=
-
=
S,R
S,R
	
(A.80)
The same relationship also holds for the discrete-time process
	
,
1
1
(
) (
)
(
) (
)
(
)
2
1
2
1
L
L
S R
L
L
S t
R t
S t
R t
R
L
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
=-
=-
-
=
-
=
+
+
S,R
S,R
	(A.81)
for an arbitrary sample rate fs.
It demonstrates that the cross-correlation function can be derived from discrete 
samples regardless of the sampling frequency. The sampling frequency, however, 
determines the timely resolution of the obtained correlation function. 
Loosely speaking, sampling needs to be ergodic in the sense that the sampling 
process needs to capture sufficient information on the stochastic properties of both 

A.3  Correlation Function Invariance 
327
processes. Ergodic sampling does not necessarily imply that the sample rate is larger 
than the Nyquist rate.
An obvious question arises, why aliasing effects—which occur if sub-Nyquist 
sampling is used—do not influence this result? In the following example, it will be 
shown that aliasing effects exist, but they average out when the correlation function 
is formed.
First, the Fourier transform of a stochastic process is given as
	
1
( )
( )exp{
}
2
t
R
R t
i t dt
ω
ω
π
=-
=
-

	
(A.82)
For a specific angular frequency w, the quantity ( )
R ω

 is a complex-valued ran-
dom variable. 
For two stochastic wide-sense stationary processes, the correlation between two 
Fourier transforms is
	
,
,
,
,
,
,
1
( ) (
)
( ) ( )
exp{
}
2
1
(
) ( )
exp{
(
)
}
2
1
( )exp{
(
)
}
2
1
( )exp{
(
)
}
2
t t
t t
S R
t t
S R
t t
S
R
S t R t
i t
i
t dtdt
S t
t R t
i
t
t
i
t dtdt
R
t
i
t
t
i
t dtdt
R
t
it
i t dtd
ω
ω
ω
ω
π
ω
ω
π
ω
ω
π
ω
ω
ω
π
=-
=-
=-
=-
=
-
-
=
-
-
-
-
=
-
-
-
=
-
+
+
S,R
S,R
S,R


,
(
)
( )exp{
}
S R
t
t
R
t
i t dt
δ ω
ω
ω
=-
=
+
	
(A.83)
where the relation
	
exp{
}
2
( )
t
i t dt
ω
πδ ω
=-
-
=
	
(A.84)
has been used to represent Dirac’s delta function. Overall, the correlation between 
the two Fourier transforms vanishes if both frequencies do not add up to zero.
If only discrete-time values τν of the cross-correlation function are considered
	
sf
ν
ν
τ
=
	
(A.85)
then the expected value of the timely averaged continuous-time correlation function 
for the shift index v is given by

328 
Appendix
	
,
,
(
) ( )
1
( ) (
)
exp{
(
)
}
2
( ) (
)
exp{
} (
)
( ) (
)
exp{
}
(
2
) (
2
)
exp{
}
t
t
s
s
S t
R t
dt
S
R
i
t
i
t d d
dt
S
R
i
d d
S
R
i
d
S
mf R
mf
i
υ
υ
ω ω
υ
ω ω
υ
ω
υ
τ
ω
ω
ω
τ
ω
ω ω
π
ω
ω
ωτ δ ω
ω
ω ω
ω
ω
ωτ
ω
ω
π
ω
π
ωτ
=-
=-
=-
=-
=-
-
=
-
+
=
-
+
=
-
-
=
+
-
-
-
S,R
S,R
S,R
S,R
S,R











s
s
f
m
f
d
π
ω
π
ω
=-
=-


	
(A.86)
Here the auxiliary angular frequency ω  has been introduced,
	
 
2
s
mf
ω
ω
π
=
+

	
(A.87)
The index m is used to count the continuous-time frequencies w, which are all 
aliased after sampling onto the same discrete-time frequency ω .
On the other hand, the expected value of the timely averaged discrete-time cor-
relation function is given by
	
,
,
,
(
) (
)
1
( ) (
)
exp{
(
)
}
2
1
( ) (
)
exp{
}
exp{
}
2
( ) (
)
exp{
}
(
(2
))
s
k
S t
R t
S
R
i
t
i
t
d d
S
R
i
i t
i
t
d d
S
R
i
kf
d
µ
υ
µ
µ
µ
υ
µ
µ
ω ω
υ
µ
µ
µ
ω ω
υ
ω ω
τ
ω
ω
ω
τ
ω
ω ω
π
ω
ω
ωτ
ω
ω
ω ω
π
ω
ω
ωτ
δ ω
π
ω
=-
=-
=-
=-
=-
=-
=-
-
=
-
+
=
-
+
=
-
-
-
S,R
S,R
S,R
S,R






( ) (2
)
exp{
}
s
k
d
S
R
kf
i
d
υ
ω
ω ω
ω
π
ω
ωτ
ω
=-
=-
=
-
-
S,R


	
(A.88)
Here the definition 
	
exp{
}
2
(
2
)
µ
µ
i t
kf
ω
π
δ ω
π
=-
=-
=
-
k
s 	
(A.89)
for the frequency comb function has been used.

A.4  Useful Formulas 
329
The expression (A.88) can be further simplified by introducing the auxiliary 
frequency ω  and we obtain
	
=
+
-
-
-
,
(
) (
)
(
2
) ( 2
)
exp{
}
s
s
µ
µ
µ
f
s
s
m k
f
S t
R t
S
mf R
k f
i
d
υ
π
υ
ω
π
τ
ω
π
π
ω
ωτ
ω
=-
=-
=-
-
S,R
S,R







	
(A.90)
For two wide-sense stationary processes, (A.86) equals (A.90) because 
	
(
2
) ( 2
)
0
s
s
m
k
S
mf R
k f
ω
π
π
ω
+
-
-
=
S,R




	
(A.91)
of (A.83).
Overall, the frequency domain picture of aliasing effects on the cross- 
correlation function can be described as follows: aliasing effects occur during 
sampling, causing correlation of frequency components, which do not correlate 
in the continuous-time case. However, the ensemble average of the aliasing effects 
averages to zero, because wide-sense stationary processes have a diagonal covari-
ance matrix in the frequency domain. 
A.4  Useful Formulas
This appendix summarizes some useful formulas for the reader’s convenience.
A.4.1  Fourier Transform
Definitions and normalization constants of three different Fourier transforms are 
summarized here. We consider the continuous Fourier transform and the discrete 
Fourier transform with finite and infinite length.
A.4.1.1  Continuous-Time
Let x(t) be a complex valued function of time t in seconds, then it is related to its 
angular frequency Fourier transform x(w)(unit [rad/s]) via 
	
1
( )
( )exp{
}
2
x t
x
i t d
ω
ω
ω
π -
=

	
(A.92)
and
	
1
( )
( )exp{
}
2
x
x t
i t dt
ω
ω
π -
=
-

	
(A.93)

330 
Appendix
Dirac’s delta function is expressed as
	
exp{
}
2
( ),
exp{
}
2
( )
i t dt
i t d
t
ω
πδ ω
ω
ω
πδ
-
-
-
=
=
	
(A.94)
The function x(t) is related to its frequency Fourier transform ( )
x f

 (unit [1/Hz]) 
via 
	
( )
( )exp{2
}
x t
x f
ift df
π
-
=

	
(A.95)
and
	
( )
( )exp{ 2
}
x f
x t
ift dt
π
-
=
-

	
(A.96)
Dirac’s delta function is expressed as
	
exp{ 2
}
( ),
exp{2
}
( )
ift dt
f
ift df
t
π
δ
π
δ
-
-
-
=
=
	
(A.97)
The Fourier transform ( )
x f

 (unit [1/ Hz]) is related to the angular frequency 
Fourier transform x(w) (in radians per seconds) via
	
( )
2
( )
x
x f
ω
π
=


	
(A.98)
A.4.1.2  Discrete Infinite Length Signal
Let xm be an infinite series of complex numbers, obtained by sampling a complex-
valued signal with a sample rate fs, then xm is related to its Fourier transform ( )
x f

(unit [1/Hz]) via 
	
2
2
1
2
( )exp
s
s
f
s
s
f
f
if
x
x f
    df
f
f
π
=-
=

µ
µ
	
(A.99)
and 
	
2
( )
exp
2
2
s
s
µ
s
µ
if
f
f
x f
x
µ
f
f
π
=-
=
-
<

	
(A.100)
Dirac’s delta function equivalent, the Kronecker delta and the Dirac comb, are 
expressed as
	
2
,0,
2
1
2
2
exp
exp
(
)
s
s
f
s
s
s
s
s
f
k
f
if
if
df
f
f
kf
f
f
f
µ
µ
π
π
µ
δ
µ
δ
=-
=-
=-
=
-
=
-
 	 (A.101)

A.4  Useful Formulas 
331
A.4.1.3  Discrete Finite Length Signal
Let xm be a finite series of complex numbers (0  m < L), then xm is related to its 
discrete Fourier transform k
x  via 
	
1
0
1
exp 2
L
µ
k
k
µk
x
x
i
L
L
π
-
=
=

	
(A.102)
and 
	
1
0
exp
2
L
k
k
x
x
i L
µ
µ
µ
π
-
=
=
-

	
(A.103)
Dirac’s delta function equivalent, the Kronecker delta, is expressed as
	
1
1
,0
,0
0
0
exp 2
,
exp
2
L
L
k
k
k
k
i
L
i
L
L
L
µ
µ
µ
µ
π
δ
π
δ
-
-
=
=
=
-
=
	
(A.104)
A.4.2  Correlation Function
Often, two signals are correlated with each other and the correlation is performed 
over a limited time span on equidistantly spaced epochs. Although the result cannot 
be simplified in a strict mathematical sense, the resulting expression is commonly 
approximated by the cross-correlation function of the two signals. This argument 
is formalized in the following discussion.
Let x(t) and y(t) be two functions. We define the (approximate) correlation 
function of the two functions as
	
,
1
1
( )
(
) ( )
L
x y
R
x t
y t
L
µ
µ
µ
τ
τ
=
-
	
(A.105)
where L is the number of samples involved in the summation. The specific values of 
the epochs tm are context-specific but they are usually equally spaced. The range of 
possible τ values is much smaller than the time span covered by tm ,
	
1
L
t
t
τ
-

	
(A.106)
The following identity holds approximately
	
,
,
1
1
1
1
( )
(
) (
)
(
) (
)
(
)
L
L
y x
x y
R
y t
x t
x t
y t
R
L
L
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
=
=
-
+
-
	
(A.107)
If x (t) and y (t) denote the first derivatives of x(t) and y(t), then the correlation 
functions involving derivatives are approximated as
	
,
,
1
1
,
,
1
1
1
1
( )
(
) (
)
(
) (
)
( )
1
1
( )
(
) (
)
(
) (
)
( )
L
L
x y
x y
L
L
x y
x y
R
x t
y t
x t
y t
R
L
L
R
x t
y t
x t
y t
R
L
L
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
µ
τ
τ
τ
τ
τ
τ
=
=
=
=
-
= -
-
-
-
+
	
(A.108)

332 
Appendix
For the second derivates, the following identities hold approximately
	
,
,
,
,
( )
( )
( )
( )
x
y
x y
x y
x y
R
R
R
R
τ
τ
τ
τ
-
	
(A.109)
For completeness, the following approximate identities are listed here
	
1
2
,
1
2
1
1
2
,
1
2
,
1
2
1
1
2
,
1
2
,
1
2
1
1
(
) (
)
(
)
1
(
) (
)
(
)
(
)
1
(
) (
)
(
)
(
)
L
                                        x y
L
                                        x y
x y
L
                                        x
y
x y
x t
y t
R
L
x t
y t
R
R
L
x t
y t
R
R
L
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
τ
=
=
=
-
-
-
-
-
-
-
-
-
-
-
-
µ
µ
µ
µ
µ
µ
µ
µ
µ
	
(A.110)
For the auto-correlation function of a complex-valued function, the following 
expressions are approximately valid
	
,
,
1
1
,
1
1
( )
(
) (
)
(
) (
)
(
)
Im{
(0)}
0
L
L
x x
x x
x x
R
x t
x t
x t
x t
R
L
L
R
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
=
=
-
+
-
	
(A.111)
for the first derivative
	
,
,
,
,
,
( )
( )
(
)
(
)
Re{
(0)}
0
x x
x x
x x
x x
x x
R
R
R
R
R
τ
τ
τ
τ
τ
τ
=
-
= -
-
	
(A.112)
and for the second derivative
	
2
2
,
,
,
,
2
2
,
( )
( )
(
)
(
)
Im{
(0)}
0
x x
x x
x x
x x
x x
R
R
R
R
R
τ
τ
τ
τ
τ
τ
=
-
=
-
	
(A.113)
A.4.3  Correlation with an Auxiliary Function
Let x(t) and y(t) be two functions. We define the (approximate) correlation function 
of the two functions including an auxiliary function h(t) as

A.4  Useful Formulas 
333
	
0
,
1
,
,
1
,
,
1
,
0
1
( ; )
(
) ( ) ( )
( )
(
) (
) (
)
( )
( )
(
) (
) ( )
(0)
1
( )
( ) ( )
L
L
x y
L
x y
x y
L
x y
x y
t
x y
L
t t
R
h
x t
y t
h t
L
R
x t
y t
h t
L
R
R
x t
y t
h t
L
R
R
W t h t dt
t
t
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
τ
τ
τ
=
=
=
=
-
-
=
-
	
(A.114)
with
	
,
( ) ( )
( )
(0)
x y
x t y t
W t
R
=
	
(A.115)
This formula is based on the assumption that the product of the two signals 
fulfills
	
-
-
0
,
,
( (
) ( )
(0)
( ) ( )
( )) ( )
0
L
t
x y
x y
t t
x t
y t R
x t y t R
h t dt
τ
τ
=
	
(A.116)
sufficiently well. Because this is a nontrivial assumption for the functions x, y and 
h, its validity has to be verified explicitly.
The function W(t) identifies the timely occurrence of the cross-correlation en-
ergy. If x(t) and y(t) are realizations of two wide-sense stationary processes, then 
W(t) is well approximated by one.
The formula for correlation with an auxiliary function is summarized as
	
,
,
,
,
(0; )
( ; )
( )
(0)
x y
x y
x y
x y
R
h
R
h
R
R
τ
τ
	
(A.117)
and indicates the required independence of the auxiliary function from the correla-
tion function.
A.4.4  Correlation with Doppler
The following example is based on Section A.4.3 with h being a complex sinusoidal 
function. Let x(t) and y(t) be two functions. We define the (approximate) correla-
tion function of the two functions including a Doppler offset w as
	
,
,
,
,
,
,
(0;exp{
})
( , )
( ;exp{
})
( )
( ) ( )
(0)
x y
x y
x y
x y
x y
x y
R
i t
R
R
i t
R
R
R
ω
τ ω
τ
ω
τ
τ κ ω
=
=
	
(A.118)

334 
Appendix
Similar to Section A.4.3, it is assumed that the correlation function is indepen-
dent from the complex sinusoidal function. The Doppler correlation function κ(w) 
evaluates to 
	
=
0
0
,
,
0
,
0
(0;exp{
})
( )
(0)
1
1
( )exp{
}
( ) ( )exp{
}
(
)
(0)(
)
L
L
x y
x y
t
t
L
x y
L
t t
t t
R
i t
R
W t
i t dt
x t y t
i t dt
t
t
R
t
t
ω
κ ω
ω
ω
=
=
=
-
-
	
(A.119)
For x(t) and y(t) being realizations of wide-sense stationary processes (i.e., 
W(t)  1) the function κ(ω) is well approximated as
	
0
0
(
)
( )
(
)
L
i t
i t
L
i e
e
t
t
ω
ω
κ ω
ω
-
-
	
(A.120)
For a symmetrically chosen summation interval of duration T
	
0
/ 2
L
t
t
T
= -
=
	
(A.121)
and x(t) and y(t) being realizations of wide-sense stationary processes, the function 
κ(w) is
	
( )
sinc
2
T
ω
κ ω
÷	
(A.122)
If x and y equal the Gaussian pulse sequence defined in (1.44), then the correla-
tion energy function is
	
2
2
2
2
2
2
0
0
2
2
,
2
2
2
2
(
)
(
)
exp
exp
2
2
( )
(0)
(
)
(
)
exp
exp
2
c c
t
a
d
t
a
d
c
c
b
b
W t
R
t
a
d
t
a
d
b
b
b b
-
-
-
+
-
+
-
-
-
-
+
-
+
-
	
(A.123)
under the parameter assumptions of Section 1.9.4.
The function κ(ω) is for the Gaussian pulse sequence approximated as
	
2
2
( )
exp{
}exp
cos(
)
4
b
i a
d
ω
κ ω
ω
ω
-
	
(A.124)
A.4.5  Correlation in Continuous Time
The correlation function between two sampled signals can be approximated by 
the correlation function of the underlying continuous-time signals. The Fourier 
transform of the continuous-time correlation function is the cross-power density 
spectrum and is the product of the Fourier transform of both signals. Fourier trans-

A.4  Useful Formulas 
335
forms and spectra of many modernized continuous-time GNSS signals can be found 
in the thesis by Ávila Rodríguez [5].
The discrete sum yielding the correlation function is approximated by an inte-
gral as
	
1
,
1
1
1
1
1
( )
(
) ( )
(
) (
)
1
(
) ( )
L
L
L
x y
t
L
t t
R
x t
y t
x t
y t
t
L
L t
x t
y t dt
t
t
µ
µ
µ
µ
µ
µ
τ
τ
τ
τ
=
=
=
-
=
-
D
D
-
-
	
(A.125)
where Dt = 1/fs is the sampling period.
If both signals are wide-sense stationary, the integration boundaries can be 
shifted. The integration is extended to infinity and the signals are expressed via the 
Fourier transforms, 
,
,
,
1
( )
lim
(
) ( )
2
1
lim
(
) (
)exp{
(
)
}
4
1
lim
(
) (
)exp{
}
exp{ (
)}
4
T
x y
T
t
T
T
T
t
T
T
T
t
T
R
x t
y t dt
T
x
y
i
t
i
t d
d
dt
T
x
y
i
it
dtd
d
T
ω ω
ω ω
τ
τ
ω
ω
ω
τ
ω
ω
ω
π
ω
ω
ω τ
ω
ω
ω
ω
π
=-
=-
=-
=-
=-
-
=
-
+
=
-
+




	
(A.126)
Exchanging limes and integration yields the following expression
	
1
1
lim
exp{ (
)}
0
2
T
T
t
T
it
dt
T
ω
ω
ω
ω
ω
ω
=-
= -
+
=
-
	
(A.127)
and the correlation function simplifies to
	
,
1
( )
(
) ( )exp{
}
2
x y
R
x
y
i
d
ω
τ
ω
ω
ωτ
ω
π
=-
-


	
(A.128)
Therefore the angular frequency domain Fourier transform of the correlation 
function is 
	
,
1
( )
(
) ( )
2
x y
R
x
y
ω
ω
ω
π
-



	
(A.129)
Because of different Fourier transform normalization factors, the normal (i.e., 
in [1/ Hz]) Fourier transform of the correlation function is 
	
, ( )
(
) ( )
x y
R
f
x
f y f
-



	
(A.130)

336 
Appendix
A.4.6  Probability Density Functions
In the following discussion, a number of probability density functions are listed 
which are used in Chapter 5 on signal detection. The formulas are based on Kay’s 
book [6]. For different distributions, the probability density function p(x) and the 
right-tail probability Q(x) (also termed complementary cumulative distribution 
function) will be listed. Both functions are related via
	
( )
( )
x
Q x
p t dt
=
	
(A.131)
A.4.6.1  Normal Distribution
The normal distribution function for a one-dimensional real-valued random vari-
able with mean m and a variance σ 2 is defined as
	
2
2
; ,
2
2
1
1
( )
exp
(
)
2
2
N
p
x
x
µ σ
µ
σ
πσ
=
-
-
	
(A.132)
The corresponding right-tail probability function cannot be expressed in closed 
form, but for x – m >> 4σ the following approximation is valid
	
2
2
2
; ,
; ,
2
(
)
( )
( )
exp
(
) 2
2
N
N
x
x
Q
x
p
t dt
x
µ σ
µ σ
σ
π
σ
-
=
-
-µ
µ
	
(A.133)
For m = 0 and σ = 1 we may omit the sub-script
	
;0,1
( )
( )
N
Q x
Q
x
=
	
(A.134)
A.4.6.2  Central Chi-Squared Distribution
The central chi-squared distribution arises as the probability distribution of the sum 
of ν squared normal distributed independent random variables yk with zero mean 
and unit variance, if yi is N(0,1) then x given by
	
2
2
1
k
k
x
y
υ
υ
χ
=
=
∼
	
(A.135)
is chi-square distributed with ν degrees of freedom. The probability density func-
tion is defined for positive values of x as
	
2
1
2
;
2
1
1
( )
exp
2
2
2
p
x
x
x
υ
χ
υ
υ
υ
-
=
-
÷
G
÷
	
(A.136)
and vanishes for negative values. The mean and variance are
	
(
)
2
var
2
x
x
x
x
υ
υ
=
=
-
=
	
(A.137)

A.4  Useful Formulas 
337
and the right-tail probability is given as
	
2 (
)
1
=
-
=
( )
( )
2
2 1
;
0
(
1) 2
1 2
1
2
( )
exp(
2)
2
!
exp(
2)
(
1)!(2 )
2
2
(2
1)!
k
k
k
k
Q
x
x
Q
x
x
k
x
k
x
Q
x
k
υ
χ
υ
υ
υ
υ
υ
π
-
=
-
-
=
=
-
-
+
-
	
(A.138)
A.4.6.3  Noncentral Chi-Squared Distribution
The noncentral chi-squared distribution arises as a result of summing the squares 
of ν-squared independent Gaussian random variables with nonzero means, if yi is 
N(mk,1) then x given by
	
2
2
,
1
k
k
x
y
υ
υ λ
χ
=
=
∼
	
(A.139)
has a noncentral chi-squared distribution with ν degrees of freedom and the non-
centrality parameter l defined as
	
2
1
k
k
µ
υ
λ
=
=
	
(A.140)
The probability density function is defined for positive values of x as
	
2
2
4
; ,
1
2
1
1
( )
exp
(
)
(
)
2
2
x
p
x
x
I
x
υ
υ
χ
υ λ
λ
λ
λ
-
-
=
-
+
÷
	
(A.141)
and vanishes for negative values of x. The symbol Ir denotes the modified Bessel 
function of the first kind and order r. The mean and variance are
	
x
x
x
2
var
(
)
2
4
x
υ
λ
υ
λ
=
+
=
-
=
+
	
(A.142)
The right-tail probability cannot be expressed in a closed form. However, for 
a large number of degrees of freedom ν, the right-tail probability can be approxi-
mated by using the central limit theorem as
	
2; , ( )
2
4
x
Q
x
Q
χ
υ λ
υ
λ
υ
λ
-
-
÷
+
	
(A.143)

338 
Appendix
A.4.6.4  Noncentral Chi-Squared Distribution for Complex-Valued  
Random Variables
If zk are complex -independent random variables whose real and imaginary part are 
independent and if Re{zk} is N(Re{mk}, 1), and Im{zk} is N(Im{mk}, 1), then x given 
by
	
2
2
2 ,
1
k
k
x
z
υ
υ λ
χ
=
=
∼
	
(A.144)
has a noncentral chi-squared distribution with 2ν degrees of freedom and the non-
centrality parameter l as
	
2
1
k
k
µ
υ
λ
=
=
	
(A.145)
The same formulas for the density function and moments as in Section A.3.6.3 
apply.
References
[1] 	
Leick, A., GPS Satellite Surveying, New York: Wiley, 2004.
[2] 	
Kay, S. M., Fundamentals of Statistical Signal Processing: Estimation Theory, Englewood 
Cliffs: Prentice Hall, 1993.
[3] 	
Diniz, P. S. R., E. A. B. da Silva, and S. L. Netto, Digital Signal Processing, System Analysis 
and Design, Cambridge, U.K.: Cambridge University Press, 2002.
[4] 	
Porat, B., Digital Processing of Random Signals, Theory & Methods, Englewood Cliffs, 
NJ: Prentice-Hall, 1994.
[5] 	
Ávila Rodríguez, J. Á., On Generalized Signal Waveforms for Satellite Navigation. Univer-
sity of Federal Armed Forces Munich, Werner-Heisenberg-Weg 39, D-85577 Neubiberg, 
http://www.unibw.de/unibib/digibib/ediss/bauv, 2008.
[6] 	
Kay, S. M., Fundamentals of Statistical Signal Processing: Detection Theory, Englewood 
Cliffs, NJ: Prentice-Hall, 1998. 

339
Abbreviations
i.i.d.
independent and identically distributed
ipexSR
Institute of Geodesy and Navigation PC-Based Experimental 
Software Receiver
ACRLB
Asymptotic CRLB
ADC
Analog-to-Digital Conversion
AEP
Application Environment Profile
AGC
Automatic Gain Control
AGNSS
Assisted GNSS
AltBOC
Alternate BOC
API
Application Programming Interface
ASIC
Application-Specific Integrated Circuit
BOC
Binary Offset Carrier
BPSK
Binary Phase Shift Keying
CCRW
Code Continuous Reference Waveform
CDMA
Code Division Multiple Access
CF
Core Framework
CORBA
Common Object Requesting Broker Architecture
COTS
Commercial Off The Shelf
CRLB
Cramér-Rao Lower Bound
CW
Continuous Wave
DAC
Digital-to-Analog Conversion
DC
Direct Current
DLL
Delay Lock Loop
DoD
Department of Defense
DOP
Dilution of Precision
DSP
Digital Signal Processor
EDGE
Enhanced Data Rates for GSM Evolution
EGNOS
European Geostationary Navigation Overlay Service
EIB
Element Interconnect Bus
EPLRS
Enhanced Position Location Reporting System
FDMA
Frequency Division Multiple Access
FFT
Fast Fourier Transform
FIR
Finite Impulse Response
FLL
Frequency Lock Loop
FM
Frequency Modulation
FPGA
Field-Programmable Gate Array
GATE
Galileo Test and Development Environment
GFLOPS
Giga Floating-Point Operations Per Second

GIG
Global Information Grid
GLRT
Generalized Likelihood Ratio Test
GNSS
Global Navigation Satellite System
GNU
GNU’s Not Unix (free software packages)
GOPS
Giga Operations Per Second
GPP
General Purpose Processor
GPS
Global Positioning System
GSM
Global System for Mobile Communications
HDTV
High-Definition Television
HF
High Frequency
HPA
High-Power Amplifier
HSDPA
High-Speed Downlink Packet Access
HSUPA
High-Speed Uplink Packet Access
ICD
Interface Control Document
IEEE
Institute of Electrical and Electronics Engineers
IGS
International GNSS Service
IMU
Inertial Measurement Unit
INS
Inertial Navigation System
IP
Internet Protocol
JAN-TE
Joint Airborne Networking–Tactical Edge
JCRLB
Joint CRLB
JTRS
Joint Tactical Radio System
LAN
Local Area Network
LNA
Low-Noise Amplifier
LORAN-C
LOng RAnge Navigation (-C)
LSB
Least Significant Bit
LSQ
Least-squares
MAP
Maximum A Posteriori Probability
MBOC
Multiplexed BOC
MCRBL
Modified CRLB
MEMS
Microelectromechanical system
MFLOPS
Mega Floating-Point Operations Per Second
MIPS
Million Instructions Per Second
ML
Maximum-Likelihood
MLE
Maximum-Likelihood estimator
MMAE
Minimum Mean Absolute Error
MMSE
Minimum Mean Squared Error
Mod-SDR
Modular SDR
MSB
Most Significant Bit
MSE
Mean Squared Error
MUOS
Mobile User Objective System
MVUE
Minimum Variance Unbiased Estimator
NCO
Numerically Controlled Oscillator
NMEA
National Marine Electronics Association
NSGU
Navigation Signal Generation Unit
OCXO
Oven Controlled Crystal Oscillator
ORB
Object Request Broker
340 
Abbreviations

OS
Open Service
OS
Operating System
PaC-SDR
Parameter-Controlled SDR
PC
Personal Computer
PCI
Peripheral Component Interconnect
PDA
Personal Digital Assistant
PL
Pseudolite
PLD
Programmable Logic Device
PLL
Phase Lock Loop
PND
Personal Navigation Device
POSIX
Portable Operating System Interface
PPE
Power Processor Element
PRN
Pseudorandom noise
PSD
Power Spectral Density
PVT
Position, Velocity and Time
QPSK
Quadratur Phase Shift Keying
R&D
Research and Development
RF
Radio Frequency
RINEX
Receiver INdependent EXchange Format
RMS
Root Mean Square
RTCM
Radio Technical Commission for Maritime services
RTK
Real-Time Kinematic
SATCOM
SATellite COMmunications
SCA
Software Communications Architecture
SDR
Software-Defined Radio
SI
Système International d’Unités
SINCGARS
SINgle Channel Ground and Airborne Radio System
SIS
Signal In Space
SISNET
Signal-In-Space NETwork
SMA
Sub-Miniature-A
SNR
Signal-to-Noise Ratio
SPE
Synergistic-Processor Element
SPI
Serial Peripheral Interface
SPS
Standard Positioning Service
SRW
Soldier Radio Waveform
SSP
Synchronous Serial Port
TCP
Transmission Control Protocol
TCRBL
True CRLB
TCXO
Temperature Controlled Crystal Oscillator
TDMA
Time Division Multiple Access
TOA
Time of Arrival
TTFF
Time to First Fix
UHF
Ultra-High Frequency
UMP
Uniform Most Powerful
UMPC
Ultra-Mobile PC
UMPUT
UMP Unbiased Test
UMTS
Universal Mobile Telecommunications System
Abbreviations 
341

USB
Universal Serial Bus
USRP
Universal Software Radio Peripheral
VDLL
Vector DLL
VLBI
Very Long Baseline Interferometry
WiMAX
Worldwide Interoperability for Microwave Access
WLAN
Wireless LAN
WNW
Wideband Networking Waveform
342 
Abbreviations

343
List of Symbols
The following conventions are generally used for mathematical symbols: Lower 
case variables denote deterministic quantities (e.g. r, s) and upper case symbols de-
note random variables (e.g. R, S). Estimates of deterministic but unknown quanti-
ties like ˆt, pˆ are themselves random variables but retain lower case symbols. A bold 
symbol like n denotes a vector having the elements nm. Matrices use italic upper case 
letters, like A or I.
Unless otherwise noticed, SI units are used. Code phases, delays or pseudo­
ranges are expressed in [s], distances in [m], angles and carrier phases in [rad], 
frequencies in [Hz] and angular frequencies in [rad/s]. 
Commonly Used Symbols
Symbol
Description
n
Noise (part of received signal samples)
p
Low rate pseudorange parameters
q
High rate pseudorange parameters
r
Deterministic signal (part of received signal samples)
s
Received signal samples
x
Position parameters
ξ
Nuisance parameters
a
Signal amplitude
c
Speed of light [299,792,458 m/s]
c(t)
Baseband representation of the navigation signal
C/N0
Carrier to noise power density ratio [Hz]
fs
Sample rate in [Samples/s]
i
Imaginary unit 
I
Fisher information matrix
L
Number of samples used for coherent integration
L(s)
Likelihood ratio
N(q, I)
Normally distributed random variables, with mean q and covariance 
matrix I
P(X > g )
Probability that the random variable X is larger than g
p(n)
Probability density function for the random variables N
Rx,y(t )
Cross-correlation function of signal x and y
tm
Time of reception for sample sm in [s]
Tcoh
Coherent integration time in [s]
t
Code phase in [s]

cfreq
Nonuniformity of signal power distribution in time
δ(x)
Dirac’s delta function
δm,υ
Kronecker’s Delta (1 for m=υ, 0 otherwise)
κ(ω)
Doppler correlation function
σ2
Variance of the noise samples
j
Carrier phase in [rad]
ω
Angular Doppler frequency in [rad/s]
Operations
Symbol
Description
(
)
( )
( )
( ) ( )
µ
µ
f
f
dµ
f
p
dn
=
=
P
N
N
n
n
n
n
Expected value of the function f with re-
spect to the random variables N with the 
probability density function p(n)
(
) (
)
var
*
*
*
=
-
-
=
-
N
N
N
N
N
N
N
S
S
S
S
S
SS
S
S
(Co-)variance of a vector of random vari-
ables S, S depends on N
2
2
var X
X
X
=
-
N
N
N
Variance of a random variable X being a 
function of N
(
)(
)
cov
,
*
=
-
-
N
N
N
N
S T
S
S
T
T
Covariance of two vectors of random 
variables S and T; S and T depend on N
x
Complex conjugate of x
xT
Transposed vector of x
x*
Hermitian conjugate (transposed and 
complex conjugate) of vector (or matrix) x
N ~ Q(a, b)
Random variable N is from distribution 
Q(a,b)
x  y
x approximately equal to y
x µ y
x proportional to y
!
=
x
y
x should be equal to y
T
µ µ
µ
x y
=
x
y
i
Dot product operation
c¢(t) = dc(t)/dt
First derivative of c(t)
<=>
Equivalence
344 
List of Symbols

345
About the Author
Thomas Pany is a senior research engineer at IFEN GmbH in Germany, a company 
that provides a complete portfolio of leading edge GNSS testing products, includ-
ing GNSS test receivers. He studied physics and began working with GPS receivers 
in 1997. He performed RTCM data quality monitoring in a network of permanent 
GPS reference stations and received a Ph.D. from the Graz University of Technol-
ogy in Austria for his work on modeling GPS and synthetic aperture radar signal 
propagation within the troposphere. In 2001, he began working at the University of 
Federal Armed Forces in Munich, and, over eight years, he has developed a number 
of different GNSS software receivers. This book derives from his work during that 
time. He has authored over 100 papers in the field of positioning, GNSS receivers, 
Galileo signal structure, and GPS science.

347
347
Index
A
A posteriori variance, 315
Absolute signal-to-noise ratio, 166, 169
Acquisition, 42, 50, 134, 129, 281
Acquisition time, 155, 288
Adjustment. See Least-squares estimation
Admissible range, 60
Aliasing, 182, 327
Allan variance, 285
Ambiguities, 305
Amplitude, 7, 74, 151
Analog data link, 26
Analog-to-digital conversion, 163, 173
Analog-to-digital conversion resolution, 
176
ASIC replacement, 25
Assembler code, 244, 247, 249, 309
Assistance data, 278, 282
Assisted acquisition, 260
Assisted tracking, 289
Asymptotic Cramér-Rao lower bound, 65, 
71, 81, 105
Asymptotic normality, 68
B
Barometer, 41
Batch processing, 35
Bayesian detector, 130, 138
Bayesian estimation, 108
Best linear unbiased estimator, 70
Binary offset carrier, 13, 134
Binary phase shift keying, 11
Bit. See Navigation data bit
Bit conversion, 242
Bit counting, 250
Bit reduction, 245
Block averaging, 257
Brick-wall filter, 208
Butterfly operation, 251
C
C/A code, 11, 260
Cache, 249, 267, 271, 274
Calibration, 235, 297
Cancellation, 148, 274, 299
Canopy, 280
Carrier phase, 7, 84, 96, 204, 223, 292
Cascaded estimation, 69, 71
Cell processor, 268
Central limit theorem, 163, 218
Channel, 42
Channel scaling, 272
Chi-square distribution, 336, 337
Circular correlation, 255
Clairvoyant detector, 134, 145
Clipping, 225
Clock drift, 283
Clock instability, jitter, 142, 158, 284, 286
Code division multiple access, 11, 196
Code Doppler, 147
Code-continuous reference waveform, 226
Codeless tracking, 200
Code-minus carrier, 53
Code phase, 7, 78, 81, 100, 102, 118, 122, 
157, 217
Code-phase drift, 147
Coherent integration, 141
Coherent Kalman filter, 113
Cold start, 50
Colored noise, 108, 178, 206, 208
Common object requesting broker 
architecture, 20

348 
Index
Complex valued signal, 189, 320
Composite binary offset carrier, 13
Composite hypothesis testing, 130
Computational burden, 158
Computational performance, 267
Concurrency level, 46
Consistent, 67
Continuous signal, 208, 334
Conversion loss, 163
Convolution theorem, 252
Correlation function, 326, 331
Correlation point, 91, 121, 234
Correlator, 72, 187, 248, 253
Correlator-based tracking, 185
Cost, Bayesian, 109, 119
Cramér-Rao lower bound, 62, 71, 80, 118
Critical path, 46
Cross-correlation protection, 148, 299
Cross-correlation tracking, 197, 200, 204
D
Data link, 278
Data reduction, 106
Data signal, 13,149
D-correlator, 10, 108, 110, 116, 194, 217, 
228
Delay, 7
Design matrix, 74, 313
Detection, 129
Deterministic signal model, 6
Difference correlator, 197
Differential detector, 158
Digital data link, 26
Direct P(Y)-code acquisition, 134
Direct sampling, 18
Discriminator, 72, 308
Doppler, 7, 78, 83, 104, 123, 157, 193, 
221, 282, 333
Doppler effect, 3
Doppler preprocessing, 160, 260
Dot product, 248
Double-delta discriminator, 194, 226
Double-difference correlator, 199, 291
Downconversion, 4
Dwell time, 156
E
Early correlator, 185, 194, 208, 213, 320
Effective bin size, 156
Efficient estimator, 63
Embedded system, 25, 273
Energy detector, 137, 176, 300
Equivalent correlators, 269
Ergodic sampling, 326
F
False alarm rate, 129, 155
Fast Fourier transform, 160, 251, 267, 
308, 329
F-correlator, 10, 108, 110, 193, 221
Fermat’s principle, 2
Filtering, 134
Finite sample rate, 212
Fisher information matrix, 62, 65, 68, 75, 
100, 117
Fixed solution, 305
Float solution, 305
Fourier transform. See Fast Fourier 
transform
FPGA receiver, 22
Front end, 22, 173, 208, 235, 273
G
Gabor bandwidth, 231
Galileo system, 13, 280
GATE, German Galileo Test Bed, 280
Generalized likelihood ratio test, 132, 140, 
160
Generic signal model, 4
Geodetic receiver, 273
Global Positioning System, 2, 10, 280
GLONASS, 280
GNU radio, 19
GPS/INS integration, 29
Group delay, 3
H
Handover, 51, 93, 284
Hard real time, 37

Index 
349
Hardware delay or bias, 3, 291
Hardware receiver, 22
Heterodyne front end, 24
High-power amplifier, 1
High-rate pseudorange, 58, 69, 74
High sensitivity, 281
Hilbert transform, 323
Hyperthreading, 278
Hypothesis test, 129
I
Independent bin, 156
Inertial measurement unit, 40, 113
Infinite sample rate, 208
Integer formats, 242
Intel architecture, 241
Intel atom processor, 278
Interference, 52, 147, 148, 165, 175, 177, 
274, 299
Intermediate frequency filter, 23
Internal time base, 33
International GNSS service, 29
Iterations, 124, 237
J
Jaffe-Rechtin filter, 94
Joint Cramér-Rao lower bound, 66, 71, 81, 
105
Joint estimation, 66
Joint tactical radio system, 19
K
Kalman filter, 94, 110, 113
L
L2-signal of GPS. See P(Y) code
Late correlator, 185, 194, 208, 213, 320
Latency, 36
Law of large numbers. See Central limit 
theorem
Least-squares estimation, 68, 69, 72, 77, 
118, 311
Likelihood equation, 67, 68
Likelihood ratio, 132
Limited size FFT, 257
Linear region, 227
Linearity condition, 88
Linearization, 97
Linearization point, 75, 234
Look-up table, 243
LORAN-C, 5
Losses (code phase, Doppler, quantization), 
157, 163
Low intermediate frequency front end, 24
Low-noise amplifier, 25
Low-rate pseudorange, 58
M
Magnetometer, 41
Marginal distribution, 64
Master channel, 42
Matched filter, 165
Maximum a posteriori probability, 110
Maximum likelihood estimation, 67, 72, 
94, 106, 151
Mean noise power density, 207
Mean squared error, 61
Measurement errors, 313
Memory bus, 250
Minimum mean-absolute error, 110
Minimum mean-squared error, 109
Minimum probability of error, 140
Minimum variance unbiased estimator, 61, 
62, 70, 72, 118
Missile tracking, 27
Mobile phone, 25
Modified Cramér-Rao lower bound, 64, 
71, 81, 105
Modular software defined radio, 18
Multibin statistics, 156
Multicore processor, 46
Multicorrelator, 107
Multifrequency receiver, 33, 304
Multipath, 98, 226, 231, 280, 309
Multipath detection, 237
Multipath-estimating delay lock loop, 232
Multiple propagation paths, 98

350 
Index
Multiplexed binary offset carrier, 13
Multiply-and-add, 25, 248, 249
N
Navigation data bit, 142, 149, 150, 153, 
289
Navigation processor, 43
Navigation signal, 1
Navigation signal generation unit, 1
Near-far effect, 297
Netbook, 277
Neyman-Pearson detector, 130, 136
Noise floor, 174
Noncoherent discriminator, 217
Noncoherent integration, 142
Noncoherent Kalman filter, 114
Non-Gaussian noise, 167
Nonlinear effects, 2, 113
Nonrandom estimation, 59
Normal distribution, 336
Normal matrix, 77
Nuisance parameters, 58, 81, 130, 131
Numerically controlled oscillator, 245, 
246, 247
Nyquist sampling, 181, 212, 321
O
Observation model, 313
Open Service of Galileo, 13
Optimal estimator, 118
Overlapping pulses, 302
Oversampling, 181
P
P(Y)-code of GPS, 197, 200, 204
Parameter-controlled SDR, 17
Particle filter, 113, 238
PC clock, 35, 41
P-correlator, 10, 108, 110, 116, 192, 217, 
221, 223
Penalty factor, 156
People tracking, 280
Personal navigation device, 25
Phase. See Carrier phase
Phase delay, 3
Photo tagging, 27
Pilot signal, 13, 149, 288
Position, 58
Position accuracy, 238
Position domain acquisition, 133, 148
Postprocessing, 38
Power consumption, 272
Precomputed signal, 245
Preprocessing, 133
Primary code, 263
Probability of detection, 129,155
Processing load, 55
Processing time, 155
Profiler, 241
Prompt correlator, 185, 192
Propagation path, 73, 76, 98
Pseudolites, 297
Pseudorange. See Code phase
Pseudorange domain acquisition, 133
Pull-in region, 227
Pulse blanking, 174, 300
Pulse clipping, 175
Pulsed signal, 14, 73, 118, 229, 299
Q
Quadrature phase shift keying, 149
Quantization, 163, 173
R
Radar, 5
Radio navigation, 1
Random sample access, 38
Real valued signal, 189, 321
Real time, 34, 37
Real-time kinematic positioning, 277, 304
Receiver autonomous integrity monitoring, 
43
Reconfigurable ASIC, 18
Recovery time, 175
Reference station, 29, 33, 50, 279, 289
Reflectometry, 27
Relative signal-to-noise ratio, 166, 169

Index 
351
Remote sensing, 27
Repetition rate of pulsed signals, 300
Resampling, 134, 245, 255
Reuse of reference signals, 91, 123
RINEX observation format, 293
Risk, Bayesian, 109
Root mean square, 61
S
Sample buffer, 40
Sample randomization, 176
Sampling, 5
Sampling epoch, 5
Scintillations, 3
S-curve shaping. See Shaping correlator
Search grid, 155, 282
Secondary code, 263
Sensor interface, 40
Server radio, 25
Shaping correlator, 52, 194, 225
Side-peak cancellation technique, 226
Signal component, 13
Signal conditioning, 3
Signal generator, 28
Signal outages, 291
Signal power, 8, 84, 321
Signal power variations, 9
Signal requirements, 8
Signal time, 155
Signal-in-noise problem, 61
Signal-power adaptation, 299
Significance level, 129
Simple hypothesis testing, 130
Single core, 48
Single propagation path, 76
Single-chip waveform, 11
Single-difference correlator, 197
Single-step estimation, 67
Size of a statistical test, 129
Smoothed time of arrival, 239
Snapshot receiver, 68
Soft real time, 37
Software communication architecture, 20
Software radio, 17
Software receiver, 22
Software-defined radio, 17
Spectral compatibility, 228
Spectral shifting, 256
Spectral whitening, 178, 309
Spectrum analyzer, 39, 53
Spoofing, 28
Squaring loss, 79, 81, 83, 84, 114
Stability, 94, 96, 226, 238, 295
Statistical test, 129
Statistics, 106
Stochastic noise model, 6
Stochastic process, 326
Sub-Nyquist sampling, 5, 52, 180
Sufficient modeling, 59
Sufficient statistics, 106, 180
Superheterodyne front end, 24
Surveying receiver, 280
System detection performance, 154
T
TCXO, 24, 282
Temperature changes, 282
Thread timeline, 45
Threading, 39, 45
Thresholds for quantization, 164, 173
Tiered code, 263
Time division multiple access, 15
Time-domain correlation, 253
Time of arrival, 239
Tracking, 51, 271
Tracking loop, 92
True Cramér-Rao lower bound, 64, 115, 
118, 308
Two’s complement, 243
U
Ultra-mobile PC, 277
Unbiased estimator, 102
Uncoupled parameters, 66
Undersampling, 182
Undetected pulses, 303
Uniform most powerful test, 131, 142
Uniform most powerful unbiased test,  
132

352 
Index
Uniformly distributed data bit, 142
Universal serial bus, 40, 47, 273
Universal serial bus front-end driver, 40
Universal software radio peripheral, 19
Unsmoothed time of arrival, 239
Unwrapping, 294
Useful parameters, 58
User motion, 142, 158, 287
V
Variance of least-squares estimates, 79
Vector instructions, 249
Vector tracking, 95, 238, 291
Vector-hold tracking, 290
Very long baseline interferometry, 200
W
Warm start, 50, 288
Waveform-based tracking, 185
W-code of the GPS P(Y)-signal, 197
W-correlator, 10, 194
White noise, 6, 178
Whitening filter, 208
White-noise transformation, 206
Wide-sense stationary, 165, 326
Wi-Fi, 41
X
XOR bit operation, 242, 250
Z
Zero padding, 254
